{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Using omterms keyword extraction package\n",
    "\n",
    "Bulent Ozel, UZH\n",
    "\n",
    "```bulent.ozel@gmail.com```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first objective of this module is to provide customizable and standardized text preprocessing phase prior to further analyses where more advanced machine learning and or statistical techniques can be applied and compared with each other. In that sense, it  provides a pipelined set of functionalities (i) to be able to inspect, organize, prune and merge texts around **one or very few specific theme(s) or topic(s)**, (ii) remove unwanted terms or literals from the texts, (iii) tokenize the texts, (iv) count the terms in texts, and (v) when desired stem the tokenized terms.\n",
    "\n",
    "The second objective of this module is to be able compare or score a foreground corpus or a specific corpus against a background corpus or reference corpus. Example use cases could be, for instance, exploring the language of a sub-culture, a community, or a movement looking at to what extend the specific use of the language of the group differentiates itself from the common language. \n",
    "\n",
    "In cases when there are more than a few number of themes or topics, and where each topic is represented with a large set of documents that validates the employment of standardized matrix decomposition based methodologies, then the scoring option of this module can be skipped entirely. More specifically, in use cases where the objective is being able to classify and differentiate a number of topics or issues from each other and where there are sufficient data that fulfills the underlining assumptions of NMF, LDA or LSI based approaches, then tools, for instance, from Python’s sklearn.decomposition package are suggested.\n",
    "\n",
    "Nevertheless, the outputs of this module such as normalized term frequencies or the specificity scores associated to them with respect to a reference background corpus can be used as input to other matrix decomposition techniques.\n",
    "\n",
    "For a general introduction on keyword and keyphrase extraction see the [readme file.](https://github.com/bulentozel/omterms/blob/master/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "A single text is provided.\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 10\n",
      "Cleaning process: Initial size of tokens = 10\n",
      "Reduction due to punctuations and stopwords = 3.\n",
      "Reduction due to all numeral terms = 1\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 5\n",
      "Percentage = 50%\n",
      "COMPLETED.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>input</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>process</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>less</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>seconds</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TF     Term  wTF\n",
       "0   1    input  0.2\n",
       "1   1     text  0.2\n",
       "2   1  process  0.2\n",
       "3   1     less  0.2\n",
       "4   1  seconds  0.2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import omterms\n",
    "from omterms.interface import *\n",
    "\n",
    "extract_terms(\"Some input X text to process less then 3 seconds.\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More detailed examples: the application interface options\n",
    "\n",
    "The application interface provides an encapsualtion and standardization at preparing a set of texts for further analyses. The standardized term extraction process covers tokenization, counting both raw and normalized term occurances, cleaning, stemming(optional), and scoring(optional) choices. The tabulated output can be exported in .csv file format and/or Pandas dataframe format.\n",
    "\n",
    "A varying number of input data formats is supported including their previously tokenized and cleaned versions. For the details on input parameters and types please see docstring documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module omterms.interface in omterms:\n",
      "\n",
      "NAME\n",
      "    omterms.interface - OpenMaker term extraction application interface.\n",
      "\n",
      "DESCRIPTION\n",
      "    Author: Bulent Ozel\n",
      "    e-mail: bulent.ozel@gmail.com\n",
      "    \n",
      "    The application interface provides an encapsualtion and standardization at preparing a set of texts for further analyses. The standardized term extraction process covers tokenization, counting both raw and normalized, cleaning, stemming(optional), and scoring(optional) chioices. The tabulated output can be exported in .csv file format and/or Pandas dataframe format.\n",
      "    \n",
      "    The input text(s) can be provided in any of the following formats:\n",
      "    - raw text\n",
      "    - tokenized text\n",
      "    - tokenized and counted\n",
      "    \n",
      "    In the same manner if a background courpus based scoring is desired then the reference corpus can be provided in any of the above formats. Depending on the desired actions on the input text, the output may contain not only raw and normalized term frequency counts but also stems of the terms its frequency count in the background corpus, when provided, and term's log likelihood weight wrt to its prevalance in the reference corpus.\n",
      "    \n",
      "    For deatils please see the README and tuturials that comes alongs with installation of this package.\n",
      "    \n",
      "    Attributes:\n",
      "        OUTPUT_FOLDER (file path): The folder to export the tabulated outputs in .csv files.\n",
      "        \n",
      "        OUTPUT_FNAME  (file name): The default output file name where results for multiple \n",
      "            texts are merged and presented.\n",
      "            \n",
      "        STOPWORDS_STANDARD (file path): The location of standard stopward list,\n",
      "            if desired and exists.\n",
      "            \n",
      "        STOPWORDS_SPECIFIC (file path): The location of topic(s) specific stopward lis,\n",
      "            if desired and exists. \n",
      "            \n",
      "        NOTALLOWED (:obj:`list` of `str`): The list of symbols that would flag the removal of the term,\n",
      "            if needed.\n",
      "            \n",
      "            Note: The removal would not take place if the term is a specific term or marked as an exception.\n",
      "            \n",
      "        TERMS_SPECIFIC (file path): The location of exception list of terms which is shielded from cleaning process,\n",
      "            if needed.\n",
      "            \n",
      "        TOKENIZER_FUNC (x :obj:`str` -> y: :obj:`str`): A tokenizer function.\n",
      "        \n",
      "        STEMMER_FUNC (x :obj:`str` -> y: :obj:`str`): A stemmer function, if needed\n",
      "        \n",
      "        MIN_LENGTH (:obj:`int`): The minimum allowed term length.\n",
      "        \n",
      "        MIN_FREQ (:obj:`float`): The minimum allowed frequency count for the tabuleted outputs.\n",
      "        \n",
      "        MODEL_THRESHOLD (:obj:`int`): if scoring is requested and if the input text is not driven from\n",
      "            the reference corpus, then the paramter is used at training the predection model for the terms\n",
      "            that don't occure in the reference corpus.\n",
      "    \n",
      "    Todo:\n",
      "        * Re-implement the module as a memoized object either via a class or a via wrapper function.\n",
      "        * Add a functionality where the configuration paramters can be loaded from a JSON file.\n",
      "        * Make tokenization an optional process, for the cases where the input is already provided in tokens.\n",
      "\n",
      "FUNCTIONS\n",
      "    extract_terms(texts, tokenizer=<function tokenize_strip_non_words at 0x105fcabf8>, merge=False, min_termlength=1, min_tf=1, topics=[], extra_process=[], stemmer=<bound method PorterStemmer.stem of <PorterStemmer>>, refcorpus=None, export=False, basefname='omterms.csv', outputdir='./output/', notallowed_symbols=\".,():;!?\\n`'=+/\\\\[]}{|><@#$%^&*_‘’“”.\", nonremovable_terms='./data/specifics_openmaker.txt', file_standard_stopwords='./data/stopwords_standard.txt', file_specific_sopwords='./data/stopwords_openmaker.txt', regression_threshold=1.0)\n",
      "        Term extraction modules main driver function.\n",
      "        \n",
      "        Args:\n",
      "            texts (:obj:`str` or :obj:`dict` of `str` or  :obj:`omterms.WikiArticles`):\n",
      "            The input text can be any of the following:\n",
      "                    - a string,\n",
      "                    - or a dictionary of strings where the key denotes the topic or\n",
      "                        any desired label/annotation regarding the text,\n",
      "                    - or a special data holder which contains labeled text scraped from\n",
      "                        Wikipedia articles.\n",
      "                    \n",
      "            tokenizer (x :obj:`str` -> y: :obj:`str`): The tokenizer,\n",
      "                (defualt omterms.tokenizer.tokenize_strip_non_words).\n",
      "                    \n",
      "            merge (:obj:`bool`): When a collection of text is provided via a dict or\n",
      "                WikiArticles, the parmater detertmines whether they should be conactinated\n",
      "                for the term extraction (default False).\n",
      "                 \n",
      "            min_termlength (:obj:`int`): The minimum allowed term length (default 1).\n",
      "            \n",
      "            min_tf (:obj:`int`): The minimum allowed frequency count for the tabuleted outputs\n",
      "                (default 4).\n",
      "                    \n",
      "            topics (:obj:`list` of `str`, optional): The list of topics from the input texts\n",
      "                to be considered (default Empty).\n",
      "                \n",
      "                If topic list is not provided and the merge is not requested but the input text\n",
      "                is given either via dict or via the WikiArticles data holder, then the topic list\n",
      "                will be driven from the input collection automatically.\n",
      "           \n",
      "            extra_process (:obj:`list` of `str`, optional): Whether stemming and/or scoring is\n",
      "                requested (default Empty).\n",
      "                - 'stem' is used/needed to flag stemming.\n",
      "                - 'compare' is used/needed to scoring texts against the designated reference corpus. \n",
      "           \n",
      "            stemmer (x :obj:`str` -> y: :obj:`str`, optional): A stemmer function, if needed\n",
      "                (default omterms.stemmer.porter).\n",
      "           \n",
      "            refcorpus (:obj:`str`\n",
      "                       or :obj:`list` of `str`\n",
      "                       or :obj:`dict` of `str`\n",
      "                       or :obj:`omterms.WikiArticles`, optional): The reference corpus\n",
      "                           (Default None)\n",
      "               The refcorpus can beny of the following:\n",
      "                    - None: if it is none yet the a scoring process is requested then\n",
      "                        NLTK's Brown corpus is loaded.\n",
      "                    - a string: A plain text.\n",
      "                    - list of words: List of words or tokens.\n",
      "                    - or a dictionary of strings where the text from the text will\n",
      "                        be unified for the reference corpus.\n",
      "                    - or a special data holder which contains labeled text scraped from Wikipedia\n",
      "                        articles, where all the texts from the collection will be combined to be used as\n",
      "                        the reference background corpus.\n",
      "        \n",
      "            export (:obj:`bool`, optional): Whether the resulting tables should be exported \n",
      "                (default False).\n",
      "            \n",
      "            basefname (:obj:`str`, optional): The output table name/prefix. Is effective\n",
      "                only when export is requested (default 'omsterms.csv').\n",
      "            \n",
      "            outputdir (:obj:`str`, optional): The file path, that is the folder to export the tabulated\n",
      "                outputs in .csv files (default './data/').\n",
      "            \n",
      "            notallowed_symbols (:obj:`list` of `str`, optional): The list of symbols that would flag\n",
      "                the removal of the term if needed (defualt omterms.tokenizer.CHARACTERS_TO_SPLIT\n",
      "                \n",
      "            nonremovable_terms (:obj:`str`, optional): File path to the list of exceptions.\n",
      "            \n",
      "            file_standard_stopwords (:obj:`str`, optional): The file path to the standard stopward list, \n",
      "                if desired and exists.\n",
      "                \n",
      "                Note: The removal would not take place if the term is a specific term or marked\n",
      "                as an exception.\n",
      "            \n",
      "            file_specific_stopwords (:obj:`str`, optional): The file path to a specifix stopward list,\n",
      "                if desired and exists.\n",
      "                \n",
      "                Note: The removal would not take place if the term is a specific term that is if marked as an exception.\n",
      "            \n",
      "            regression_threshold (:obj:`float`, optional): if scoring is requested and if the input text is\n",
      "                not driven from the reference corpus then this paramter is used at training the predection model\n",
      "                for the terms that don't occure in the reference corpus (default 1.0).\n",
      "                \n",
      "        Returns:\n",
      "            (:obj:`pandas.DataFrame`, optional) The tabulated data.\n",
      "    \n",
      "    reduce(...)\n",
      "        reduce(function, sequence[, initial]) -> value\n",
      "        \n",
      "        Apply a function of two arguments cumulatively to the items of a sequence,\n",
      "        from left to right, so as to reduce the sequence to a single value.\n",
      "        For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates\n",
      "        ((((1+2)+3)+4)+5).  If initial is present, it is placed before the items\n",
      "        of the sequence in the calculation, and serves as a default when the\n",
      "        sequence is empty.\n",
      "\n",
      "DATA\n",
      "    MIN_FREQ = 1\n",
      "    MIN_LENGTH = 1\n",
      "    MODEL_THRESHOLD = 1.0\n",
      "    NOTALLOWED = \".,():;!?\\n`'=+/\\\\[]}{|><@#$%^&*_‘’“”.\"\n",
      "    OUTPUT_FNAME = 'omterms.csv'\n",
      "    OUTPUT_FOLDER = './output/'\n",
      "    STOPWORDS_SPECIFIC = './data/stopwords_openmaker.txt'\n",
      "    STOPWORDS_STANDARD = './data/stopwords_standard.txt'\n",
      "    TERMS_SPECIFIC = './data/specifics_openmaker.txt'\n",
      "    brown = <CategorizedTaggedCorpusReader in '.../corpora/brown' (not loa...\n",
      "    log = <ufunc 'log'>\n",
      "\n",
      "FILE\n",
      "    /Users/bulentozel/OpenMaker/GitHub/omterms/omterms/interface.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(omterms.interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function extract_terms in module omterms.interface:\n",
      "\n",
      "extract_terms(texts, tokenizer=<function tokenize_strip_non_words at 0x105fcabf8>, merge=False, min_termlength=1, min_tf=1, topics=[], extra_process=[], stemmer=<bound method PorterStemmer.stem of <PorterStemmer>>, refcorpus=None, export=False, basefname='omterms.csv', outputdir='./output/', notallowed_symbols=\".,():;!?\\n`'=+/\\\\[]}{|><@#$%^&*_‘’“”.\", nonremovable_terms='./data/specifics_openmaker.txt', file_standard_stopwords='./data/stopwords_standard.txt', file_specific_sopwords='./data/stopwords_openmaker.txt', regression_threshold=1.0)\n",
      "    Term extraction modules main driver function.\n",
      "    \n",
      "    Args:\n",
      "        texts (:obj:`str` or :obj:`dict` of `str` or  :obj:`omterms.WikiArticles`):\n",
      "        The input text can be any of the following:\n",
      "                - a string,\n",
      "                - or a dictionary of strings where the key denotes the topic or\n",
      "                    any desired label/annotation regarding the text,\n",
      "                - or a special data holder which contains labeled text scraped from\n",
      "                    Wikipedia articles.\n",
      "                \n",
      "        tokenizer (x :obj:`str` -> y: :obj:`str`): The tokenizer,\n",
      "            (defualt omterms.tokenizer.tokenize_strip_non_words).\n",
      "                \n",
      "        merge (:obj:`bool`): When a collection of text is provided via a dict or\n",
      "            WikiArticles, the parmater detertmines whether they should be conactinated\n",
      "            for the term extraction (default False).\n",
      "             \n",
      "        min_termlength (:obj:`int`): The minimum allowed term length (default 1).\n",
      "        \n",
      "        min_tf (:obj:`int`): The minimum allowed frequency count for the tabuleted outputs\n",
      "            (default 4).\n",
      "                \n",
      "        topics (:obj:`list` of `str`, optional): The list of topics from the input texts\n",
      "            to be considered (default Empty).\n",
      "            \n",
      "            If topic list is not provided and the merge is not requested but the input text\n",
      "            is given either via dict or via the WikiArticles data holder, then the topic list\n",
      "            will be driven from the input collection automatically.\n",
      "       \n",
      "        extra_process (:obj:`list` of `str`, optional): Whether stemming and/or scoring is\n",
      "            requested (default Empty).\n",
      "            - 'stem' is used/needed to flag stemming.\n",
      "            - 'compare' is used/needed to scoring texts against the designated reference corpus. \n",
      "       \n",
      "        stemmer (x :obj:`str` -> y: :obj:`str`, optional): A stemmer function, if needed\n",
      "            (default omterms.stemmer.porter).\n",
      "       \n",
      "        refcorpus (:obj:`str`\n",
      "                   or :obj:`list` of `str`\n",
      "                   or :obj:`dict` of `str`\n",
      "                   or :obj:`omterms.WikiArticles`, optional): The reference corpus\n",
      "                       (Default None)\n",
      "           The refcorpus can beny of the following:\n",
      "                - None: if it is none yet the a scoring process is requested then\n",
      "                    NLTK's Brown corpus is loaded.\n",
      "                - a string: A plain text.\n",
      "                - list of words: List of words or tokens.\n",
      "                - or a dictionary of strings where the text from the text will\n",
      "                    be unified for the reference corpus.\n",
      "                - or a special data holder which contains labeled text scraped from Wikipedia\n",
      "                    articles, where all the texts from the collection will be combined to be used as\n",
      "                    the reference background corpus.\n",
      "    \n",
      "        export (:obj:`bool`, optional): Whether the resulting tables should be exported \n",
      "            (default False).\n",
      "        \n",
      "        basefname (:obj:`str`, optional): The output table name/prefix. Is effective\n",
      "            only when export is requested (default 'omsterms.csv').\n",
      "        \n",
      "        outputdir (:obj:`str`, optional): The file path, that is the folder to export the tabulated\n",
      "            outputs in .csv files (default './data/').\n",
      "        \n",
      "        notallowed_symbols (:obj:`list` of `str`, optional): The list of symbols that would flag\n",
      "            the removal of the term if needed (defualt omterms.tokenizer.CHARACTERS_TO_SPLIT\n",
      "            \n",
      "        nonremovable_terms (:obj:`str`, optional): File path to the list of exceptions.\n",
      "        \n",
      "        file_standard_stopwords (:obj:`str`, optional): The file path to the standard stopward list, \n",
      "            if desired and exists.\n",
      "            \n",
      "            Note: The removal would not take place if the term is a specific term or marked\n",
      "            as an exception.\n",
      "        \n",
      "        file_specific_stopwords (:obj:`str`, optional): The file path to a specifix stopward list,\n",
      "            if desired and exists.\n",
      "            \n",
      "            Note: The removal would not take place if the term is a specific term that is if marked as an exception.\n",
      "        \n",
      "        regression_threshold (:obj:`float`, optional): if scoring is requested and if the input text is\n",
      "            not driven from the reference corpus then this paramter is used at training the predection model\n",
      "            for the terms that don't occure in the reference corpus (default 1.0).\n",
      "            \n",
      "    Returns:\n",
      "        (:obj:`pandas.DataFrame`, optional) The tabulated data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(extract_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with plain texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 230\n"
     ]
    }
   ],
   "source": [
    "texta = \"\"\"The first objective of this module is to provide customizable and standardized text \n",
    "preprocessing phase prior to further analyses where more advanced machine learning and or statistical \n",
    "techniques can be applied and compared with each other. In that sense, it provides a pipelined set of \n",
    "functionalities (i) to be able to inspect, organize, prune and merge texts around one or very few specific \n",
    "theme(s) or topic(s), (ii) remove unwanted terms or literals from the texts, (iii) tokenize the texts, \n",
    "(iv) count the terms in texts, and (v) when desired stem the tokenized terms.\"\"\"\n",
    "\n",
    "textb = \"\"\"The second objective of this module is to be able compare or score a foreground corpus or a \n",
    "specific corpus against a background corpus or reference corpus. Example use cases could be, for instance, \n",
    "exploring the language of a sub-culture, a community, or a movement looking at to what extend the specific \n",
    "use of the language of the group differentiates itself from the common language.\n",
    "\"\"\"\n",
    "\n",
    "textc = \"\"\"In cases when there are more than a few number of themes or topics, and where each topic is \n",
    "represented with a large set of documents that validates the employment of standardized matrix decomposition \n",
    "based methodologies, then the scoring option of this module can be skipped entirely. More specifically, \n",
    "in use cases where the objective is being able to classify and differentiate a number of topics or issues \n",
    "from each other and where there are sufficient data that fulfills the underlining assumptions of NMF, LDA\n",
    "or LSI based approaches, then tools, for instance, from Python’s sklearn.decomposition package are suggested.\n",
    "\"\"\"\n",
    "\n",
    "textd = \"\"\"Nevertheless, the outputs of this module such as normalized term frequencies or the specificity\n",
    "scores associated to them with respect to a reference background corpus can be used as input to other matrix \n",
    "decomposition techniques.\n",
    "\"\"\"\n",
    "\n",
    "texts = {'a':texta, 'b':textb, 'c':textc, 'd':textd}\n",
    "textref = ' * '.join([texta,textc,textd])\n",
    "tokensref = run_tokenizing_process(textref, TOKENIZER_FUNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "A single text is provided.\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 95\n",
      "Cleaning process: Initial size of tokens = 95\n",
      "Reduction due to punctuations and stopwords = 53.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 54\n",
      "Percentage = 57%\n",
      "COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(texta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>texts</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>terms</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>objective</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>module</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>provide</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TF       Term       wTF\n",
       "27   4      texts  0.086957\n",
       "34   3      terms  0.065217\n",
       "0    1  objective  0.021739\n",
       "1    1     module  0.021739\n",
       "2    1    provide  0.021739"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# Note that TF stands for term frequency count wTF is TF/nwords in the input text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting the table  to a specific location and file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "A single text is provided.\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 95\n",
      "Cleaning process: Initial size of tokens = 95\n",
      "Reduction due to punctuations and stopwords = 53.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 54\n",
      "Percentage = 57%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/mytable.csv\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(texta, export = True, outputdir = './output/', basefname= 'mytable.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting terms from a set of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "\n",
      "Processing each topic ::>\n",
      "\n",
      "Topic = a\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 95\n",
      "Cleaning process: Initial size of tokens = 95\n",
      "Reduction due to punctuations and stopwords = 53.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 54\n",
      "Percentage = 57%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/a_omterms.csv\n",
      "\n",
      "Topic = b\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 66\n",
      "Cleaning process: Initial size of tokens = 66\n",
      "Reduction due to punctuations and stopwords = 40.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 40\n",
      "Percentage = 61%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/b_omterms.csv\n",
      "\n",
      "Topic = c\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 100\n",
      "Cleaning process: Initial size of tokens = 100\n",
      "Reduction due to punctuations and stopwords = 57.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 57\n",
      "Percentage = 57%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/c_omterms.csv\n",
      "\n",
      "Topic = d\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 35\n",
      "Cleaning process: Initial size of tokens = 35\n",
      "Reduction due to punctuations and stopwords = 17.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 17\n",
      "Percentage = 49%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/d_omterms.csv\n",
      "Results are exported to file: ./output/omterms.csv\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(texts, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>a-TF</th>\n",
       "      <th>a-wTF</th>\n",
       "      <th>b-TF</th>\n",
       "      <th>b-wTF</th>\n",
       "      <th>c-TF</th>\n",
       "      <th>c-wTF</th>\n",
       "      <th>d-TF</th>\n",
       "      <th>d-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>able</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advanced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>against</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>analyses</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>applied</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>approaches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>around</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>associated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>assumptions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>background</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Term  a-TF     a-wTF  b-TF     b-wTF  c-TF     c-wTF  d-TF     d-wTF\n",
       "0         able   1.0  0.021739   1.0  0.030303   1.0  0.020833   NaN       NaN\n",
       "1     advanced   1.0  0.021739   NaN       NaN   NaN       NaN   NaN       NaN\n",
       "2      against   NaN       NaN   1.0  0.030303   NaN       NaN   NaN       NaN\n",
       "3     analyses   1.0  0.021739   NaN       NaN   NaN       NaN   NaN       NaN\n",
       "4      applied   1.0  0.021739   NaN       NaN   NaN       NaN   NaN       NaN\n",
       "5   approaches   NaN       NaN   NaN       NaN   1.0  0.020833   NaN       NaN\n",
       "6       around   1.0  0.021739   NaN       NaN   NaN       NaN   NaN       NaN\n",
       "7   associated   NaN       NaN   NaN       NaN   NaN       NaN   1.0  0.055556\n",
       "8  assumptions   NaN       NaN   NaN       NaN   1.0  0.020833   NaN       NaN\n",
       "9   background   NaN       NaN   1.0  0.030303   NaN       NaN   1.0  0.055556"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifiying a subset of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "\n",
      "Processing each topic ::>\n",
      "\n",
      "Topic = a\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 95\n",
      "Cleaning process: Initial size of tokens = 95\n",
      "Reduction due to punctuations and stopwords = 53.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 54\n",
      "Percentage = 57%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "COMPLETED.\n",
      "\n",
      "Topic = c\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 100\n",
      "Cleaning process: Initial size of tokens = 100\n",
      "Reduction due to punctuations and stopwords = 57.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 57\n",
      "Percentage = 57%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(texts, topics = ['a','c'], extra_process = ['stem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>a-TF</th>\n",
       "      <th>a-wTF</th>\n",
       "      <th>c-TF</th>\n",
       "      <th>c-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>able</td>\n",
       "      <td>abl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advanced</td>\n",
       "      <td>advanc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>analyses</td>\n",
       "      <td>analys</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>applied</td>\n",
       "      <td>appli</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>approaches</td>\n",
       "      <td>approach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Term      Stem  a-TF     a-wTF  c-TF     c-wTF\n",
       "0        able       abl   1.0  0.021739   1.0  0.020833\n",
       "1    advanced    advanc   1.0  0.021739   NaN       NaN\n",
       "2    analyses    analys   1.0  0.021739   NaN       NaN\n",
       "3     applied     appli   1.0  0.021739   NaN       NaN\n",
       "4  approaches  approach   NaN       NaN   1.0  0.020833"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring/comparing wrt  a background text\n",
    "\n",
    "The details of the scoring including the prediction model on missing terms on the background see the custom processing session below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "Preparing the reference corpus ::>\n",
      "Cleaning the reference corpus ...\n",
      "Cleaning process: Initial size of tokens = 230\n",
      "Reduction due to punctuations and stopwords = 137.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 138\n",
      "Percentage = 60%\n",
      "Stemming the word in the reference corpus ...\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "Done: Reference corpus process.\n",
      "A single text is provided.\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 95\n",
      "Cleaning process: Initial size of tokens = 95\n",
      "Reduction due to punctuations and stopwords = 53.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 54\n",
      "Percentage = 57%\n",
      "41 / 41  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "0 / 41 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "0 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(texta, extra_process = ['compare'], refcorpus = tokensref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "      <th>SType</th>\n",
       "      <th>Score</th>\n",
       "      <th>wTFref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>texts</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>terms</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>0.026786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>provide</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>customizable</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TF          Term       wTF SType     Score    wTFref\n",
       "27   4         texts  0.086957   raw  0.889857  0.035714\n",
       "34   3         terms  0.065217   raw  0.889857  0.026786\n",
       "2    1       provide  0.021739   raw  0.889857  0.008929\n",
       "3    1  customizable  0.021739   raw  0.889857  0.008929\n",
       "5    1          text  0.021739   raw  0.889857  0.008929"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score** is the log likelihood of the normalized term frequencies wrt to the reference corpus.\n",
    "\n",
    "**SType** stands for scoring type which can be either one of:\n",
    "- raw: the term as it is was identified in the background corpus, so a loglikelihood scoring was applied\n",
    "- stem: not the term as it is but its stem was identified, so mean of the observed stem occurances in the background was used as the reference\n",
    "- noref: neither the term nor its stem was identified, so **the prediction model, a log-linear regression based model** is used for the frequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "Preparing the reference corpus ::>\n",
      "An untokenized reference corpus is identified.\n",
      "Tokenizing the reference corpus ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 230\n",
      "Cleaning the reference corpus ...\n",
      "Cleaning process: Initial size of tokens = 230\n",
      "Reduction due to punctuations and stopwords = 137.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 138\n",
      "Percentage = 60%\n",
      "Stemming the word in the reference corpus ...\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "Done: Reference corpus process.\n",
      "\n",
      "Processing each topic ::>\n",
      "\n",
      "Topic = a\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 95\n",
      "Cleaning process: Initial size of tokens = 95\n",
      "Reduction due to punctuations and stopwords = 53.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 54\n",
      "Percentage = 57%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "41 / 41  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "0 / 41 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "0 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n",
      "\n",
      "Topic = b\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 66\n",
      "Cleaning process: Initial size of tokens = 66\n",
      "Reduction due to punctuations and stopwords = 40.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 40\n",
      "Percentage = 61%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "10 / 26  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "16 / 26 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "3 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n",
      "\n",
      "Topic = c\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 100\n",
      "Cleaning process: Initial size of tokens = 100\n",
      "Reduction due to punctuations and stopwords = 57.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 57\n",
      "Percentage = 57%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "43 / 43  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "0 / 43 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "0 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n",
      "\n",
      "Topic = d\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 35\n",
      "Cleaning process: Initial size of tokens = 35\n",
      "Reduction due to punctuations and stopwords = 17.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 17\n",
      "Percentage = 49%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "18 / 18  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "0 / 18 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "0 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(texts, extra_process = ['stem','compare'], refcorpus = textref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTFref</th>\n",
       "      <th>SType</th>\n",
       "      <th>a-Score</th>\n",
       "      <th>a-TF</th>\n",
       "      <th>a-wTF</th>\n",
       "      <th>b-Score</th>\n",
       "      <th>b-TF</th>\n",
       "      <th>b-wTF</th>\n",
       "      <th>c-Score</th>\n",
       "      <th>c-TF</th>\n",
       "      <th>c-wTF</th>\n",
       "      <th>d-Score</th>\n",
       "      <th>d-TF</th>\n",
       "      <th>d-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>able</td>\n",
       "      <td>abl</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.196710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.528844</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.154151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advanced</td>\n",
       "      <td>advanc</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>against</td>\n",
       "      <td>against</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>analyses</td>\n",
       "      <td>analys</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>applied</td>\n",
       "      <td>appli</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>approaches</td>\n",
       "      <td>approach</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>around</td>\n",
       "      <td>around</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>associated</td>\n",
       "      <td>associ</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.828127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>assumptions</td>\n",
       "      <td>assumpt</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>background</td>\n",
       "      <td>background</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.221991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.828127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>based</td>\n",
       "      <td>base</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Term        Stem    wTFref  SType   a-Score  a-TF     a-wTF  \\\n",
       "0          able         abl  0.017857    raw  0.196710   1.0  0.021739   \n",
       "1      advanced      advanc  0.008929    raw  0.889857   1.0  0.021739   \n",
       "2       against     against       NaN  noref       NaN   NaN       NaN   \n",
       "3      analyses      analys  0.008929    raw  0.889857   1.0  0.021739   \n",
       "4       applied       appli  0.008929    raw  0.889857   1.0  0.021739   \n",
       "5    approaches    approach  0.008929    raw       NaN   NaN       NaN   \n",
       "6        around      around  0.008929    raw  0.889857   1.0  0.021739   \n",
       "7    associated      associ  0.008929    raw       NaN   NaN       NaN   \n",
       "8   assumptions     assumpt  0.008929    raw       NaN   NaN       NaN   \n",
       "9    background  background  0.008929    raw       NaN   NaN       NaN   \n",
       "10        based        base  0.017857    raw       NaN   NaN       NaN   \n",
       "\n",
       "     b-Score  b-TF     b-wTF   c-Score  c-TF     c-wTF   d-Score  d-TF  \\\n",
       "0   0.528844   1.0  0.030303  0.154151   1.0  0.020833       NaN   NaN   \n",
       "1        NaN   NaN       NaN       NaN   NaN       NaN       NaN   NaN   \n",
       "2        NaN   1.0  0.030303       NaN   NaN       NaN       NaN   NaN   \n",
       "3        NaN   NaN       NaN       NaN   NaN       NaN       NaN   NaN   \n",
       "4        NaN   NaN       NaN       NaN   NaN       NaN       NaN   NaN   \n",
       "5        NaN   NaN       NaN  0.847298   1.0  0.020833       NaN   NaN   \n",
       "6        NaN   NaN       NaN       NaN   NaN       NaN       NaN   NaN   \n",
       "7        NaN   NaN       NaN       NaN   NaN       NaN  1.828127   1.0   \n",
       "8        NaN   NaN       NaN  0.847298   1.0  0.020833       NaN   NaN   \n",
       "9   1.221991   1.0  0.030303       NaN   NaN       NaN  1.828127   1.0   \n",
       "10       NaN   NaN       NaN  0.847298   2.0  0.041667       NaN   NaN   \n",
       "\n",
       "       d-wTF  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "5        NaN  \n",
       "6        NaN  \n",
       "7   0.055556  \n",
       "8        NaN  \n",
       "9   0.055556  \n",
       "10       NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTFref</th>\n",
       "      <th>SType</th>\n",
       "      <th>a-Score</th>\n",
       "      <th>a-TF</th>\n",
       "      <th>a-wTF</th>\n",
       "      <th>b-Score</th>\n",
       "      <th>b-TF</th>\n",
       "      <th>b-wTF</th>\n",
       "      <th>c-Score</th>\n",
       "      <th>c-TF</th>\n",
       "      <th>c-wTF</th>\n",
       "      <th>d-Score</th>\n",
       "      <th>d-TF</th>\n",
       "      <th>d-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>themes</td>\n",
       "      <td>theme</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tokenize</td>\n",
       "      <td>token</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tokenized</td>\n",
       "      <td>token</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tools</td>\n",
       "      <td>tool</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>topic</td>\n",
       "      <td>topic</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.196710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>topics</td>\n",
       "      <td>topic</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>underlining</td>\n",
       "      <td>underlin</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>unwanted</td>\n",
       "      <td>unwant</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.915138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>used</td>\n",
       "      <td>use</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.828127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>validates</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Term      Stem    wTFref SType   a-Score  a-TF     a-wTF  \\\n",
       "97        themes     theme  0.008929   raw       NaN   NaN       NaN   \n",
       "98      tokenize     token  0.008929   raw  0.889857   1.0  0.021739   \n",
       "99     tokenized     token  0.008929   raw  0.889857   1.0  0.021739   \n",
       "100        tools      tool  0.008929   raw       NaN   NaN       NaN   \n",
       "101        topic     topic  0.017857   raw  0.196710   1.0  0.021739   \n",
       "102       topics     topic  0.017857   raw       NaN   NaN       NaN   \n",
       "103  underlining  underlin  0.008929   raw       NaN   NaN       NaN   \n",
       "104     unwanted    unwant  0.008929   raw  0.889857   1.0  0.021739   \n",
       "105          use       use  0.008929   raw       NaN   NaN       NaN   \n",
       "106         used       use  0.008929   raw       NaN   NaN       NaN   \n",
       "107    validates     valid  0.008929   raw       NaN   NaN       NaN   \n",
       "\n",
       "      b-Score  b-TF     b-wTF   c-Score  c-TF     c-wTF   d-Score  d-TF  \\\n",
       "97        NaN   NaN       NaN  0.847298   1.0  0.020833       NaN   NaN   \n",
       "98        NaN   NaN       NaN       NaN   NaN       NaN       NaN   NaN   \n",
       "99        NaN   NaN       NaN       NaN   NaN       NaN       NaN   NaN   \n",
       "100       NaN   NaN       NaN  0.847298   1.0  0.020833       NaN   NaN   \n",
       "101       NaN   NaN       NaN  0.154151   1.0  0.020833       NaN   NaN   \n",
       "102       NaN   NaN       NaN  0.847298   2.0  0.041667       NaN   NaN   \n",
       "103       NaN   NaN       NaN  0.847298   1.0  0.020833       NaN   NaN   \n",
       "104       NaN   NaN       NaN       NaN   NaN       NaN       NaN   NaN   \n",
       "105  1.915138   2.0  0.060606  0.847298   1.0  0.020833       NaN   NaN   \n",
       "106       NaN   NaN       NaN       NaN   NaN       NaN  1.828127   1.0   \n",
       "107       NaN   NaN       NaN  0.847298   1.0  0.020833       NaN   NaN   \n",
       "\n",
       "        d-wTF  \n",
       "97        NaN  \n",
       "98        NaN  \n",
       "99        NaN  \n",
       "100       NaN  \n",
       "101       NaN  \n",
       "102       NaN  \n",
       "103       NaN  \n",
       "104       NaN  \n",
       "105       NaN  \n",
       "106  0.055556  \n",
       "107       NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on larger texts crawled from Wikipedia.\n",
    "\n",
    "For the purpose and convenience a data holder named WikiArticles is designed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class WikiArticles in module omterms.datauis:\n",
      "\n",
      "class WikiArticles(builtins.object)\n",
      " |  The object contains a set of tools to process the set of \n",
      " |      documents collected and cleaned by the wiki crawler.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      collection_json (:obj:`str`): This is a filename to the scraped data.\n",
      " |          Each JSON document is expected to have following fields:\n",
      " |          - theme: Topic identifier, ex: Sustainability\n",
      " |          - theme.id: A unique category identifier\n",
      " |          - document.id: A unique document id\n",
      " |          - title: Title of the document\n",
      " |          - url: Full URL of the document\n",
      " |          - depth: The link distance from the seed docuement. The seed documents depth is 0.\n",
      " |          - text: The string data scraped from the page without tags. Pancuations are not \n",
      " |              required but terms are expected to be delineated by white space. \n",
      " |      collection (:obj:`list` of :obj:`dict`): Loaded json file into native list of dictionaries.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, collection)\n",
      " |      The class constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          collection (:obj:`str`): A filename to a previously scraped data.\n",
      " |  \n",
      " |  collate(self, by_theme_id=None, by_doc_ids=[], marker='\\n')\n",
      " |      The method collects the desired set of documents concatenates them creating a unified document.\n",
      " |          The order of merge is as follows:\n",
      " |          - When neither list of theme nor doc ids is provided, it collates entire text.\n",
      " |          - If a theme is given then all the documents under that theme are to be joined first.\n",
      " |          - When a list of docs is given, only those in the list are kept.\n",
      " |          Note that if both theme id and doc ids provided, precedence is on themes.\n",
      " |      \n",
      " |      Args:\n",
      " |          by_theme_id (:obj:`int`, optional): The theme id of the docs to be collated.\n",
      " |          by_doc_ids (:obj:`list` of :obj:`int`, optional): The list of doc ids to be collated (default Empty). \n",
      " |          marker (:obj:`str`, optional): A delimiter (default newline)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`str`): The collated text.\n",
      " |  \n",
      " |  display_documents_list(self, tid=None, stdout=True)\n",
      " |      List the articles meta data and crawling information on them.\n",
      " |      \n",
      " |      Args:\n",
      " |          tid (:obj:`int`, optional): Used if documents info under a specific theme is desired \n",
      " |              otherwise a summary of whole set is returned or displayed (default None).\n",
      " |          stdout (:obj:`bool`, optional): Whether the info is to be displayed/printed\n",
      " |              to standard io (default True).\n",
      " |              \n",
      " |      Returns:\n",
      " |          ( :obj:`list`): A summary list of documents in the collection.\n",
      " |  \n",
      " |  get_document_fields(self)\n",
      " |      The method lists the fields of each json field of its collection.\n",
      " |        \n",
      " |      Args:\n",
      " |          None  \n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`dict_keys`): List of keys.\n",
      " |          None: When the collection is empty.\n",
      " |  \n",
      " |  get_theme_id(self, theme_name)\n",
      " |      The method returns topic id of the first match theme name.\n",
      " |        \n",
      " |      Args:\n",
      " |          theme_name (:obj:`str`): The theme or topic name. \n",
      " |          \n",
      " |      Returns:\n",
      " |          ( :obj:`int`): A unique theme identifier.\n",
      " |  \n",
      " |  get_theme_title(self, theme_id)\n",
      " |      The method returns topic name.\n",
      " |        \n",
      " |      Args:\n",
      " |          theme_id (:obj:`int`): The unique theme id. \n",
      " |          \n",
      " |      Returns:\n",
      " |          ( :obj:`str`): Topic name.\n",
      " |  \n",
      " |  list_themes(self)\n",
      " |      The method lists the summary of themes/topics in the collection.\n",
      " |        \n",
      " |      Args:\n",
      " |          None  \n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list` of :obj:`dict`): List of dictionry where keys are\n",
      " |              - name: theme's textual descriptor\n",
      " |              - id: theme's unique id\n",
      " |              - count: number of articles under the theme.\n",
      " |  \n",
      " |  load_corpus(self, collection=None)\n",
      " |      The method loads imports json file into a native collection.\n",
      " |        \n",
      " |      Args:\n",
      " |          collection (:obj:`str`): A filename to a previously scraped data.\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  prune(self, themes_to_keep=[], docs_to_drop=[], istodrop=<function WikiArticles.<lambda> at 0x11115fbf8>)\n",
      " |      The method is used to filter out documents from the set.\n",
      " |          The order of prunning is as follows:\n",
      " |          - when a none empty list is provide all the documents not belonging themes to be kept\n",
      " |              are prunned entirely. Note that when initial list is empty it doesn't have an effect.\n",
      " |          - of remaing documents those appear in docs_to_drop are prunned\n",
      " |          - of the remaing docs those produce a True at a call on the predicate function are dropped.\n",
      " |          \n",
      " |          The function can be repeatedly called until a desired level of prunning is achieved.\n",
      " |      \n",
      " |      Args:\n",
      " |          themes_to_keep (:obj:`list` of :obj:`int`, optional): The list of theme ids to be kept (default Empty).\n",
      " |          docs_to_drop (:obj:`list`, optional): The list of doc ids to be dropt (default Empty). \n",
      " |          f (x :obj:`dict_item` -> :obj:`bool`, optional): A predicate function (default lambda x:False)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(WikiArticles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and preparing the WikiCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the corpus: 563\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'name': 'universalism', 'num_of_articles': 205},\n",
       " {'id': 2, 'name': 'hedonism', 'num_of_articles': 85},\n",
       " {'id': 3, 'name': 'achievement', 'num_of_articles': 46},\n",
       " {'id': 4, 'name': 'power', 'num_of_articles': 24},\n",
       " {'id': 5, 'name': 'self-direction', 'num_of_articles': 37},\n",
       " {'id': 6, 'name': 'benevolence', 'num_of_articles': 57},\n",
       " {'id': 7, 'name': 'conformity', 'num_of_articles': 42},\n",
       " {'id': 8, 'name': 'tradition', 'num_of_articles': 18},\n",
       " {'id': 9, 'name': 'stimulation', 'num_of_articles': 7},\n",
       " {'id': 10, 'name': 'security', 'num_of_articles': 32}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WIKI_DOCS = \"data/corpuses/schwartz.json\"\n",
    "WikiC = WikiArticles(WIKI_DOCS)\n",
    "WikiC.list_themes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the configuration paremeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"./output/\"\n",
    "OUTPUT_FNAME = \"schwartz.csv\"\n",
    "\n",
    "STOPWORDS_STANDARD = \"./data/stopwords_standard.txt\"\n",
    "STOPWORDS_SPECIFIC = \"./data/stopwords_openmaker.txt\"\n",
    "NOTALLOWED = tokenizer.CHARACTERS_TO_SPLIT\n",
    "TERMS_SPECIFIC = \"./data/specifics_openmaker.txt\"\n",
    "\n",
    "TOKENIZER_FUNC = tokenizer.tokenize_strip_non_words\n",
    "STEMMER_FUNC = porter\n",
    "\n",
    "MIN_LENGTH = 2\n",
    "MIN_FREQ = 3\n",
    "MODEL_THRESHOLD = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "\n",
      "Processing each topic ::>\n",
      "\n",
      "Topic = universalism\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 701497\n",
      "Cleaning process: Initial size of tokens = 701497\n",
      "Reduction due to punctuations and stopwords = 666886.\n",
      "Reduction due to all numeral terms = 601\n",
      "Reduction due to short terms = 267\n",
      "Reduction due to rare terms = 19485\n",
      "Reduction due to partially numeral terms = 42\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 687281\n",
      "Percentage = 98%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/universalism_schwartz.csv\n",
      "\n",
      "Topic = hedonism\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 210302\n",
      "Cleaning process: Initial size of tokens = 210302\n",
      "Reduction due to punctuations and stopwords = 193608.\n",
      "Reduction due to all numeral terms = 216\n",
      "Reduction due to short terms = 169\n",
      "Reduction due to rare terms = 9926\n",
      "Reduction due to partially numeral terms = 16\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 203935\n",
      "Percentage = 97%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/hedonism_schwartz.csv\n",
      "\n",
      "Topic = achievement\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 124988\n",
      "Cleaning process: Initial size of tokens = 124988\n",
      "Reduction due to punctuations and stopwords = 114578.\n",
      "Reduction due to all numeral terms = 211\n",
      "Reduction due to short terms = 64\n",
      "Reduction due to rare terms = 5830\n",
      "Reduction due to partially numeral terms = 14\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 120697\n",
      "Percentage = 97%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/achievement_schwartz.csv\n",
      "\n",
      "Topic = power\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 59284\n",
      "Cleaning process: Initial size of tokens = 59284\n",
      "Reduction due to punctuations and stopwords = 50484.\n",
      "Reduction due to all numeral terms = 90\n",
      "Reduction due to short terms = 62\n",
      "Reduction due to rare terms = 5766\n",
      "Reduction due to partially numeral terms = 17\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 56419\n",
      "Percentage = 95%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/power_schwartz.csv\n",
      "\n",
      "Topic = self-direction\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 88900\n",
      "Cleaning process: Initial size of tokens = 88900\n",
      "Reduction due to punctuations and stopwords = 78653.\n",
      "Reduction due to all numeral terms = 197\n",
      "Reduction due to short terms = 95\n",
      "Reduction due to rare terms = 6334\n",
      "Reduction due to partially numeral terms = 23\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 85302\n",
      "Percentage = 96%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/self-direction_schwartz.csv\n",
      "\n",
      "Topic = benevolence\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 156450\n",
      "Cleaning process: Initial size of tokens = 156450\n",
      "Reduction due to punctuations and stopwords = 141999.\n",
      "Reduction due to all numeral terms = 396\n",
      "Reduction due to short terms = 131\n",
      "Reduction due to rare terms = 8697\n",
      "Reduction due to partially numeral terms = 12\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 151235\n",
      "Percentage = 97%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/benevolence_schwartz.csv\n",
      "\n",
      "Topic = conformity\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 92224\n",
      "Cleaning process: Initial size of tokens = 92224\n",
      "Reduction due to punctuations and stopwords = 82395.\n",
      "Reduction due to all numeral terms = 74\n",
      "Reduction due to short terms = 86\n",
      "Reduction due to rare terms = 6008\n",
      "Reduction due to partially numeral terms = 7\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 88570\n",
      "Percentage = 96%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/conformity_schwartz.csv\n",
      "\n",
      "Topic = tradition\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 48257\n",
      "Cleaning process: Initial size of tokens = 48257\n",
      "Reduction due to punctuations and stopwords = 40348.\n",
      "Reduction due to all numeral terms = 66\n",
      "Reduction due to short terms = 62\n",
      "Reduction due to rare terms = 5509\n",
      "Reduction due to partially numeral terms = 5\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 45990\n",
      "Percentage = 95%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/tradition_schwartz.csv\n",
      "\n",
      "Topic = stimulation\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 29302\n",
      "Cleaning process: Initial size of tokens = 29302\n",
      "Reduction due to punctuations and stopwords = 23646.\n",
      "Reduction due to all numeral terms = 51\n",
      "Reduction due to short terms = 39\n",
      "Reduction due to rare terms = 4040\n",
      "Reduction due to partially numeral terms = 11\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 27787\n",
      "Percentage = 95%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/stimulation_schwartz.csv\n",
      "\n",
      "Topic = security\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 86698\n",
      "Cleaning process: Initial size of tokens = 86698\n",
      "Reduction due to punctuations and stopwords = 76712.\n",
      "Reduction due to all numeral terms = 78\n",
      "Reduction due to short terms = 82\n",
      "Reduction due to rare terms = 6225\n",
      "Reduction due to partially numeral terms = 8\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 83105\n",
      "Percentage = 96%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/security_schwartz.csv\n",
      "Results are exported to file: ./output/schwartz.csv\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(WikiC,\n",
    "                  tokenizer = TOKENIZER_FUNC,\n",
    "                  min_termlength = MIN_LENGTH,\n",
    "                  min_tf = MIN_FREQ,\n",
    "                  stemmer = STEMMER_FUNC,\n",
    "                  export = True,\n",
    "                  basefname = OUTPUT_FNAME,\n",
    "                  outputdir = OUTPUT_FOLDER, \n",
    "                  notallowed_symbols = NOTALLOWED,\n",
    "                  nonremovable_terms = TERMS_SPECIFIC,\n",
    "                  file_standard_stopwords = STOPWORDS_STANDARD,\n",
    "                  file_specific_sopwords = STOPWORDS_SPECIFIC,\n",
    "                  regression_threshold = MODEL_THRESHOLD\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Ach-TF</th>\n",
       "      <th>Ach-wTF</th>\n",
       "      <th>Ben-TF</th>\n",
       "      <th>Ben-wTF</th>\n",
       "      <th>Con-TF</th>\n",
       "      <th>Con-wTF</th>\n",
       "      <th>Hed-TF</th>\n",
       "      <th>Hed-wTF</th>\n",
       "      <th>Pow-TF</th>\n",
       "      <th>...</th>\n",
       "      <th>Sec-TF</th>\n",
       "      <th>Sec-wTF</th>\n",
       "      <th>Sel-TF</th>\n",
       "      <th>Sel-wTF</th>\n",
       "      <th>Sti-TF</th>\n",
       "      <th>Sti-wTF</th>\n",
       "      <th>Tra-TF</th>\n",
       "      <th>Tra-wTF</th>\n",
       "      <th>Uni-TF</th>\n",
       "      <th>Uni-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18495</th>\n",
       "      <td>zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18496</th>\n",
       "      <td>zurvanism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18497</th>\n",
       "      <td>zygmunt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18498</th>\n",
       "      <td>zygote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18499</th>\n",
       "      <td>zzz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Term  Ach-TF   Ach-wTF  Ben-TF  Ben-wTF  Con-TF  Con-wTF  Hed-TF  \\\n",
       "18495     zurich     NaN       NaN     NaN      NaN     NaN      NaN     NaN   \n",
       "18496  zurvanism     NaN       NaN     NaN      NaN     NaN      NaN     NaN   \n",
       "18497    zygmunt     3.0  0.000046     NaN      NaN     NaN      NaN     NaN   \n",
       "18498     zygote     NaN       NaN     NaN      NaN     NaN      NaN     NaN   \n",
       "18499        zzz     NaN       NaN     NaN      NaN     NaN      NaN     NaN   \n",
       "\n",
       "       Hed-wTF  Pow-TF    ...     Sec-TF  Sec-wTF  Sel-TF   Sel-wTF  Sti-TF  \\\n",
       "18495      NaN     3.0    ...        NaN      NaN     NaN       NaN     NaN   \n",
       "18496      NaN     NaN    ...        NaN      NaN     NaN       NaN     NaN   \n",
       "18497      NaN     NaN    ...        NaN      NaN     NaN       NaN     NaN   \n",
       "18498      NaN     NaN    ...        NaN      NaN     NaN       NaN     NaN   \n",
       "18499      NaN     NaN    ...        NaN      NaN     3.0  0.000068     NaN   \n",
       "\n",
       "       Sti-wTF  Tra-TF  Tra-wTF  Uni-TF   Uni-wTF  \n",
       "18495      NaN     NaN      NaN     NaN       NaN  \n",
       "18496      NaN     NaN      NaN     4.0  0.000010  \n",
       "18497      NaN     NaN      NaN     NaN       NaN  \n",
       "18498      NaN     NaN      NaN     3.0  0.000008  \n",
       "18499      NaN     NaN      NaN     NaN       NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "Term extraction on the combined text from collection is requested.\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 1597902\n",
      "Cleaning process: Initial size of tokens = 1597902\n",
      "Reduction due to punctuations and stopwords = 1543723.\n",
      "Reduction due to all numeral terms = 1219\n",
      "Reduction due to short terms = 423\n",
      "Reduction due to rare terms = 29708\n",
      "Reduction due to partially numeral terms = 80\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 1575153\n",
      "Percentage = 99%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(WikiC,\n",
    "                  tokenizer = TOKENIZER_FUNC,\n",
    "                  merge = True,\n",
    "                  min_termlength = MIN_LENGTH,\n",
    "                  min_tf = MIN_FREQ,\n",
    "                  extra_process = ['stem'],\n",
    "                  stemmer = STEMMER_FUNC,\n",
    "                  notallowed_symbols = NOTALLOWED,\n",
    "                  nonremovable_terms = TERMS_SPECIFIC,\n",
    "                  file_standard_stopwords = STOPWORDS_STANDARD,\n",
    "                  file_specific_sopwords = STOPWORDS_SPECIFIC,\n",
    "                  regression_threshold = MODEL_THRESHOLD\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>4461</td>\n",
       "      <td>social</td>\n",
       "      <td>social</td>\n",
       "      <td>0.005068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2970</td>\n",
       "      <td>people</td>\n",
       "      <td>peopl</td>\n",
       "      <td>0.003374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>2845</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>0.003232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2254</td>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>0.002561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>2230</td>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>0.002534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>1942</td>\n",
       "      <td>environmental</td>\n",
       "      <td>environment</td>\n",
       "      <td>0.002206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>1893</td>\n",
       "      <td>states</td>\n",
       "      <td>state</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1870</td>\n",
       "      <td>theory</td>\n",
       "      <td>theori</td>\n",
       "      <td>0.002125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1759</td>\n",
       "      <td>used</td>\n",
       "      <td>use</td>\n",
       "      <td>0.001998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>1736</td>\n",
       "      <td>united</td>\n",
       "      <td>unit</td>\n",
       "      <td>0.001972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TF           Term         Stem       wTF\n",
       "1011  4461         social       social  0.005068\n",
       "101   2970         people        peopl  0.003374\n",
       "419   2845          human        human  0.003232\n",
       "381   2254          world        world  0.002561\n",
       "892   2230            new          new  0.002534\n",
       "895   1942  environmental  environment  0.002206\n",
       "1023  1893         states        state  0.002151\n",
       "279   1870         theory       theori  0.002125\n",
       "742   1759           used          use  0.001998\n",
       "1022  1736         united         unit  0.001972"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "Preparing the reference corpus ::>\n",
      "Comparions/Scoring is requested but no reference corpus text or tokens is provided.\n",
      "Loading nltk.corpus.brown ...\n",
      "Cleaning the reference corpus ...\n",
      "Cleaning process: Initial size of tokens = 1161192\n",
      "Reduction due to punctuations and stopwords = 1111606.\n",
      "Reduction due to all numeral terms = 1747\n",
      "Reduction due to short terms = 178\n",
      "Reduction due to rare terms = 27810\n",
      "Reduction due to partially numeral terms = 49\n",
      "Reduction due to terms with not allowed symbols = 645\n",
      "The total term count reduction during this cleaning process = 1142035\n",
      "Percentage = 98%\n",
      "Stemming the word in the reference corpus ...\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "Done: Reference corpus process.\n",
      "\n",
      "Processing each topic ::>\n",
      "\n",
      "Topic = power\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 59284\n",
      "Cleaning process: Initial size of tokens = 59284\n",
      "Reduction due to punctuations and stopwords = 50484.\n",
      "Reduction due to all numeral terms = 90\n",
      "Reduction due to short terms = 62\n",
      "Reduction due to rare terms = 5766\n",
      "Reduction due to partially numeral terms = 17\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 56419\n",
      "Percentage = 95%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "2517 / 2865  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "348 / 2865 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "84 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/power_schwartz.csv\n",
      "\n",
      "Topic = universalism\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 701497\n",
      "Cleaning process: Initial size of tokens = 701497\n",
      "Reduction due to punctuations and stopwords = 666886.\n",
      "Reduction due to all numeral terms = 601\n",
      "Reduction due to short terms = 267\n",
      "Reduction due to rare terms = 19485\n",
      "Reduction due to partially numeral terms = 42\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 687281\n",
      "Percentage = 98%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "8950 / 14216  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "5266 / 14216 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "1261 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/universalism_schwartz.csv\n",
      "Results are exported to file: ./output/schwartz.csv\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(WikiC,\n",
    "                  tokenizer = TOKENIZER_FUNC,\n",
    "                  merge = False,\n",
    "                  min_termlength = MIN_LENGTH,\n",
    "                  min_tf = MIN_FREQ,\n",
    "                  topics = ['power', 'universalism'],\n",
    "                  extra_process = ['stem', 'compare'],\n",
    "                  stemmer = STEMMER_FUNC,\n",
    "                  refcorpus = None,\n",
    "                  export = True,\n",
    "                  basefname = OUTPUT_FNAME,\n",
    "                  outputdir = OUTPUT_FOLDER, \n",
    "                  notallowed_symbols = NOTALLOWED,\n",
    "                  nonremovable_terms = TERMS_SPECIFIC,\n",
    "                  file_standard_stopwords = STOPWORDS_STANDARD,\n",
    "                  file_specific_sopwords = STOPWORDS_SPECIFIC,\n",
    "                  regression_threshold = MODEL_THRESHOLD\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTFref</th>\n",
       "      <th>SType</th>\n",
       "      <th>Pow-Score</th>\n",
       "      <th>Pow-TF</th>\n",
       "      <th>Pow-wTF</th>\n",
       "      <th>Uni-Score</th>\n",
       "      <th>Uni-TF</th>\n",
       "      <th>Uni-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13949</th>\n",
       "      <td>veto</td>\n",
       "      <td>veto</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.136333</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>collapse</td>\n",
       "      <td>collaps</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.082428</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>1.543837</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7019</th>\n",
       "      <td>islamic</td>\n",
       "      <td>islam</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.799861</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>3.700468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>citation</td>\n",
       "      <td>citat</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.678500</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>4.240464</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.000743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9478</th>\n",
       "      <td>participants</td>\n",
       "      <td>particip</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.545627</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>2.160023</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6888</th>\n",
       "      <td>interpersonal</td>\n",
       "      <td>interperson</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.463388</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.887058</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14165</th>\n",
       "      <td>wealth</td>\n",
       "      <td>wealth</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.445039</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>1.521709</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9022</th>\n",
       "      <td>obedience</td>\n",
       "      <td>obedi</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.440916</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>-0.057404</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13061</th>\n",
       "      <td>template</td>\n",
       "      <td>templat</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.380007</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>3.540300</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>portal</td>\n",
       "      <td>portal</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.320288</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>4.189048</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Term         Stem    wTFref SType  Pow-Score  Pow-TF  \\\n",
       "13949           veto         veto  0.000021   raw   5.136333    98.0   \n",
       "2378        collapse      collaps  0.000015   raw   5.082428    65.0   \n",
       "7019         islamic        islam  0.000006   raw   4.799861    21.0   \n",
       "2212        citation        citat  0.000011   raw   4.678500    31.0   \n",
       "9478    participants     particip  0.000015   raw   4.545627    38.0   \n",
       "6888   interpersonal  interperson  0.000006   raw   4.463388    15.0   \n",
       "14165         wealth       wealth  0.000047   raw   4.445039   108.0   \n",
       "9022       obedience        obedi  0.000019   raw   4.440916    44.0   \n",
       "13061       template      templat  0.000011   raw   4.380007    23.0   \n",
       "9979          portal       portal  0.000006   raw   4.320288    13.0   \n",
       "\n",
       "        Pow-wTF  Uni-Score  Uni-TF   Uni-wTF  \n",
       "13949  0.003642        NaN     NaN       NaN  \n",
       "2378   0.002416   1.543837    27.0  0.000070  \n",
       "7019   0.000780   3.700468   100.0  0.000260  \n",
       "2212   0.001152   4.240464   286.0  0.000743  \n",
       "9478   0.001412   2.160023    50.0  0.000130  \n",
       "6888   0.000557   0.887058     6.0  0.000016  \n",
       "14165  0.004014   1.521709    83.0  0.000216  \n",
       "9022   0.001635  -0.057404     7.0  0.000018  \n",
       "13061  0.000855   3.540300   142.0  0.000369  \n",
       "9979   0.000483   4.189048   163.0  0.000424  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = 'Pow-Score', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTFref</th>\n",
       "      <th>SType</th>\n",
       "      <th>Pow-Score</th>\n",
       "      <th>Pow-TF</th>\n",
       "      <th>Pow-wTF</th>\n",
       "      <th>Uni-Score</th>\n",
       "      <th>Uni-TF</th>\n",
       "      <th>Uni-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>environmental</td>\n",
       "      <td>environment</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>raw</td>\n",
       "      <td>3.105265</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>5.718224</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>0.004562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>global</td>\n",
       "      <td>global</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>raw</td>\n",
       "      <td>3.952563</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>5.194495</td>\n",
       "      <td>594.0</td>\n",
       "      <td>0.001544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13973</th>\n",
       "      <td>vietnam</td>\n",
       "      <td>vietnam</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>2.853951</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>4.789030</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.000772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7367</th>\n",
       "      <td>labour</td>\n",
       "      <td>labour</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>raw</td>\n",
       "      <td>3.770241</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>4.391112</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>citation</td>\n",
       "      <td>citat</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.678500</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>4.240464</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.000743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>enlightenment</td>\n",
       "      <td>enlighten</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>stem</td>\n",
       "      <td>2.630807</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>4.229919</td>\n",
       "      <td>283.0</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8909</th>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>raw</td>\n",
       "      <td>3.918661</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>4.195774</td>\n",
       "      <td>547.0</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>portal</td>\n",
       "      <td>portal</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.320288</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>4.189048</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>islam</td>\n",
       "      <td>islam</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>3.834780</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>4.145154</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.000406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>hindu</td>\n",
       "      <td>hindu</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.078905</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.000380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Term         Stem    wTFref SType  Pow-Score  Pow-TF  \\\n",
       "4520   environmental  environment  0.000015   raw   3.105265     9.0   \n",
       "5668          global       global  0.000009   raw   3.952563    12.0   \n",
       "13973        vietnam      vietnam  0.000006   raw   2.853951     3.0   \n",
       "7367          labour       labour  0.000009   raw   3.770241    10.0   \n",
       "2212        citation        citat  0.000011   raw   4.678500    31.0   \n",
       "4466   enlightenment    enlighten  0.000011  stem   2.630807     4.0   \n",
       "8909             non          non  0.000021   raw   3.918661    29.0   \n",
       "9979          portal       portal  0.000006   raw   4.320288    13.0   \n",
       "7018           islam        islam  0.000006   raw   3.834780     8.0   \n",
       "6145           hindu        hindu  0.000006   raw        NaN     NaN   \n",
       "\n",
       "        Pow-wTF  Uni-Score  Uni-TF   Uni-wTF  \n",
       "4520   0.000334   5.718224  1755.0  0.004562  \n",
       "5668   0.000446   5.194495   594.0  0.001544  \n",
       "13973  0.000111   4.789030   297.0  0.000772  \n",
       "7367   0.000372   4.391112   266.0  0.000691  \n",
       "2212   0.001152   4.240464   286.0  0.000743  \n",
       "4466   0.000149   4.229919   283.0  0.000736  \n",
       "8909   0.001078   4.195774   547.0  0.001422  \n",
       "9979   0.000483   4.189048   163.0  0.000424  \n",
       "7018   0.000297   4.145154   156.0  0.000406  \n",
       "6145        NaN   4.078905   146.0  0.000380  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = 'Uni-Score', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTFref</th>\n",
       "      <th>SType</th>\n",
       "      <th>Pow-Score</th>\n",
       "      <th>Pow-TF</th>\n",
       "      <th>Pow-wTF</th>\n",
       "      <th>Uni-Score</th>\n",
       "      <th>Uni-TF</th>\n",
       "      <th>Uni-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13949</th>\n",
       "      <td>veto</td>\n",
       "      <td>veto</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.136333</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>collapse</td>\n",
       "      <td>collaps</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.082428</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>1.543837</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7019</th>\n",
       "      <td>islamic</td>\n",
       "      <td>islam</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.799861</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>3.700468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>citation</td>\n",
       "      <td>citat</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.678500</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>4.240464</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.000743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9478</th>\n",
       "      <td>participants</td>\n",
       "      <td>particip</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.545627</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>2.160023</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6888</th>\n",
       "      <td>interpersonal</td>\n",
       "      <td>interperson</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.463388</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.887058</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14165</th>\n",
       "      <td>wealth</td>\n",
       "      <td>wealth</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.445039</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>1.521709</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9022</th>\n",
       "      <td>obedience</td>\n",
       "      <td>obedi</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.440916</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>-0.057404</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13061</th>\n",
       "      <td>template</td>\n",
       "      <td>templat</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.380007</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>3.540300</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>portal</td>\n",
       "      <td>portal</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.320288</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>4.189048</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8290</th>\n",
       "      <td>mid</td>\n",
       "      <td>mid</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.320288</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>3.777429</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14407</th>\n",
       "      <td>wrought</td>\n",
       "      <td>wrought</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.240245</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.704736</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001</th>\n",
       "      <td>shocks</td>\n",
       "      <td>shock</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.240245</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>citations</td>\n",
       "      <td>citat</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>stem</td>\n",
       "      <td>4.188952</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>3.428660</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4827</th>\n",
       "      <td>experimenter</td>\n",
       "      <td>experiment</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.188952</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>assent</td>\n",
       "      <td>assent</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.175706</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.887058</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>dominance</td>\n",
       "      <td>domin</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.144935</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.686387</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>computers</td>\n",
       "      <td>comput</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.077726</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.376232</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10316</th>\n",
       "      <td>productivity</td>\n",
       "      <td>product</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.063789</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.496191</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6844</th>\n",
       "      <td>interactions</td>\n",
       "      <td>interact</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.057923</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>3.084282</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Term         Stem    wTFref SType  Pow-Score  Pow-TF  \\\n",
       "13949           veto         veto  0.000021   raw   5.136333    98.0   \n",
       "2378        collapse      collaps  0.000015   raw   5.082428    65.0   \n",
       "7019         islamic        islam  0.000006   raw   4.799861    21.0   \n",
       "2212        citation        citat  0.000011   raw   4.678500    31.0   \n",
       "9478    participants     particip  0.000015   raw   4.545627    38.0   \n",
       "6888   interpersonal  interperson  0.000006   raw   4.463388    15.0   \n",
       "14165         wealth       wealth  0.000047   raw   4.445039   108.0   \n",
       "9022       obedience        obedi  0.000019   raw   4.440916    44.0   \n",
       "13061       template      templat  0.000011   raw   4.380007    23.0   \n",
       "9979          portal       portal  0.000006   raw   4.320288    13.0   \n",
       "8290             mid          mid  0.000006   raw   4.320288    13.0   \n",
       "14407        wrought      wrought  0.000006   raw   4.240245    12.0   \n",
       "12001         shocks        shock  0.000011   raw   4.240245    20.0   \n",
       "2213       citations        citat  0.000011  stem   4.188952    19.0   \n",
       "4827    experimenter   experiment  0.000011   raw   4.188952    19.0   \n",
       "932           assent       assent  0.000009   raw   4.175706    15.0   \n",
       "3947       dominance        domin  0.000024   raw   4.144935    40.0   \n",
       "2584       computers       comput  0.000011   raw   4.077726    17.0   \n",
       "10316   productivity      product  0.000036   raw   4.063789    57.0   \n",
       "6844    interactions     interact  0.000006   raw   4.057923    10.0   \n",
       "\n",
       "        Pow-wTF  Uni-Score  Uni-TF   Uni-wTF  \n",
       "13949  0.003642        NaN     NaN       NaN  \n",
       "2378   0.002416   1.543837    27.0  0.000070  \n",
       "7019   0.000780   3.700468   100.0  0.000260  \n",
       "2212   0.001152   4.240464   286.0  0.000743  \n",
       "9478   0.001412   2.160023    50.0  0.000130  \n",
       "6888   0.000557   0.887058     6.0  0.000016  \n",
       "14165  0.004014   1.521709    83.0  0.000216  \n",
       "9022   0.001635  -0.057404     7.0  0.000018  \n",
       "13061  0.000855   3.540300   142.0  0.000369  \n",
       "9979   0.000483   4.189048   163.0  0.000424  \n",
       "8290   0.000483   3.777429   108.0  0.000281  \n",
       "14407  0.000446   0.704736     5.0  0.000013  \n",
       "12001  0.000743        NaN     NaN       NaN  \n",
       "2213   0.000706   3.428660   127.0  0.000330  \n",
       "4827   0.000706        NaN     NaN       NaN  \n",
       "932    0.000557   0.887058     8.0  0.000021  \n",
       "3947   0.001487   0.686387    18.0  0.000047  \n",
       "2584   0.000632   0.376232     6.0  0.000016  \n",
       "10316  0.002118   0.496191    23.0  0.000060  \n",
       "6844   0.000372   3.084282    54.0  0.000140  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = ['Pow-Score','Uni-Score'], ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic by topic and Custom Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing  modules from omterm package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from omterms import tokenizer\n",
    "from omterms.datauis import WikiArticles, Corpus\n",
    "from omterms.cleaner import TextCleaner\n",
    "from omterms.measures import Scoring\n",
    "from omterms.utilities import *\n",
    "from omterms.stemmer import porter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing a crawled Wikipedia collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Loading and examining harvested Wikipedia articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class WikiArticles in module omterms.datauis:\n",
      "\n",
      "class WikiArticles(builtins.object)\n",
      " |  The object contains a set of tools to process the set of \n",
      " |      documents collected and cleaned by the wiki crawler.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      collection_json (:obj:`str`): This is a filename to the scraped data.\n",
      " |          Each JSON document is expected to have following fields:\n",
      " |          - theme: Topic identifier, ex: Sustainability\n",
      " |          - theme.id: A unique category identifier\n",
      " |          - document.id: A unique document id\n",
      " |          - title: Title of the document\n",
      " |          - url: Full URL of the document\n",
      " |          - depth: The link distance from the seed docuement. The seed documents depth is 0.\n",
      " |          - text: The string data scraped from the page without tags. Pancuations are not \n",
      " |              required but terms are expected to be delineated by white space. \n",
      " |      collection (:obj:`list` of :obj:`dict`): Loaded json file into native list of dictionaries.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, collection)\n",
      " |      The class constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          collection (:obj:`str`): A filename to a previously scraped data.\n",
      " |  \n",
      " |  collate(self, by_theme_id=None, by_doc_ids=[], marker='\\n')\n",
      " |      The method collects the desired set of documents concatenates them creating a unified document.\n",
      " |          The order of merge is as follows:\n",
      " |          - When neither list of theme nor doc ids is provided, it collates entire text.\n",
      " |          - If a theme is given then all the documents under that theme are to be joined first.\n",
      " |          - When a list of docs is given, only those in the list are kept.\n",
      " |          Note that if both theme id and doc ids provided, precedence is on themes.\n",
      " |      \n",
      " |      Args:\n",
      " |          by_theme_id (:obj:`int`, optional): The theme id of the docs to be collated.\n",
      " |          by_doc_ids (:obj:`list` of :obj:`int`, optional): The list of doc ids to be collated (default Empty). \n",
      " |          marker (:obj:`str`, optional): A delimiter (default newline)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`str`): The collated text.\n",
      " |  \n",
      " |  display_documents_list(self, tid=None, stdout=True)\n",
      " |      List the articles meta data and crawling information on them.\n",
      " |      \n",
      " |      Args:\n",
      " |          tid (:obj:`int`, optional): Used if documents info under a specific theme is desired \n",
      " |              otherwise a summary of whole set is returned or displayed (default None).\n",
      " |          stdout (:obj:`bool`, optional): Whether the info is to be displayed/printed\n",
      " |              to standard io (default True).\n",
      " |              \n",
      " |      Returns:\n",
      " |          ( :obj:`list`): A summary list of documents in the collection.\n",
      " |  \n",
      " |  get_document_fields(self)\n",
      " |      The method lists the fields of each json field of its collection.\n",
      " |        \n",
      " |      Args:\n",
      " |          None  \n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`dict_keys`): List of keys.\n",
      " |          None: When the collection is empty.\n",
      " |  \n",
      " |  get_theme_id(self, theme_name)\n",
      " |      The method returns topic id of the first match theme name.\n",
      " |        \n",
      " |      Args:\n",
      " |          theme_name (:obj:`str`): The theme or topic name. \n",
      " |          \n",
      " |      Returns:\n",
      " |          ( :obj:`int`): A unique theme identifier.\n",
      " |  \n",
      " |  get_theme_title(self, theme_id)\n",
      " |      The method returns topic name.\n",
      " |        \n",
      " |      Args:\n",
      " |          theme_id (:obj:`int`): The unique theme id. \n",
      " |          \n",
      " |      Returns:\n",
      " |          ( :obj:`str`): Topic name.\n",
      " |  \n",
      " |  list_themes(self)\n",
      " |      The method lists the summary of themes/topics in the collection.\n",
      " |        \n",
      " |      Args:\n",
      " |          None  \n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list` of :obj:`dict`): List of dictionry where keys are\n",
      " |              - name: theme's textual descriptor\n",
      " |              - id: theme's unique id\n",
      " |              - count: number of articles under the theme.\n",
      " |  \n",
      " |  load_corpus(self, collection=None)\n",
      " |      The method loads imports json file into a native collection.\n",
      " |        \n",
      " |      Args:\n",
      " |          collection (:obj:`str`): A filename to a previously scraped data.\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  prune(self, themes_to_keep=[], docs_to_drop=[], istodrop=<function WikiArticles.<lambda> at 0x11115fbf8>)\n",
      " |      The method is used to filter out documents from the set.\n",
      " |          The order of prunning is as follows:\n",
      " |          - when a none empty list is provide all the documents not belonging themes to be kept\n",
      " |              are prunned entirely. Note that when initial list is empty it doesn't have an effect.\n",
      " |          - of remaing documents those appear in docs_to_drop are prunned\n",
      " |          - of the remaing docs those produce a True at a call on the predicate function are dropped.\n",
      " |          \n",
      " |          The function can be repeatedly called until a desired level of prunning is achieved.\n",
      " |      \n",
      " |      Args:\n",
      " |          themes_to_keep (:obj:`list` of :obj:`int`, optional): The list of theme ids to be kept (default Empty).\n",
      " |          docs_to_drop (:obj:`list`, optional): The list of doc ids to be dropt (default Empty). \n",
      " |          f (x :obj:`dict_item` -> :obj:`bool`, optional): A predicate function (default lambda x:False)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(WikiArticles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the corpus: 563\n",
      "\n",
      "10562749\n"
     ]
    }
   ],
   "source": [
    "# Loading:\n",
    "WikiC = WikiArticles(WIKI_DOCS)\n",
    "print(len(WikiC.collate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output file prefix: Power\n"
     ]
    }
   ],
   "source": [
    "# Selecting a specific topic\n",
    "TOPIC_NAME = 'power'\n",
    "TOPIC_ID = WikiC.get_theme_id(TOPIC_NAME)\n",
    "OUTPUT_FNAME_PREFIX = format_output_fname(TOPIC_NAME)\n",
    "print('The output file prefix: {}'.format(OUTPUT_FNAME_PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['theme', 'theme.id', 'document.id', 'title', 'url', 'depth', 'text'])\n",
      "4\n",
      "power\n"
     ]
    }
   ],
   "source": [
    "# Getting fields name on each document in the collection\n",
    "print(WikiC.get_document_fields())\n",
    "print(WikiC.get_theme_id(TOPIC_NAME))\n",
    "print(WikiC.get_theme_title(TOPIC_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Filtering out by a set of use case creteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function prune in module omterms.datauis:\n",
      "\n",
      "prune(self, themes_to_keep=[], docs_to_drop=[], istodrop=<function WikiArticles.<lambda> at 0x11115fbf8>)\n",
      "    The method is used to filter out documents from the set.\n",
      "        The order of prunning is as follows:\n",
      "        - when a none empty list is provide all the documents not belonging themes to be kept\n",
      "            are prunned entirely. Note that when initial list is empty it doesn't have an effect.\n",
      "        - of remaing documents those appear in docs_to_drop are prunned\n",
      "        - of the remaing docs those produce a True at a call on the predicate function are dropped.\n",
      "        \n",
      "        The function can be repeatedly called until a desired level of prunning is achieved.\n",
      "    \n",
      "    Args:\n",
      "        themes_to_keep (:obj:`list` of :obj:`int`, optional): The list of theme ids to be kept (default Empty).\n",
      "        docs_to_drop (:obj:`list`, optional): The list of doc ids to be dropt (default Empty). \n",
      "        f (x :obj:`dict_item` -> :obj:`bool`, optional): A predicate function (default lambda x:False)\n",
      "        \n",
      "    Returns:\n",
      "        (:obj:`bool`): True.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(WikiArticles.prune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document.id :: theme.id :: theme :: depth :: url\n",
      "19 4 power 0 https://en.wikipedia.org/wiki/Power_(social_and_political)\n",
      "21 4 power 0 https://en.wikipedia.org/wiki/Authority\n",
      "361 4 power 0 https://en.wikipedia.org/wiki/Wealth\n",
      "54 4 power 1 https://en.wikipedia.org/wiki/The_Anatomy_of_Revolution\n",
      "55 4 power 1 https://en.wikipedia.org/wiki/Personal_boundaries\n",
      "56 4 power 1 https://en.wikipedia.org/wiki/State_collapse\n",
      "57 4 power 1 https://en.wikipedia.org/wiki/Discourse_of_power\n",
      "58 4 power 1 https://en.wikipedia.org/wiki/Speaking_truth_to_power\n",
      "59 4 power 1 https://en.wikipedia.org/wiki/Amity-enmity_complex\n",
      "60 4 power 1 https://en.wikipedia.org/wiki/Social_control\n",
      "66 4 power 1 https://en.wikipedia.org/wiki/Veto\n",
      "67 4 power 1 https://en.wikipedia.org/wiki/Cognitive_authority\n",
      "69 4 power 1 https://en.wikipedia.org/wiki/Cratology\n",
      "70 4 power 1 https://en.wikipedia.org/wiki/Appeal_to_authority\n",
      "71 4 power 1 https://en.wikipedia.org/wiki/Religious_authority\n",
      "72 4 power 1 https://en.wikipedia.org/wiki/Authority_(management)\n",
      "73 4 power 1 https://en.wikipedia.org/wiki/Petty_authority\n",
      "74 4 power 1 https://en.wikipedia.org/wiki/Milgram_experiment\n",
      "75 4 power 1 https://en.wikipedia.org/wiki/Anti-authoritarianism\n",
      "76 4 power 1 https://en.wikipedia.org/wiki/Dominance_(ethology)\n",
      "77 4 power 1 https://en.wikipedia.org/wiki/Control_of_time_in_power_relationships\n",
      "82 4 power 1 https://en.wikipedia.org/wiki/Authoritarianism\n",
      "368 4 power 1 https://en.wikipedia.org/wiki/Gross_National_Happiness\n",
      "371 4 power 1 https://en.wikipedia.org/wiki/Happiness_economics\n",
      "374 4 power 1 https://en.wikipedia.org/wiki/Productivity_improving_technologies_(historical)\n",
      "document.id :: theme.id :: theme :: depth :: url\n",
      "19 4 power 0 https://en.wikipedia.org/wiki/Power_(social_and_political)\n",
      "21 4 power 0 https://en.wikipedia.org/wiki/Authority\n"
     ]
    }
   ],
   "source": [
    "# Some random prunning\n",
    "WikiC.prune(themes_to_keep = [TOPIC_ID])\n",
    "WikiC.display_documents_list(tid=TOPIC_ID, stdout = True)\n",
    "DOCS = [19,21]\n",
    "WikiC.prune(istodrop = lambda x: x['document.id'] not in DOCS)\n",
    "WikiC.display_documents_list()\n",
    "TEXT = WikiC.collate(by_theme_id = TOPIC_ID, by_doc_ids = DOCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the corpus: 563\n",
      "\n",
      "document.id :: theme.id :: theme :: depth :: url\n",
      "19 4 power 0 https://en.wikipedia.org/wiki/Power_(social_and_political)\n",
      "21 4 power 0 https://en.wikipedia.org/wiki/Authority\n",
      "361 4 power 0 https://en.wikipedia.org/wiki/Wealth\n",
      "57 4 power 1 https://en.wikipedia.org/wiki/Discourse_of_power\n",
      "58 4 power 1 https://en.wikipedia.org/wiki/Speaking_truth_to_power\n",
      "59 4 power 1 https://en.wikipedia.org/wiki/Amity-enmity_complex\n",
      "60 4 power 1 https://en.wikipedia.org/wiki/Social_control\n",
      "66 4 power 1 https://en.wikipedia.org/wiki/Veto\n",
      "67 4 power 1 https://en.wikipedia.org/wiki/Cognitive_authority\n",
      "69 4 power 1 https://en.wikipedia.org/wiki/Cratology\n",
      "70 4 power 1 https://en.wikipedia.org/wiki/Appeal_to_authority\n",
      "71 4 power 1 https://en.wikipedia.org/wiki/Religious_authority\n",
      "72 4 power 1 https://en.wikipedia.org/wiki/Authority_(management)\n",
      "73 4 power 1 https://en.wikipedia.org/wiki/Petty_authority\n",
      "74 4 power 1 https://en.wikipedia.org/wiki/Milgram_experiment\n",
      "75 4 power 1 https://en.wikipedia.org/wiki/Anti-authoritarianism\n",
      "76 4 power 1 https://en.wikipedia.org/wiki/Dominance_(ethology)\n",
      "77 4 power 1 https://en.wikipedia.org/wiki/Control_of_time_in_power_relationships\n",
      "82 4 power 1 https://en.wikipedia.org/wiki/Authoritarianism\n",
      "368 4 power 1 https://en.wikipedia.org/wiki/Gross_National_Happiness\n",
      "371 4 power 1 https://en.wikipedia.org/wiki/Happiness_economics\n",
      "374 4 power 1 https://en.wikipedia.org/wiki/Productivity_improving_technologies_(historical)\n",
      "document.id :: theme.id :: theme :: depth :: url\n",
      "19 4 power 0 https://en.wikipedia.org/wiki/Power_(social_and_political)\n",
      "21 4 power 0 https://en.wikipedia.org/wiki/Authority\n",
      "57 4 power 1 https://en.wikipedia.org/wiki/Discourse_of_power\n",
      "58 4 power 1 https://en.wikipedia.org/wiki/Speaking_truth_to_power\n",
      "59 4 power 1 https://en.wikipedia.org/wiki/Amity-enmity_complex\n",
      "60 4 power 1 https://en.wikipedia.org/wiki/Social_control\n",
      "66 4 power 1 https://en.wikipedia.org/wiki/Veto\n",
      "67 4 power 1 https://en.wikipedia.org/wiki/Cognitive_authority\n",
      "69 4 power 1 https://en.wikipedia.org/wiki/Cratology\n",
      "70 4 power 1 https://en.wikipedia.org/wiki/Appeal_to_authority\n",
      "71 4 power 1 https://en.wikipedia.org/wiki/Religious_authority\n",
      "72 4 power 1 https://en.wikipedia.org/wiki/Authority_(management)\n",
      "73 4 power 1 https://en.wikipedia.org/wiki/Petty_authority\n",
      "74 4 power 1 https://en.wikipedia.org/wiki/Milgram_experiment\n",
      "75 4 power 1 https://en.wikipedia.org/wiki/Anti-authoritarianism\n",
      "76 4 power 1 https://en.wikipedia.org/wiki/Dominance_(ethology)\n",
      "77 4 power 1 https://en.wikipedia.org/wiki/Control_of_time_in_power_relationships\n",
      "82 4 power 1 https://en.wikipedia.org/wiki/Authoritarianism\n",
      "368 4 power 1 https://en.wikipedia.org/wiki/Gross_National_Happiness\n",
      "371 4 power 1 https://en.wikipedia.org/wiki/Happiness_economics\n",
      "document.id :: theme.id :: theme :: depth :: url\n",
      "19 4 power 0 https://en.wikipedia.org/wiki/Power_(social_and_political)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'depth': 0,\n",
       "  'document.id': 19,\n",
       "  'theme': 'power',\n",
       "  'theme.id': 4,\n",
       "  'title': 'Power (social and political)',\n",
       "  'url': 'https://en.wikipedia.org/wiki/Power_(social_and_political)'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some more random prunning examples\n",
    "WikiC = WikiArticles(WIKI_DOCS)\n",
    "WikiC.prune(themes_to_keep = [TOPIC_ID],\n",
    "            docs_to_drop = [54, 55,56],\n",
    "            istodrop = lambda x: not 0 <= x['depth'] < 2)\n",
    "WikiC.display_documents_list()\n",
    "WikiC.prune(docs_to_drop = [374,361,255])\n",
    "WikiC.display_documents_list()\n",
    "WikiC.prune(istodrop = lambda x: len(x['text']) < 10000 or x['depth'] == 1 )\n",
    "WikiC.display_documents_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Joining a subset of articles within a topic for further analysis.\n",
    "\n",
    "It should be noted such document unification is a convenience if tokenization, frequency counts etc are done around a single topic. In other words, if the corpus holds a large set of documents and $tf$ $x$ $idf$ style examinations are intended, then merging the documents may cause loss of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function collate in module omterms.datauis:\n",
      "\n",
      "collate(self, by_theme_id=None, by_doc_ids=[], marker='\\n')\n",
      "    The method collects the desired set of documents concatenates them creating a unified document.\n",
      "        The order of merge is as follows:\n",
      "        - When neither list of theme nor doc ids is provided, it collates entire text.\n",
      "        - If a theme is given then all the documents under that theme are to be joined first.\n",
      "        - When a list of docs is given, only those in the list are kept.\n",
      "        Note that if both theme id and doc ids provided, precedence is on themes.\n",
      "    \n",
      "    Args:\n",
      "        by_theme_id (:obj:`int`, optional): The theme id of the docs to be collated.\n",
      "        by_doc_ids (:obj:`list` of :obj:`int`, optional): The list of doc ids to be collated (default Empty). \n",
      "        marker (:obj:`str`, optional): A delimiter (default newline)\n",
      "        \n",
      "    Returns:\n",
      "        (:obj:`str`): The collated text.\n",
      "\n",
      "Length of the corpus in terms of characters: 40701\n"
     ]
    }
   ],
   "source": [
    "help(WikiArticles.collate)\n",
    "TEXT = WikiC.collate(by_theme_id = TOPIC_ID, marker = \" \")\n",
    "print('Length of the corpus in terms of characters: {}'.format(len(TEXT)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenizing\n",
    "A custom tokenizer is developed and is being used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module omterms.tokenizer in omterms:\n",
      "\n",
      "NAME\n",
      "    omterms.tokenizer - OpenMaker text tokenizer.\n",
      "\n",
      "DESCRIPTION\n",
      "    Author: Bulent Ozel\n",
      "    e-mail: bulent.ozel@gmail.com\n",
      "    \n",
      "    The module contains a set of basic tools in order to tokenize a given inout text.\n",
      "    \n",
      "    Todo:\n",
      "        * Nothing at the moment ;)\n",
      "\n",
      "FUNCTIONS\n",
      "    normalise(s)\n",
      "        Basic string normalisation.\n",
      "        \n",
      "        Args:\n",
      "            s: (:obj:`str`): Input string to normalise.\n",
      "        \n",
      "        Returns:\n",
      "            (:obj:`str`): Normalised string.\n",
      "    \n",
      "    tokenize(raw)\n",
      "        The function tokenizes by splitting them on spaces, line breaks or characters\n",
      "            in CHARACTERS_TO_SPLIT.\n",
      "        \n",
      "        Args:\n",
      "            raw: (:obj:`str`): Input string to split\n",
      "        \n",
      "        Returns:\n",
      "            (:obj:`list` of :obj:`str`): list of terms\n",
      "    \n",
      "    tokenize_strip_non_words(raw)\n",
      "        Same as tokenize, but also removes non-word characters.\n",
      "        \n",
      "        Args:\n",
      "            raw: (:obj:`str`): Input string to split\n",
      "        \n",
      "        Returns:\n",
      "            (:obj:`list` of :obj:`str`): list of terms\n",
      "    \n",
      "    tokenized_pprint(tokens)\n",
      "        A pretty print function for strings tokenized by tokenize.\n",
      "        \n",
      "        Args:\n",
      "            tokens: (:obj:`list` of :obj:`str`): list of terms \n",
      "        \n",
      "        Returns:\n",
      "            (:obj:`str`): The joined terms.\n",
      "\n",
      "DATA\n",
      "    ALLOWED_SYMBOLS = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', '...\n",
      "    CHARACTERS_TO_SPLIT = \".,():;!?\\n`'=+/\\\\[]}{|><@#$%^&*_‘’“”.\"\n",
      "    REPLACEMENTS = {'&': 'and', \"'\": ' ', '-': ' ', r'\\x05': ' ', '`': ' '...\n",
      "\n",
      "FILE\n",
      "    /Users/bulentozel/OpenMaker/GitHub/omterms/omterms/tokenizer.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'power social and political public power redirects here for public electric utilities see public utility sociology outline portal main theories structural functionalism conflict theory symbolic interactionism methods quantitative qualitative historical comparative mathematical computational ethnography ethnomethodology network analysis positivism critical theory subfields and other major theories conflict criminology social constructionism culture development deviance demography education economic environmental family feminist sociology gender health industrial inequality knowledge law literature medical military organizational political race and ethnicity religion rural science social change social movements social psychology in sociology stratification science and technology technology urban utilitarianism browse bibliography by country index journals organizations people timeline v t e in social science and politics power is the ability to influence or outright control the behaviour of people the term authority is often used for power perceived as legitimate by the social structure power can be seen as evil or unjust but the exercise of power is accepted as endemic to humans as social beings in business power is often expressed as being upward or downward with downward power a company s superior influences subordinates when a company exerts upward power it is the subordinates who influence the decisions of their leader or leaders the use of power need not involve force or the threat of force coercion at one extreme it closely resembles what an english speaking person might term influence although some authors distinguish influence as a means by which power is used one such example is soft power as compared to hard power much of the recent sociological debate about power revolves around the issue of its means to enable in other words power as a means to make social actions possible as much as it may constrain or prevent them the philosopher michel foucault saw power as a structural expression of a complex strategic situation in a given social setting that requires both constraint and enablement theories five bases legitimate power referent power expert power reward power coercive power principles in interpersonal relationships rational choice framework cultural hegemony tarnow foucault clegg galbraith gene sharp bjrn kraus unmarked categories counterpower other theories psychological research empathy gap past research bargaining games conclusion abusive power and control tactics balance of power effects approach inhibition theory positive negative reactions tactics resistance to coercive influence kelman s compliance identification internalization theory of conversion power literacy quotations theories five bases french and raven s five bases of power social psychologists john r p french and bertram raven in a now classic study developed a schema of sources of power by which to analyse how power plays work or fail to work in a specific relationship according to french and raven power must be distinguished from influence in the following way power is that state of affairs which holds in a given relationship a b such that a given influence attempt by a over b makes a s desired change in b more likely conceived this way power is fundamentally relative it depends on the specific understandings a and b each apply to their relationship and interestingly requires b s recognition of a quality in a which would motivate b to change in the way a intends a must draw on the base or combination of bases of power appropriate to the relationship to effect the desired outcome drawing on the wrong power base can have unintended effects including a reduction in a s own power french and raven argue that there are five significant categories of such qualities while not excluding other minor categories further bases have since been adduced in particular by gareth morgan in his book images of organization legitimate power legitimate power also called positional power it is the power of an individual because of the relative position and duties of the holder of the position within an organization legitimate power is formal authority delegated to the holder of the position it is usually accompanied by various attributes of power such as a uniform a title or an imposing physical office referent power referent power referent power is the power or ability of individuals to attract others and build loyalty it is based on the charisma and interpersonal skills of the power holder a person may be admired because of specific personal trait and this admiration creates the opportunity for interpersonal influence here the person under power desires to identify with these personal qualities and gains satisfaction from being an accepted follower nationalism and patriotism count towards an intangible sort of referent power for example soldiers fight in wars to defend the honor of the country this is the second least obvious power but the most effective advertisers have long used the referent power of sports figures for products endorsements for example the charismatic appeal of the sports star supposedly leads to an acceptance of the endorsement although the individual may have little real credibility outside the sports arena abuse is possible when someone that is likable yet lacks integrity and honesty rises to power placing them in a situation to gain personal advantage at the cost of the group s position referent power is unstable alone and is not enough for a leader who wants longevity and respect when combined with other sources of power however it can help a person achieve great success expert power expert power expert power is an individual s power deriving from the skills or expertise of the person and the organization s needs for those skills and expertise unlike the others this type of power is usually highly specific and limited to the particular area in which the expert is trained and qualified when they have knowledge and skills that enable them to understand a situation suggest solutions use solid judgment and generally out perform others then people tend to listen to them when individuals demonstrate expertise people tend to trust them and respect what they say as subject matter experts their ideas will have more value and others will look to them for leadership in that area reward power reward power reward power depends on the ability of the power wielder to confer valued material rewards it refers to the degree to which the individual can give others a reward of some kind such as benefits time off desired gifts promotions or increases in pay or responsibility this power is obvious but also ineffective if abused people who abuse reward power can become pushy or be reprimanded for being too forthcoming or moving things too quickly if others expect to be rewarded for doing what someone wants there s a high probability that they ll do it the problem with this basis of power is that the rewarder may not have as much control over rewards as may be required supervisors rarely have complete control over salary increases and managers often can t control promotions all by themselves and even a ceo needs permission from the board of directors for some actions so when somebody uses up available rewards or the rewards don t have enough perceived value to others their power weakens one of the frustrations of using rewards is that they often need to be bigger each time if they re to have the same motivational impact even then if rewards are given frequently people can become satiated by the reward such that it loses its effectiveness coercive power coercive power coercive control coercive power is the application of negative influences it includes the ability to demote or to withhold other rewards the desire for valued rewards or the fear of having them withheld that ensures the obedience of those under power coercive power tends to be the most obvious but least effective form of power as it builds resentment and resistance from the people who experience it threats and punishment are common tools of coercion implying or threatening that someone will be fired demoted denied privileges or given undesirable assignments these are examples of using coercive power extensive use of coercive power is rarely appropriate in an organizational setting and relying on these forms of power alone will result in a very cold impoverished style of leadership principles in interpersonal relationships according to guerrero laura k and peter a andersen in close encounters communication in relationships power as a perception power is a perception in a sense that some people can have objective power but still have trouble influencing others people who use power cues and act powerfully and proactively tend to be perceived as powerful by others some people become influential even though they don t overtly use powerful behavior power as a relational concept power exists in relationships the issue here is often how much relative power a person has in comparison to one s partner partners in close and satisfying relationships often influence each other at different times in various arenas power as resource based power usually represents a struggle over resources the more scarce and valued resources are the more intense and protracted are power struggles the scarcity hypothesis indicates that people have the most power when the resources they possess are hard to come by or are in high demand however scarce resource leads to power only if it s valued within a relationship the principle of least interest and dependence power the person with less to lose has greater power in the relationship dependence power indicates that those who are dependent on their relationship or partner are less powerful especially if they know their partner is uncommitted and might leave them according to interdependence theory quality of alternatives refers to the types of relationships and opportunities people could have if they were not in their current relationship the principle of least interest suggests that if a difference exists in the intensity of positive feelings between partners the partner who feels the most positive is at a power disadvantage there s an inverse relationship between interest in relationship and the degree of relational power power as enabling or disabling power can be enabling or disabling research has been shown that people are more likely to have an enduring influence on others when they engage in dominant behavior that reflects social skill rather than intimidation personal power is protective against pressure and excessive influence by others and or situational stress people who communicate through self confidence and expressive composed behavior tend to be successful in achieving their goals and maintaining good relationships power can be disabling when it leads to destructive patterns of communication this can lead to the chilling effect where the less powerful person often hesitates to communicate dissatisfaction and the demand withdrawal pattern which is when one person makes demands and the other becomes defensive and withdraws mawasha both effects have negative consequences for relational satisfaction power as a prerogative the prerogative principle states that the partner with more power can make and break the rules powerful people can violate norms break relational rules and manage interactions without as much penalty as powerless people these actions may reinforce the powerful person s dependence power in addition the more powerful person has the prerogative to manage both verbal and nonverbal interactions they can initiate conversations change topics interrupt others initiate touch and end discussions more easily than less powerful people see expressions of dominance rational choice framework game theory with its foundations in the walrasian theory of rational choice is increasingly used in various disciplines to help analyze power relationships one rational choice definition of power is given by keith dowding in his book power in rational choice theory human individuals or groups can be modelled as actors who choose from a choice set of possible actions in order to try to achieve desired outcomes an actor s incentive structure comprises its beliefs about the costs associated with different actions in the choice set and the likelihoods that different actions will lead to desired outcomes in this setting we can differentiate between outcome power the ability of an actor to bring about or help bring about outcomes social power the ability of an actor to change the incentive structures of other actors in order to bring about outcomes this framework can be used to model a wide range of social interactions where actors have the ability to exert power over others for example a powerful actor can take options away from another s choice set can change the relative costs of actions can change the likelihood that a given action will lead to a given outcome or might simply change the other s beliefs about its incentive structure as with other models of power this framework is neutral as to the use of coercion for example a threat of violence can change the likely costs and benefits of different actions so can a financial penalty in a voluntarily agreed contract or indeed a friendly offer cultural hegemony in the marxist tradition the italian writer antonio gramsci elaborated the role of ideology in creating a cultural hegemony which becomes a means of bolstering the power of capitalism and of the nation state drawing on niccol machiavelli in the prince and trying to understand why there had been no communist revolution in western europe while it was claimed there had been one in russia gramsci conceptualised this hegemony as a centaur consisting of two halves the back end the beast represented the more classic material image of power power through coercion through brute force be it physical or economic but the capitalist hegemony he argued depended even more strongly on the front end the human face which projected power through consent in russia this power was lacking allowing for a revolution however in western europe specifically in italy capitalism had succeeded in exercising consensual power convincing the working classes that their interests were the same as those of capitalists in this way revolution had been avoided while gramsci stresses the significance of ideology in power structures marxist feminist writers such as michele barrett stress the role of ideologies in extolling the virtues of family life the classic argument to illustrate this point of view is the use of women as a reserve army of labour in wartime it is accepted that women perform masculine tasks while after the war the roles are easily reversed therefore according to barrett the destruction of capitalist economic relations is necessary but not sufficient for the liberation of women tarnow tarnow considers what power hijackers have over air plane passengers and draws similarities with power in the military he shows that power over an individual can be amplified by the presence of a group if the group conforms to the leader s commands the leader s power over an individual is greatly enhanced while if the group does not conform the leader s power over an individual is nil foucault for michel foucault real power will always rely on the ignorance of its agents with the discovery and emergence of biopower and biopolitics a biological and political technology of its population highlights this fact no single human group nor single actor runs the dispositif machine or apparatus but power is dispersed through the apparatus as efficiently and silently as possible ensuring its agents do whatever is necessary it is because of this action that power is unlikely to be detected so remains elusive to rational investigation according to foucault foucault quotes a text reputedly written by political economist jean baptiste antoine auget de montyon entitled recherches et considrations sur la population de la france but however turns out to be written by his secretary jean baptise moheau and by emphasizing biologist jean baptiste lamarck who constantly refers to milieus as a plural adjective and sees into the milieu as an expression as nothing more than water air and light confirming the genus within the milieu in this case the human species relates to a function of the population and its social and political interaction in which both form an artificial and natural milieu this milieu both artificial and natural appears as a target of intervention for power according to foucault which is radically different from the previous notions on sovereignty territory and disciplinary space inter woven into from a social and political relations which function as a species biological species clegg stewart clegg proposes another three dimensional model with his circuits of power theory this model likens the production and organizing of power to an electric circuit board consisting of three distinct interacting circuits episodic dispositional and facilitative these circuits operate at three levels two are macro and one is micro the episodic circuit is the micro level and is constituted of irregular exercise of power as agents address feelings communication conflict and resistance in day to day interrelations the outcomes of the episodic circuit are both positive and negative the dispositional circuit is constituted of macro level rules of practice and socially constructed meanings that inform member relations and legitimate authority the facilitative circuit is constituted of macro level technology environmental contingencies job design and networks which empower or disempower and thus punish or reward agency in the episodic circuit all three independent circuits interact at obligatory passage points which are channels for empowerment or disempowerment galbraith jk galbraith summarizes the types of power as being condign based on force compensatory through the use of various resources or conditioned the result of persuasion and their sources as personality individuals property their material resources and organizational whoever sits at the top of an organisational power structure gene sharp gene sharp an american professor of political science believes that power depends ultimately on its bases thus a political regime maintains power because people accept and obey its dictates laws and policies sharp cites the insight of tienne de la botie sharp s key theme is that power is not monolithic that is it does not derive from some intrinsic quality of those who are in power for sharp political power the power of any state regardless of its particular structural organization ultimately derives from the subjects of the state his fundamental belief is that any power structure relies upon the subjects obedience to the orders of the ruler s if subjects do not obey leaders have no power his work is thought to have been influential in the overthrow of slobodan milosevic in the arab spring and other nonviolent revolutions bjrn kraus bjrn kraus deals with the epistemological perspective upon power regarding the question about possibilities of interpersonal influence by developing a special form of constructivism named relational constructivism instead of focussing on the valuation and distribution of power he asks first and foremost what the term can describe at all coming from max weber s definition of power he realizes that the term of power has to be split into instructive power and destructive power more precisely instructive power means the chance to determine the actions and thoughts of another person whereas destructive power means the chance to diminish the opportunities of another person how significant this distinction really is becomes evident by looking at the possibilities of rejecting power attempts rejecting instructive power is possible rejecting destructive power is not by using this distinction proportions of power can be analyzed in a more sophisticated way helping to sufficiently reflect on matters of responsibility f this perspective permits to get over an either or position either there is power or there isn t which is common especially in epistemological discourses about power theories and to introduce the possibility of an as well as position unmarked categories the idea of unmarked categories originated in feminism the theory analyzes the culture of the powerful the powerful comprise those people in society with easy access to resources those who can exercise power without considering their actions for the powerful their culture seems obvious for the powerless on the other hand it remains out of reach lite and expensive the unmarked category can form the identifying mark of the powerful the unmarked category becomes the standard against which to measure everything else for most western readers it is posited that if a protagonist s race is not indicated it will be assumed by the reader that the protagonist is caucasian if a sexual identity is not indicated it will be assumed by the reader that the protagonist is heterosexual if the gender of a body is not indicated will be assumed by the reader that it is male if a disability is not indicated it will be assumed by the reader that the protagonist is able bodied just as a set of examples one can often overlook unmarked categories whiteness forms an unmarked category not commonly visible to the powerful as they often fall within this category the unmarked category becomes the norm with the other categories relegated to deviant status social groups can apply this view of power to race gender and disability without modification the able body is the neutral body counterpower the term counter power sometimes written counterpower is used in a range of situations to describe the countervailing force that can be utilised by the oppressed to counterbalance or erode the power of elites a general definition has been provided by the anthropologist david graeber as a collection of social institutions set in opposition to the state and capital from self governing communities to radical labor unions to popular militias graeber also notes that counter power can also be referred to as anti power and when institutions of counter power maintain themselves in the face of the state this is usually referred to as a dual power situation tim gee in his book counterpower making change happen put forward a theory that those disempowered by governments and elite groups power can use counterpower to counter this in gee s model counterpower is split into three categories idea counterpower economic counterpower and physical counterpower although the term has come to prominence through its use by participants in the global justice anti globalization movement of the 1990s onwards the word has been used for at least years for instance martin buber s book paths in utopia includes the line power abdicates only under the stress of counter power other theories thomas hobbes defined power as a man s present means to obtain some future apparent good leviathan ch the thought of friedrich nietzsche underlies much 20th century analysis of power nietzsche disseminated ideas on the will to power which he saw as the domination of other humans as much as the exercise of control over one s environment some schools of psychology notably that associated with alfred adler place power dynamics at the core of their theory where orthodox freudians might place sexuality psychological research recent experimental psychology suggests that the more power one has the less one takes on the perspective of others implying that the powerful have less empathy adam galinsky along with several coauthors found that when those who are reminded of their powerlessness are instructed to draw es on their forehead they are times more likely to draw them such that they are legible to others than those who are reminded of their power powerful people are also more likely to take action in one example powerful people turned off an irritatingly close fan twice as much as less powerful people researchers have documented the bystander effect they found that powerful people are three times as likely to first offer help to a stranger in distress a study involving over college students suggested that those primed to feel powerful through stating power words were less susceptible to external pressure more willing to give honest feedback and more creative empathy gap empathy gap power is defined as a possibility to influence others the use of power has evolved from centuries citation needed gaining prestige honor and reputation is one of the central motives for gaining power in human nature citation needed power also relates with empathy gaps because it limits the interpersonal relationship and compares the power differences having power or not having power can cause a number of psychological consequences it leads to strategic versus social responsibilities citation needed research experiments were done by whom as early as to explore power conflict past research earlier when research proposed that increased power relates to increased rewards and leads one to approach things more frequently citation needed in contrast decreased power relates to more constraint threat and punishment which leads to inhibitions it was concluded by whom that being powerful leads one to successful outcomes to develop negotiation strategies and to make more self serving offers citation needed later when research proposed that differences in power lead to strategic considerations being strategic can also mean to defend when one is opposed or to hurt the decision maker it was concluded by whom that facing one with more power leads to strategic consideration whereas facing one with less power leads to a social responsibility bargaining games bargaining games were explored by whom in and these studies compared behavior done in different power given clarification needed situations in an ultimatum game the person in given power offers an ultimatum and the recipient would have to accept that offer or else both the proposer and the recipient will receive no reward in a dictator game the person in given power offers a proposal and the recipient would have to accept that offer the recipient has no choice of rejecting the offer conclusion the dictator game gives no power to the recipient whereas the ultimatum game gives some power to the recipient the behavior observed was that the person offering the proposal would act less strategically than would the one offering in the ultimatum game self serving also occurred and a lot of pro social behavior was observed when the counterpart recipient is completely powerless lack of strategy social responsibility and moral consideration is often observed from the behavior of the proposal given the one with the power abusive power and control abusive power and control coercive power abusive power and control or controlling behaviour or coercive control is the way that abusers gain and maintain power and control over a victim for an abusive purpose such as psychological physical sexual or financial abuse the abuse can be for various reasons such as personal gain personal gratification psychological projection devaluation envy or just for the sake of it as the abuser may simply enjoy exercising power and control controlling abusers may use multiple tactics to exert power and control over their victims the tactics themselves are psychologically and sometimes physically abusive control may be helped through economic abuse thus limiting the victim s actions as they may then lack the necessary resources to resist the abuse the goal of the abuser is to control and intimidate the victim or to influence them to feel that they do not have an equal voice in the relationship manipulators and abusers control their victims with a range of tactics including positive reinforcement such as praise flattery ingratiation love bombing smiling gifts attention negative reinforcement intermittent or partial reinforcement psychological punishment such as nagging silent treatment swearing threats intimidation emotional blackmail guilt trips inattention and traumatic tactics such as verbal abuse or explosive anger the vulnerabilities of the victim are exploited with those who are particularly vulnerable being most often selected as targets traumatic bonding can occur between the abuser and victim as the result of ongoing cycles of abuse in which the intermittent reinforcement of reward and punishment creates powerful emotional bonds that are resistant to change and a climate of fear an attempt may be made to normalise legitimise rationalise deny or minimise the abusive behaviour or blame the victim for it isolation gaslighting mind games lying disinformation propaganda destabilisation and divide and rule are other strategies that are often used the victim may be plied with alcohol or drugs to help disorientate them certain personality types feel particularly compelled to control other people tactics in everyday situations people use a variety of power tactics to push or prompt people into particular action there are plenty of examples of power tactics that are quite common and employed every day some of these tactics include bullying collaboration complaining criticizing demanding disengaging evading humor inspiring manipulating negotiating socializing and supplicating these power tactics can be classified along three different dimensions soft and hard soft tactics take advantage of the relationship between person and the target they are more indirect and interpersonal e g collaboration socializing conversely hard tactics are harsh forceful direct and rely on concrete outcomes however they are not more powerful than soft tactics in many circumstances fear of social exclusion can be a much stronger motivator than some kind of physical punishment rational and nonrational rational tactics of influence make use of reasoning logic and sound judgment whereas nonrational tactics rely on emotionality and misinformation examples of each include bargaining and persuasion and evasion and put downs respectively unilateral and bilateral bilateral tactics such as collaboration and negotiation involve reciprocity on the part of both the person influencing and their target unilateral tactics on the other hand are enacted without any participation on the part of the target these tactics include disengagement and fait accompli people tend to vary in their use of power tactics with different types of people opting for different tactics for instance interpersonally oriented people tend to use soft and rational tactics machiavellians however tend to use nonrational tactics moreover extroverts use a greater variety of power tactics than do introverts people will also choose different tactics based on the group situation and based on whom they are trying to influence people also tend to shift from soft to hard tactics when they face resistance balance of power because power operates both relationally and reciprocally sociologists speak of the balance of power between parties to a relationship all parties to all relationships have some power the sociological examination of power concerns itself with discovering and describing the relative strengths equal or unequal stable or subject to periodic change sociologists usually analyse relationships in which the parties have relatively equal or nearly equal power in terms of constraint rather than of power thus power has a connotation of unilateralism if this were not so then all relationships could be described in terms of power and its meaning would be lost given that power is not innate and can be granted to others to acquire power you must possess or control a form of power currency effects power changes those in the position of power and those who are targets of that power approach inhibition theory developed by d keltner and colleagues approach inhibition theory assumes that having power and using power alters psychological states of individuals the theory is based on the notion that most organisms react to environmental events in two common ways the reaction of approach is associated with action self promotion seeking rewards increased energy and movement inhibition on the contrary is associated with self protection avoiding threats or danger vigilance loss of motivation and an overall reduction in activity overall approach inhibition theory holds that power promotes approach tendencies while reduction in power promotes inhibition tendencies positive power prompts people to take action makes individuals more responsive to changes within a group and its environment powerful people are more proactive more likely to speak up make the first move and lead negotiation powerful people are more focused on the goals appropriate in a given situation and tend to plan more task related activities in a work setting powerful people tend to experience more positive emotions such as happiness and satisfaction and they smile more than low power individuals power is associated with optimism about the future because more powerful individuals focus their attention on more positive aspects of the environment people with more power tend to carry out executive cognitive functions more rapidly and successfully including internal control mechanisms that coordinate attention decision making planning and goal selection negative powerful people are prone to take risky inappropriate or unethical decisions and often overstep their boundaries they tend to generate negative emotional reactions in their subordinates particularly when there is a conflict in the group when individuals gain power their self evaluation become more positive while their evaluations of others become more negative power tends to weaken ones social attentiveness which leads to difficulty understanding other peoples point of view powerful people also spend less time collecting and processing information about their subordinates and often perceive them in a stereotypical fashion people with power tend to use more coercive tactics increase social distance between themselves and subordinates believe that non powerful individuals are untrustworthy and devalue work and ability of less powerful individuals reactions tactics a number of studies demonstrate that harsh power tactics e g punishment both personal and impersonal rule based sanctions and non personal rewards are less effective than soft tactics expert power referent power and personal rewards it is probably because harsh tactics generate hostility depression fear and anger while soft tactics are often reciprocated with cooperation coercive and reward power can also lead group members to lose interest in their work while instilling a feeling of autonomy in ones subordinates can sustain their interest in work and maintain high productivity even in the absence of monitoring coercive influence creates conflict that can disrupt entire group functioning when disobedient group members are severely reprimanded the rest of the group may become more disruptive and uninterested in their work leading to negative and inappropriate activities spreading from one troubled member to the rest of the group this effect is called disruptive contagion or ripple effect and it is strongly manifested when reprimanded member has a high status within a group and authoritys requests are vague and ambiguous resistance to coercive influence coercive influence can be tolerated when the group is successful the leader is trusted and the use of coercive tactics is justified by group norms furthermore coercive methods are more effective when applied frequently and consistently to punish prohibited actions however in some cases group members chose to resist the authoritys influence when low power group members have a feeling of shared identity they are more likely to form a revolutionary coalition a subgroup formed within a larger group that seeks to disrupt and oppose the groups authority structure group members are more likely to form a revolutionary coalition and resist an authority when authority lacks referent power uses coercive methods and asks group members to carry out unpleasant assignments it is because these conditions create reactance a complex emotional and cognitive reaction that occurs when individuals feel that their freedom to make choices has been threatened or eliminated when reactance occurs individuals strive to reassert their sense of freedom by affirming their authority kelman s compliance identification internalization theory of conversion herbert kelman identified three basic step like reactions that people display in response to coercive influence compliance identification and internalization this theory explains how groups convert hesitant recruits into zealous followers over time at the stage of compliance group members comply with authoritys demands but personally do not agree with them if authority does not monitor the members they will probably not obey identification occurs when the target of the influence admires and therefore imitates the authority mimics authoritys actions values characteristics and takes on behaviours of the person with power if prolonged and continuous identification can lead to the final stage internalization when internalization occurs individual adopts the induced behaviour because it is congruent with his her value system at this stage group members no longer carry out authority orders but perform actions that are congruent with their personal beliefs and opinions extreme obedience often requires internalization power literacy power literacy refers to how one perceives power how it is formed and accumulates and the structures that support it and who is in control of it education can be helpful for heightening power literacy in a ted talk eric liu notes that we don t like to talk about power as we find it scary and somehow evil with it having a negative moral valence and states that the pervasiveness of power illiteracy causes a concentration of knowledge understanding and clout joe l kincheloe describes a cyber literacy of power that is concerned with the forces that shape knowledge production and the construction and transmission of meaning being more about engaging knowledge than mastering information and a cyber power literacy that is focused on transformative knowledge production and new modes of accountability quotations the love of power is the love of ourselves william hazlitt power tends to confuse itself with virtue and a great nation is susceptible to the idea that its power is a sign of god s favor the bush the younger administration claims possession of an ultimate truth that because we are stronger we must know better and must have right on our side amity enmity complex authority bias control of time in power relationships cratology the art and science of social power discourse of power speaking truth to power social control state collapse the anatomy of revolution veto the power to forbid an action '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS = tokenizer.tokenize_strip_non_words(TEXT)\n",
    "tokenizer.tokenized_pprint(TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term counts: Power Corpus = 6190\n"
     ]
    }
   ],
   "source": [
    "print('Term counts: {} Corpus = {}'.format(TOPIC_NAME.capitalize(), len(TOKENS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning and counting\n",
    "A set of custome text cleaning tools is developed.\n",
    "\n",
    "This is an example case for post proceesing in terms of cleaning. The pre-processing, that is data cleaning/preperation during or right after harvesting could be further improved to avoid such processes at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TextCleaner in module omterms.cleaner:\n",
      "\n",
      "class TextCleaner(builtins.object)\n",
      " |  An object that contains a set of tools to clean and preprocess textual data.\n",
      " |  \n",
      " |  Note:\n",
      " |      The object uses nltk.FreqDist object\n",
      " |      For stem checks during pruninng it needs an external stemmer.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      exceptions (:obj:`list` of :obj:`str`): List of excepted terms.\n",
      " |      stopwords (:obj:`list` of :obj:`str`): List of stopwords.\n",
      " |      stemf: A stemmer funtion.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, stopwords=[], exceptions=[], fstemmer=<function TextCleaner.<lambda> at 0x111161840>, stemcheck=False)\n",
      " |      The class constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          stopwords (:obj:`list` of :obj:`str`, optional): list of stopwords (default None).\n",
      " |          exceptions (:obj:`set` of :obj:`str`, optional): list of excepted terms (default None).\n",
      " |          fstemmer (x :obj:`str` -> y: :obj:`str`, optional): A stemmer function (default f(x) = x)\n",
      " |          stemcheck (:obj:`bool`): A flag to determine whether stems of exceptions should also be considered\n",
      " |              (default False)\n",
      " |  \n",
      " |  clean(self, words, display_top=10, logging=True, exceptions=[])\n",
      " |      Removes panctuations and stopwords from a corpus.\n",
      " |          \n",
      " |      Args:\n",
      " |          words (:obj:`list` of :obj:`str`): The input corpus as list of words.\n",
      " |          display_top (:obj:`int`, optional): Logging size (default 10).\n",
      " |          logging (:obj:`bool`): Optional. When true stdout logging is done (default True).\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The list terms that will not \n",
      " |              be pruned (default None).\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns the trimmed corpus as the NLTK obj.\n",
      " |  \n",
      " |  extend_stopwords(self, spointer)\n",
      " |      The method extends a new stopwords list.\n",
      " |          \n",
      " |      Args:\n",
      " |          spointer (:obj:`list` of :obj:`str`, :obj:`str`): Either file path string or\n",
      " |              a list of stopwords.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: True if successful, False otherwise.\n",
      " |      \n",
      " |      Raises:\n",
      " |          FileNotFoundError: Raised if a given file is not accessable.\n",
      " |  \n",
      " |  isexception(self, term, exceptions=[], stemcheck=False)\n",
      " |      The static makes the exception list and returns it.\n",
      " |      \n",
      " |      Args:\n",
      " |          term (:obj:`str`): The term.\n",
      " |          exceptions (:obj:`list`, optional): The list of exception terms (default None).\n",
      " |          stemcheck (:obj:`bool`, optional): if the list to be extended via the stems (default False)\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`bool`):\n",
      " |  \n",
      " |  load_stopwords(self, spointer)\n",
      " |      The method reloads a new stopwords list.\n",
      " |      \n",
      " |      Note:\n",
      " |          Internal stopword is overwritten.\n",
      " |          \n",
      " |      Args:\n",
      " |          spointer (:obj:`list` of :obj:`str`or :obj:`str`): Either file path string or\n",
      " |              a list of stopwords.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: True if successful, False otherwise.\n",
      " |      \n",
      " |      Raises:\n",
      " |          FileNotFoundError: Raised if a given file is not accessable.\n",
      " |  \n",
      " |  remove_contains(self, freq_dist, literals=\".,():;!?\\n`'=+/\\\\[]}{|><@#$%^&*_‘’“”.\", exceptions=[])\n",
      " |      Removes the terms that contains the specific literals.\n",
      " |              \n",
      " |      Args:\n",
      " |          freq_dist (:obj:`nltk.FreqDist`): list of words and more.\n",
      " |          literals (:obj:`list` of  :obj:`str`): list of literals.\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The exception list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  remove_numerals(self, freq_dist, remove_any=False, exceptions=[])\n",
      " |      The method removes terms with numeral literals.\n",
      " |          \n",
      " |      Note:\n",
      " |          When remove_any is selected, literals such as 3D would vanish.\n",
      " |          \n",
      " |      Args:\n",
      " |          freq_dist (:obj:`nltk.FreqDist`): list of words and more.\n",
      " |          remove_any (:obj:`bool`, optional): If True mumeral and literal mixed terms are removed.\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The exception list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  remove_panctuation(self, freq_dist, exceptions=[])\n",
      " |      The static method removes punctuation only terms.\n",
      " |          \n",
      " |      Args:\n",
      " |          freq_dist (:obj:`nltk.FreqDist`): list of words and more.\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The exception list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  remove_rare_terms(self, freq_dist, below=3, exceptions=[])\n",
      " |      The method removes terms that have rare occurances.\n",
      " |      \n",
      " |      Note:\n",
      " |          Such removal may help reduce errenous and random terms.\n",
      " |          \n",
      " |      Args:\n",
      " |          freq_dist (:obj:`nltk.FreqDist`): list of words and more.\n",
      " |          below (:obj:`int`, optional): The minumum allowed frequency count (default 3).\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The exception list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  remove_short_terms(self, freq_dist, threshold=1, exceptions=[])\n",
      " |      The method removes terms that are below a certain length.\n",
      " |      \n",
      " |      Args:\n",
      " |          freq_dist (:obj:`nltk.FreqDist`): list of words and more.\n",
      " |          threshold (:obj:`int`, optional): The charcter length of a term (default 1).\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The exception list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  remove_stopwords(self, freq_dist, exceptions=[])\n",
      " |      The static method removes stopwords.\n",
      " |          \n",
      " |      Args:\n",
      " |          freq_dist (:obj:`nltk.FreqDist`): list of words and more.\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The exception list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  reset_exceptions(self)\n",
      " |      Resets the exception set to empty.\n",
      " |      \n",
      " |      Args:\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`bool`):\n",
      " |  \n",
      " |  set_exceptions(self, exceptions, stemcheck=False)\n",
      " |      Sets instance-wide exception set.\n",
      " |      \n",
      " |      Args:\n",
      " |          exceptions (:obj:`list` of `str`): The list of exception terms.\n",
      " |          stemcheck (:obj:`bool`, optional): if the list to be extended via the stems (default False)\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  freq_dist(words)\n",
      " |      The static method computes frequency distribution of a word list.\n",
      " |          \n",
      " |      Args:\n",
      " |          words (:obj:`list` of :obj:`str`, :obj:`str`): list of words.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  make_exceptions(exceptions, stemf=<function TextCleaner.<lambda> at 0x111161e18>, stemcheck=False)\n",
      " |      The static method makes the exception list and returns it.\n",
      " |      \n",
      " |      Args:\n",
      " |          exceptions (:obj:`list`): The list of exception terms.\n",
      " |          stemf (x :obj:`str` -> y: :obj:`str`, optional): A stemmer function (default f(x) = x)\n",
      " |          stemcheck (:obj:`bool`, optional): if the list to be extended via the stems (default False)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`set`): The exception set. If stemcheck is opted both terms and their stems \n",
      " |              is be represented in the list.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TextCleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Forming stopwords list\n",
    "A domain specific stop-word is added to standard stopwords. Domain specific in this tutorial is examplary and it needs to be extended.\n",
    "\n",
    "A larger list of stopwords can be generated either\n",
    "- by repeating the examination flow that is outlined in this tutorial, which would give insight on the subject\n",
    "- or via adoption of state of art methods that specifically focus on theme specific stopward generation, which itself is an interesting and crucial research and development issue within NLP and Text Analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cleaner = TextCleaner()\n",
    "Cleaner.load_stopwords(STOPWORDS_STANDARD)\n",
    "Cleaner.extend_stopwords(STOPWORDS_SPECIFIC)\n",
    "#pp.pprint(Cleaner.stopwords)\n",
    "len(Cleaner.stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Adding/notifying list of theme/topic specific terms\n",
    "A maker culture speficic term such as 3-D or 3D, reprap, c2c, or abbrieviations such as oss (open source software) are important in the discourse of the community but maybe considered or skipped in most text cleaning techniques. Besides, each community movement generates and created its own terms which may not be present in the common culture and so in a background corpus.\n",
    "\n",
    "Adding a precompiled list of specific terms, if exists or needed, right after the instantiation stage of the cleaner stage also helps to protect them in later cleaning and prunning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/specifics_openmaker.txt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TERMS_SPECIFIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3-d',\n",
      " '3d',\n",
      " 'abatement',\n",
      " 'affordable',\n",
      " 'agenda21',\n",
      " 'anarchism',\n",
      " 'autonomous',\n",
      " 'biodiesel',\n",
      " 'biodiversity',\n",
      " 'biofuel',\n",
      " 'biogas',\n",
      " 'biomass',\n",
      " 'biosphere',\n",
      " 'bricolage',\n",
      " 'brundtland',\n",
      " 'c2c',\n",
      " 'cad',\n",
      " 'cap-and-trade',\n",
      " 'carfree',\n",
      " 'cdm',\n",
      " 'christensen',\n",
      " 'co-creation',\n",
      " 'co-develop',\n",
      " 'co-invention',\n",
      " 'co-inventor',\n",
      " 'coextinction',\n",
      " 'cognition',\n",
      " 'commons-based',\n",
      " 'computer-aided',\n",
      " 'conferencing',\n",
      " 'consortium',\n",
      " 'constraints',\n",
      " 'construct',\n",
      " 'copyleft',\n",
      " 'copyright',\n",
      " 'cradle-to-cradle',\n",
      " 'crowdsourcing',\n",
      " 'crowdworker',\n",
      " 'cuvier',\n",
      " 'deforestation',\n",
      " 'desalination',\n",
      " 'displaystyle',\n",
      " 'diy',\n",
      " 'eco',\n",
      " 'eco-innovation',\n",
      " 'ecology',\n",
      " 'ecopsychology',\n",
      " 'ecosystem',\n",
      " 'edupunk',\n",
      " 'electromagnetic',\n",
      " 'extrinsic',\n",
      " 'f-oss',\n",
      " 'fab',\n",
      " 'fairtrade',\n",
      " 'footprint',\n",
      " 'foss',\n",
      " 'fossil',\n",
      " 'freshwater',\n",
      " 'geothermal',\n",
      " 'glazunov',\n",
      " 'gnu',\n",
      " 'google',\n",
      " 'graphics',\n",
      " 'greenoman',\n",
      " 'grid',\n",
      " 'groupware',\n",
      " 'hackerspace',\n",
      " 'high-technology',\n",
      " 'hippel',\n",
      " 'holistic ',\n",
      " 'how-to',\n",
      " 'hydro',\n",
      " 'hydroelectricity',\n",
      " 'hydropower',\n",
      " 'hype',\n",
      " 'hyperdiffusionism',\n",
      " 'ideation',\n",
      " 'ieee',\n",
      " 'ietf',\n",
      " 'infrastructure',\n",
      " 'internet',\n",
      " 'interoperability',\n",
      " 'intranet',\n",
      " 'iso',\n",
      " 'isoiec',\n",
      " 'itu-t',\n",
      " 'kludge',\n",
      " 'kluge',\n",
      " 'landfill',\n",
      " 'laser',\n",
      " 'life-cycle',\n",
      " 'lifecycle',\n",
      " 'lifestyles',\n",
      " 'linux',\n",
      " 'liveable',\n",
      " 'marginalize',\n",
      " 'methane',\n",
      " 'microsoft',\n",
      " 'mit',\n",
      " 'nikolay',\n",
      " 'non-discriminatory',\n",
      " 'online',\n",
      " 'open-source',\n",
      " 'openbts',\n",
      " 'opencores',\n",
      " 'organisation',\n",
      " 'osi',\n",
      " 'oss',\n",
      " 'participatory',\n",
      " 'pearce',\n",
      " 'permaculture',\n",
      " 'photovoltaic',\n",
      " 'photovoltaics',\n",
      " 'post-partisanship',\n",
      " 'programmable',\n",
      " 'proprietary',\n",
      " 'prosumer',\n",
      " 'prosumption',\n",
      " 'prototype',\n",
      " 'psychometric',\n",
      " 'racism',\n",
      " 'rainwater',\n",
      " 'recycled',\n",
      " 'recycling',\n",
      " 'reprap',\n",
      " 'reuse',\n",
      " 'rimsky-korsakov',\n",
      " 'robotics',\n",
      " 'schmidhuber',\n",
      " 'schumpeter',\n",
      " 'software',\n",
      " 'sparkfun',\n",
      " 'stakeholders',\n",
      " 'sternberg',\n",
      " 'sub-saharan',\n",
      " 'sustainable',\n",
      " 'telepresence',\n",
      " 'thingiverse',\n",
      " 'toolkit',\n",
      " 'unsustainable',\n",
      " 'value-added',\n",
      " 'w3c',\n",
      " 'website',\n",
      " 'wiki',\n",
      " 'wikinomics'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cleaner.set_exceptions(load_from_file(TERMS_SPECIFIC))\n",
    "pp.pprint(Cleaner.exceptions)\n",
    "len(Cleaner.exceptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Removing panctuations and stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6190\n",
      "Initial state:\n",
      "Total term counts: 6190\n",
      "[('the', 326),\n",
      " ('power', 245),\n",
      " ('of', 224),\n",
      " ('and', 203),\n",
      " ('to', 179),\n",
      " ('in', 119),\n",
      " ('a', 119),\n",
      " ('is', 102),\n",
      " ('that', 81),\n",
      " ('as', 71)]\n",
      "Removing panctuation only terms...\n",
      "Total term counts: 6190\n",
      "[('the', 326),\n",
      " ('power', 245),\n",
      " ('of', 224),\n",
      " ('and', 203),\n",
      " ('to', 179),\n",
      " ('in', 119),\n",
      " ('a', 119),\n",
      " ('is', 102),\n",
      " ('that', 81),\n",
      " ('as', 71)]\n",
      "Removing stopwords...\n",
      "Total term counts: 3541\n",
      "[('power', 245),\n",
      " ('people', 40),\n",
      " ('tactics', 33),\n",
      " ('powerful', 31),\n",
      " ('social', 27),\n",
      " ('control', 23),\n",
      " ('group', 23),\n",
      " ('influence', 22),\n",
      " ('use', 20),\n",
      " ('coercive', 20)]\n"
     ]
    }
   ],
   "source": [
    "print(len(TOKENS))\n",
    "TOKENS_TF = Cleaner.clean(TOKENS,logging = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 4560 punctuations and stopword occurances are removed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('power', 245),\n",
       " ('people', 40),\n",
       " ('tactics', 33),\n",
       " ('powerful', 31),\n",
       " ('social', 27),\n",
       " ('control', 23),\n",
       " ('group', 23),\n",
       " ('influence', 22),\n",
       " ('use', 20),\n",
       " ('coercive', 20)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('A total of {} punctuations and stopword occurances are removed.'.format(len(TOKENS) - len(TOKENS_TF)))\n",
    "TOKENS_TF.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Removing all numeral terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction due to all numeral terms = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('power', 245),\n",
       " ('people', 40),\n",
       " ('tactics', 33),\n",
       " ('powerful', 31),\n",
       " ('social', 27),\n",
       " ('control', 23),\n",
       " ('group', 23),\n",
       " ('influence', 22),\n",
       " ('use', 20),\n",
       " ('coercive', 20)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS_TFu = Cleaner.remove_numerals(TOKENS_TF, remove_any = False, exceptions = [])\n",
    "print(\"Reduction due to all numeral terms = {}\".format(len(TOKENS_TF) - len(TOKENS_TFu)))\n",
    "TOKENS_TF = TOKENS_TFu\n",
    "TOKENS_TF.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Removing terms that has numerals in them\n",
    "This would remove literals such as 20th, 3D, etc unless they are in the exception of the cleaner object or marked as exception during the function call. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction due to partially numeral terms = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('power', 245),\n",
       " ('people', 40),\n",
       " ('tactics', 33),\n",
       " ('powerful', 31),\n",
       " ('social', 27),\n",
       " ('control', 23),\n",
       " ('group', 23),\n",
       " ('influence', 22),\n",
       " ('use', 20),\n",
       " ('coercive', 20)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS_TFu = Cleaner.remove_numerals(TOKENS_TF, remove_any = True, exceptions = [])\n",
    "print(\"Reduction due to partially numeral terms = {}\".format(len(TOKENS_TF) - len(TOKENS_TFu)))\n",
    "TOKENS_TF = TOKENS_TFu\n",
    "TOKENS_TF.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Removing very short terms\n",
    "Terms such a, s, *, -, etc are removed  via the operation below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction due to short terms = 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('power', 245),\n",
       " ('people', 40),\n",
       " ('tactics', 33),\n",
       " ('powerful', 31),\n",
       " ('social', 27),\n",
       " ('control', 23),\n",
       " ('group', 23),\n",
       " ('influence', 22),\n",
       " ('use', 20),\n",
       " ('coercive', 20)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS_TFu = Cleaner.remove_short_terms(TOKENS_TF, threshold = MIN_LENGTH, exceptions = [])\n",
    "print(\"Reduction due to short terms = {}\".format(len(TOKENS_TF) - len(TOKENS_TFu)))\n",
    "TOKENS_TF = TOKENS_TFu\n",
    "TOKENS_TF.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Removing terms with low occurance frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction due to rare terms = 1309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('power', 245),\n",
       " ('people', 40),\n",
       " ('tactics', 33),\n",
       " ('powerful', 31),\n",
       " ('social', 27),\n",
       " ('control', 23),\n",
       " ('group', 23),\n",
       " ('influence', 22),\n",
       " ('use', 20),\n",
       " ('coercive', 20)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS_TFu = Cleaner.remove_rare_terms(TOKENS_TF, below = MIN_FREQ)\n",
    "print(\"Reduction due to rare terms = {}\".format(len(TOKENS_TF) - len(TOKENS_TFu)))\n",
    "TOKENS_TF = TOKENS_TFu\n",
    "TOKENS_TF.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Removing terms that contain not allowed symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\".,():;!?\\n`'=+/\\\\[]}{|><@#$%^&*_‘’“”.\"\n",
      "Reduction due to terms with not allowed symbols = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('power', 245),\n",
       " ('people', 40),\n",
       " ('tactics', 33),\n",
       " ('powerful', 31),\n",
       " ('social', 27),\n",
       " ('control', 23),\n",
       " ('group', 23),\n",
       " ('influence', 22),\n",
       " ('use', 20),\n",
       " ('coercive', 20)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.pprint(NOTALLOWED)\n",
    "TOKENS_TFu = Cleaner.remove_contains(TOKENS_TF, literals = NOTALLOWED)\n",
    "print(\"Reduction due to terms with not allowed symbols = {}\".format(len(TOKENS_TF) - len(TOKENS_TFu)))\n",
    "TOKENS_TF = TOKENS_TFu\n",
    "TOKENS_TF.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total term count reduction during cleaning process = 5884\n",
      "Percentage = 4.9%\n"
     ]
    }
   ],
   "source": [
    "print(\"The total term count reduction during cleaning process = {}\".format(len(TOKENS) - len(TOKENS_TFu)))\n",
    "print(\"Percentage = {}%\".format((round(100 * len(TOKENS_TFu)/len(TOKENS),1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Anayzing a cleaned corpus\n",
    "A generic Corpus module that is designed and implemented for this provides a collection of tools for the purpose.\n",
    "\n",
    "\n",
    "Inspection below can be beneficial for both to improve cleaning and tokenization steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Corpus in module omterms.datauis:\n",
      "\n",
      "class Corpus(builtins.object)\n",
      " |  A generic class to be used for foreground or background corpuses.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      tf_dist: (:obj:`nltk.FreqDist`): An NLTK container for tokenized and cleaned\n",
      " |          terms in the corpus.\n",
      " |      stemmer (x :obj:`str` -> y: :obj:`str`): A stemmer function.\n",
      " |      stems (:obj:`dict`): A dictionary of terms and their stems\n",
      " |      labels (:obj:`dict`): Term level labels.\n",
      " |      scores (:obj:`dict`): A dictionary of terms and their corpus sepcificity scores\n",
      " |          as of a reference corpus\n",
      " |      ref (:obj:`dict`): A dictionary of terms that holds normalized occurance frequency of\n",
      " |          the term at a reference corpus.\n",
      " |      sepficifs (:obj:`set`): A set of terms appointed/associated with the corpus externally.        \n",
      " |      To be implemented:\n",
      " |          texts_raw (:obj:`json`): A JSON collection of raw texts of the corpus.\n",
      " |      \n",
      " |          texts_clean (:obj:`json`): A JSON collection of cleaned/processed\n",
      " |          texts of the corpus.\n",
      " |      \n",
      " |          tf_idf (:obj:`json`): Tf-Idf analyses of the corpus (to be implemented).\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, tf_dist, stemmer=None)\n",
      " |      The class constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          tf_dist (:obj:`nltk.FreqDist`): An NLTK container for tokenized and cleaned\n",
      " |          terms in the corpus.\n",
      " |          stemmer (x :obj:`str` -> y: :obj:`str`): A stemmer function (default None)\n",
      " |  \n",
      " |  compute_stems(self)\n",
      " |      The function returns the a dictionary of terms and their corresponding stems.\n",
      " |      \n",
      " |      Args:\n",
      " |          stemmer (x :obj:`str` -> y: :obj:`str`): A stemmer function (default None)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True\n",
      " |  \n",
      " |  difference(self, other, as_corpus=False, stats=False)\n",
      " |      The method identifies and returns the difference of the self from the other.\n",
      " |      \n",
      " |      Note:\n",
      " |          Implementation needs style and refactoring.\n",
      " |          \n",
      " |      Args:\n",
      " |          other (:obj:`Corpus`): An instance of this Corpus Class object.\n",
      " |          as_corpus (bool): When True it returns a new Corpus (default False).\n",
      " |          stats (bool): When True and as_corpus is false returns the frequency \n",
      " |              count of the difference set.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`dict`): A dictionary of terms and their frequency counts.\n",
      " |  \n",
      " |  get_count_uniques(self)\n",
      " |      The method identifies and returns top frequent terms.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`int`): Returns an integer.\n",
      " |  \n",
      " |  get_least_frequents(self, bottom=42)\n",
      " |      The method identifies and returns least frequent terms.\n",
      " |      \n",
      " |      Args:\n",
      " |          bottom (int): Size of the short list (default 42).\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list` of :obj:`tuple` of :obj:`str` and :obj:`int`): Returns the frequency dist\n",
      " |              for the least frequent terms as list of tuples of term and frequency pairs.\n",
      " |  \n",
      " |  get_size(self)\n",
      " |      The returns the size of the corpus in terms of number of terms it has.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`int`): Returns an integer. It is summation of raw frequency counts.\n",
      " |  \n",
      " |  get_stems(self)\n",
      " |      The function returns the a dictionary of terms and their corresponding stems.\n",
      " |      \n",
      " |      Args:\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`dict`): A dictionary of {term:stem of the term}.\n",
      " |  \n",
      " |  get_top_frequents(self, top=42)\n",
      " |      The method identifies and returns top frequent terms.\n",
      " |      \n",
      " |      Args:\n",
      " |          top (int): Size of the short list (default 42).\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list` of :obj:`tuple` of :obj:`str` and :obj:`int`): Returns the frequency dist\n",
      " |              for top terms as list of tuples of term and frequency pairs.\n",
      " |  \n",
      " |  intersection(self, other, as_corpus=False, stats=False)\n",
      " |      The method identifies and returns the intersection of two corpora.\n",
      " |      \n",
      " |      Args:\n",
      " |          other (:obj:`Corpus`): An instance of this Class object.\n",
      " |          as_corpus (bool): When True it returns a new Corpus (default False).\n",
      " |          stats (bool): When True and as_corpus is false returns the frequency \n",
      " |              count of the intersections.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list` of :obj:`str`): If as_corpus is False and stats is False \n",
      " |              it returns the list of joint terms.\n",
      " |          (:obj:`list` of :obj:`tuple` of :obj:`str` and :obj:`int`): Returns the frequency dist\n",
      " |              for the joint terms, if as_corpus is False and stats is True. \n",
      " |          (:obj:`Corpus`): In all other cases it returns a nrew Corpus class for the intersection.\n",
      " |              Frequencies are the minimum of the two occurances.\n",
      " |  \n",
      " |  label(self, marker, labels=None)\n",
      " |      The function labels yet not labeled terms according to the user defined scheme.\n",
      " |      \n",
      " |      Args:\n",
      " |          marker (x :obj:`str` -> y: :obj:`str`): A marker function\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`dict`): A dictionary of {term:label of term}.\n",
      " |  \n",
      " |  list_terms(self)\n",
      " |      It returns the list terms in the corpus\n",
      " |      \n",
      " |      Note:\n",
      " |          Implementation needs refactoring.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list`): An alphabetically sorted list.\n",
      " |  \n",
      " |  plot(self, top, cumulative=False)\n",
      " |      Plotting.\n",
      " |      \n",
      " |      Note:\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True\n",
      " |  \n",
      " |  set_specific_set(self, terms)\n",
      " |      The function sets the set of corpus specific terms.\n",
      " |      \n",
      " |      Args:\n",
      " |          terms (:obj:`set`): The list of corpus specific terms\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  set_stemmer(self, stemmer)\n",
      " |      The appointing a new stemmer function to the corpus.\n",
      " |      \n",
      " |      Args:\n",
      " |          stemmer (x :obj:`str` -> y: :obj:`str`): A stemmer function (default None)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True\n",
      " |  \n",
      " |  tabulate(self, top)\n",
      " |      Tabulating.\n",
      " |      \n",
      " |      Note:\n",
      " |          Works better when used to see few top terms.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True\n",
      " |  \n",
      " |  to_pandas(self)\n",
      " |      The function exports its data into pandas dataframe.\n",
      " |      \n",
      " |      Note:\n",
      " |          ToDo: The function needs parameterization, generalization and error checks.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`pandas.DataFrame`) The tabulated data\n",
      " |  \n",
      " |  union(self, other, as_corpus=False, stats=False)\n",
      " |      The method identifies and returns the union of two corpora.\n",
      " |      \n",
      " |      Args:\n",
      " |          other (:obj:`Corpus`): An instance of this Class object.\n",
      " |          as_corpus (bool): When True it returns a new Corpus (default False).\n",
      " |          stats (bool): When True and as_corpus is false returns the frequency \n",
      " |              count of the union.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list` of :obj:`str`): If as_corpus is False and stats is False \n",
      " |              it returns the list of union of terms in both cases.\n",
      " |          (:obj:`list` of :obj:`tuple` of :obj:`str` and :obj:`int`): Returns the frequency dist\n",
      " |              for the union terms, ff as_corpus is False and stats is True. \n",
      " |          (:obj:`Corpus`): In all other cases it returns a nrew Corpus class for the intersection.\n",
      " |              Frequencies are the minimum of the two occurances.\n",
      " |      \n",
      " |      Examples:\n",
      " |          >>> Corpus(FreqDist('abbbc')).union(Corpus(FreqDist('bccd')), stats = True)\n",
      " |          [('a', 1), ('b', 3), ('c', 2), ('d', 1)]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __slotnames__ = []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words = 306\n",
      "Number of words = 1948\n",
      "\n",
      "Most frequents ::>>\n",
      "[('power', 245),\n",
      " ('people', 40),\n",
      " ('tactics', 33),\n",
      " ('powerful', 31),\n",
      " ('social', 27),\n",
      " ('control', 23),\n",
      " ('group', 23),\n",
      " ('influence', 22),\n",
      " ('use', 20),\n",
      " ('coercive', 20),\n",
      " ('person', 19),\n",
      " ('theory', 18),\n",
      " ('others', 18),\n",
      " ('will', 15),\n",
      " ('actions', 14),\n",
      " ('given', 14),\n",
      " ('relationship', 14),\n",
      " ('individuals', 13),\n",
      " ('tend', 13),\n",
      " ('less', 13),\n",
      " ('change', 12),\n",
      " ('relationships', 12),\n",
      " ('rewards', 12),\n",
      " ('authority', 11),\n",
      " ('reward', 11),\n",
      " ('negative', 10),\n",
      " ('personal', 10),\n",
      " ('leads', 10),\n",
      " ('different', 10),\n",
      " ('political', 9),\n",
      " ('much', 9),\n",
      " ('referent', 9),\n",
      " ('rational', 9),\n",
      " ('choice', 9),\n",
      " ('counterpower', 9),\n",
      " ('positive', 9),\n",
      " ('likely', 9),\n",
      " ('members', 9),\n",
      " ('ability', 8),\n",
      " ('used', 8),\n",
      " ('soft', 8),\n",
      " ('unmarked', 8)]\n",
      "\n",
      "Least frequents ::>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('love', 3),\n",
       " ('attention', 3),\n",
       " ('particularly', 3),\n",
       " ('include', 3),\n",
       " ('collaboration', 3),\n",
       " ('harsh', 3),\n",
       " ('nonrational', 3),\n",
       " ('parties', 3),\n",
       " ('carry', 3),\n",
       " ('stage', 3)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SC = Corpus(TOKENS_TF)\n",
    "print('Number of unique words = {}'.format(SC.get_count_uniques()))\n",
    "print('Number of words = {}'.format(SC.get_size()))\n",
    "print('\\nMost frequents ::>>')\n",
    "pp.pprint(SC.get_top_frequents(top = 42))\n",
    "print('\\nLeast frequents ::>>')\n",
    "SC.get_least_frequents(bottom = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAE7CAYAAADHHRb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115c10b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAE7CAYAAADHHRb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115c167b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SC.plot(20), SC.plot(20, cumulative = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   power   people  tactics powerful   social  control    group \n",
      "     245       40       33       31       27       23       23 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SC.tabulate(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = SC.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245</td>\n",
       "      <td>power</td>\n",
       "      <td>0.125770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40</td>\n",
       "      <td>people</td>\n",
       "      <td>0.020534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>33</td>\n",
       "      <td>tactics</td>\n",
       "      <td>0.016940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>31</td>\n",
       "      <td>powerful</td>\n",
       "      <td>0.015914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>social</td>\n",
       "      <td>0.013860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TF      Term       wTF\n",
       "0    245     power  0.125770\n",
       "21    40    people  0.020534\n",
       "89    33   tactics  0.016940\n",
       "183   31  powerful  0.015914\n",
       "1     27    social  0.013860"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245</td>\n",
       "      <td>power</td>\n",
       "      <td>0.125770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40</td>\n",
       "      <td>people</td>\n",
       "      <td>0.020534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>33</td>\n",
       "      <td>tactics</td>\n",
       "      <td>0.016940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>31</td>\n",
       "      <td>powerful</td>\n",
       "      <td>0.015914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>social</td>\n",
       "      <td>0.013860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>control</td>\n",
       "      <td>0.011807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>23</td>\n",
       "      <td>group</td>\n",
       "      <td>0.011807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>influence</td>\n",
       "      <td>0.011294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20</td>\n",
       "      <td>use</td>\n",
       "      <td>0.010267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>20</td>\n",
       "      <td>coercive</td>\n",
       "      <td>0.010267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TF       Term       wTF\n",
       "0    245      power  0.125770\n",
       "21    40     people  0.020534\n",
       "89    33    tactics  0.016940\n",
       "183   31   powerful  0.015914\n",
       "1     27     social  0.013860\n",
       "24    23    control  0.011807\n",
       "151   23      group  0.011807\n",
       "23    22  influence  0.011294\n",
       "36    20        use  0.010267\n",
       "64    20   coercive  0.010267"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='wTF', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3</td>\n",
       "      <td>satisfaction</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3</td>\n",
       "      <td>creates</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>3</td>\n",
       "      <td>holder</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3</td>\n",
       "      <td>reduction</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3</td>\n",
       "      <td>including</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3</td>\n",
       "      <td>outcome</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3</td>\n",
       "      <td>appropriate</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3</td>\n",
       "      <td>draw</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>3</td>\n",
       "      <td>quality</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>3</td>\n",
       "      <td>stage</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TF          Term      wTF\n",
       "142   3  satisfaction  0.00154\n",
       "141   3       creates  0.00154\n",
       "131   3        holder  0.00154\n",
       "125   3     reduction  0.00154\n",
       "124   3     including  0.00154\n",
       "123   3       outcome  0.00154\n",
       "121   3   appropriate  0.00154\n",
       "120   3          draw  0.00154\n",
       "119   3       quality  0.00154\n",
       "305   3         stage  0.00154"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='wTF', ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full list of terms ::>>\n"
     ]
    }
   ],
   "source": [
    "print(\"The full list of terms ::>>\")\n",
    "#SC.list_terms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SC.set_stemmer(STEMMER_FUNC)\n",
    "SC.compute_stems()\n",
    "#SC.stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245</td>\n",
       "      <td>power</td>\n",
       "      <td>power</td>\n",
       "      <td>0.125770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40</td>\n",
       "      <td>people</td>\n",
       "      <td>peopl</td>\n",
       "      <td>0.020534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>33</td>\n",
       "      <td>tactics</td>\n",
       "      <td>tactic</td>\n",
       "      <td>0.016940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>31</td>\n",
       "      <td>powerful</td>\n",
       "      <td>power</td>\n",
       "      <td>0.015914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>social</td>\n",
       "      <td>social</td>\n",
       "      <td>0.013860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TF      Term    Stem       wTF\n",
       "0    245     power   power  0.125770\n",
       "21    40    people   peopl  0.020534\n",
       "89    33   tactics  tactic  0.016940\n",
       "183   31  powerful   power  0.015914\n",
       "1     27    social  social  0.013860"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = SC.to_pandas()\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Computing specificity of terms in a corpus with respect to a reference background corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Scoring in module omterms.measures:\n",
      "\n",
      "class Scoring(builtins.object)\n",
      " |  The object given term frequency distribution of a foreground specific corpus and a background\n",
      " |  reference corpus, provides tools that help to compute specificity of each term in the foreground corpus.\n",
      " |  \n",
      " |  This kind of scoring is mainly to be used for the cases where an input text around a specific\n",
      " |  theme or topic is given. The process expects a tokenized, cleaned text with term counts.\n",
      " |  \n",
      " |  Note:\n",
      " |      It consumes a Corpus object and uses its methods and attributed and mutates it unless desired otherwise.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      sCorpus (:obj:`Corpus`): A Corpus class instance of the specific corpus to be scored.\n",
      " |      rCorpus (:obj:`Corpus`): A Corpus class instance of the reference corpus.\n",
      " |      common (:obj:`list` of `str`): The common terms between the foreground and backgrouns corpus\n",
      " |      distinct (:obj:`list` of `str`): The terms observed in the foreground but not in the backgrouns corpus\n",
      " |      model: a prediction model created during instantiation process using the data of the class instance.\n",
      " |          For details see`form_prediction_model` method description.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, sCorpus, rCorpus, nsteps=3, mutate=False, model_threshold=1.0)\n",
      " |      The class constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          sCorpus (:obj:`Corpus`): A Corpus class instance of the specific corpus to be scored.\n",
      " |          rCorpus (:obj:`Corpus`): A Corpus class instance of the reference corpus.\n",
      " |          nsteps (:obj:`int`):  Number of phases to process at init.\n",
      " |              1-> raw, 2 -> raw,stem, 3 ->raw,stem,noref (default 3)\n",
      " |          mutate (:obj:`bool`, optional): A flag when true mutates the input Corpus object \n",
      " |              for specific text corpus (default False).\n",
      " |          model_threshold (:obj:`float` or None) :  The minimum score value used for prediction model.\n",
      " |  \n",
      " |  compute_commons(self)\n",
      " |      Computes the specifity score of the terms in the corpus.\n",
      " |      \n",
      " |      Note:\n",
      " |          It is a simple log likelihood measure. It compares frequency count of a term in\n",
      " |          a specific corpus versus its frequency count in the reference reference corpus.\n",
      " |          Here assumption is that the reference corpus is a large enough sample of the language\n",
      " |          at observing the occurance of a term. Then having a higher/lower observation frequency of\n",
      " |          a term in the specific corpus is a proxy indicator for the term choice while having a debate\n",
      " |          on the topic.\n",
      " |      \n",
      " |          The likelihood ratio for a term $P_t$ is calculated as:\n",
      " |          .. math::\n",
      " |              $P_t = log ( (ntS/NS) / (ntR/NR) )$\n",
      " |          \n",
      " |          where\n",
      " |              - *ntS* is the raw frequency count of the term in the entire specific corpus\n",
      " |              - *ntR* is the raw frequenccy count of the term in the reference corpus\n",
      " |              - *NS* is the total number of terms in the specific corpus\n",
      " |              - *NR* is the total number of terms in the reference corpus\n",
      " |          \n",
      " |          It should be noted that frequency counts are calculated after having applied the same tokenization\n",
      " |          and post processing such as excluding stop-words, pancuations, rare terms, etc both on the reference\n",
      " |          corpus and the specific corpus.\n",
      " |          \n",
      " |      Args:\n",
      " |          None\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  compute_distincts(self)\n",
      " |      Computes the specifity score of the terms in the corpus when neither the term nor its stems\n",
      " |          matched by the background corpus.\n",
      " |          \n",
      " |      Note:\n",
      " |          It uses a log linear regression model to predict likelihood of the dictinct terms.\n",
      " |          The model is trained using the scores and frequencies within the matching set.\n",
      " |          \n",
      " |          See `form_prediction_model` method description for details.\n",
      " |          \n",
      " |      Args:\n",
      " |          None\n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  compute_stem_commons(self)\n",
      " |      Computes the specifity score of the terms in the corpus when the term as it is not \n",
      " |          matched by a term in the reference corpus. It matches the stems. The loglikelihood\n",
      " |          ration is applied over the mean frequency counts of the matching stems.\n",
      " |          \n",
      " |          See `compute_commons` method description for details.\n",
      " |          \n",
      " |      Args:\n",
      " |          None\n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  form_prediction_model(self, threshold=1.0)\n",
      " |      The method creats the prediction model to be used for distinct terms.\n",
      " |          \n",
      " |      Note:\n",
      " |          It is based on a log-linear regression. The model is created using the observed\n",
      " |          scores and frequencies within the matching set. The model aims to fit a best line\n",
      " |          to logarithm of the observed term frequencies vs associated scores.\n",
      " |          \n",
      " |          Considering the fact that frequent distinct terms are likely among the ones with a \n",
      " |          higher specificity, the terms with relatively high scores are used for the regression.\n",
      " |          The R-squared of the regression tests have been used for validation of the approach.\n",
      " |          In the same reasoning among the all distinct terms the ones with relatively higher frequencies\n",
      " |          are considered for scoring.\n",
      " |          \n",
      " |      ToDo:\n",
      " |          As a second approach, the model training to be improved considering terms with relatively high term\n",
      " |          frequencies and high specificity scores. Observe the scatter plots for the insight.\n",
      " |          \n",
      " |          An alternative, a third approach, would be forming the logarithmic bins on frequencies and using\n",
      " |          distributional charcteristics of each bin at making predictions. For instance, by simply predicting\n",
      " |          the median value as the guess. \n",
      " |          \n",
      " |      Args:\n",
      " |          threshold (:obj:`float`, optional):  The default value is driven from regression tests on \n",
      " |              test cases (default 1.0).\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  get_scores_by(self, stype='raw')\n",
      " |      The method returns computed/available scores by the label of the terms.\n",
      " |      \n",
      " |      Note:\n",
      " |          The labels in this implementation correspond:\n",
      " |          - raw: the term as it is was identified in the background corpus, so\n",
      " |              a loglikelihood scoring was applied\n",
      " |          - stem: not the term as it is but its stem was identified, so mean of the observed\n",
      " |              stem occurances in the background was used as the reference\n",
      " |          - noref: neither the term nor its stem was identified, so the prediction model was used\n",
      " |              for the frequent ones.\n",
      " |          \n",
      " |      Args:\n",
      " |          stype (:obj:`str`, optional): The term scoring type (default 'raw').\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`dict`): The term scores.\n",
      " |  \n",
      " |  plot(self, threshold=1.0, islog=True)\n",
      " |      Scatter plot of frequency vs scores.\n",
      " |                      \n",
      " |      Args:\n",
      " |          threshold (:obj:`float`, optional):  The default value is driven from regression tests on \n",
      " |              test cases (default 1.0).\n",
      " |          \n",
      " |          islog (:obj:`bool`): Whether natural log of the frequency counts to be returned (default True).\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  predict(self, w, count, minp=0.001, minf=3)\n",
      " |      The method assigns a predicted score to a given term with a a frequency\n",
      " |          over the designated threshold. An internally formed prediction model is used.\n",
      " |          The natural logorithm of raw frequency counts is passed to the model. See \n",
      " |          `form_prediction_model` method description for details.\n",
      " |          \n",
      " |      Args:\n",
      " |          count (:obj:`int`): The raw frequency count.\n",
      " |          minp (:obj:`float`, optional): The relative frequency threshold (default 0.001).\n",
      " |          minf (:obj:`int`, optional): The raw frequency threshold (default 3).\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`float`): The predicted score.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Loading and preparing a reference corpus\n",
    "For the demonstration purpose a NLTK's Brown corpus is used. \n",
    "\n",
    "However for a more sound comparison foreground corpus needs to a sample or a driven niche of the background corpus. In that respect full Wikipedia Corpus needs to be inetgrated into this work:\n",
    "\n",
    "https://github.com/pavlobaron/wpcorpus\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the first timers: uncomment the command below for an interaction download process\n",
    "#nltk.download()\n",
    "from nltk.corpus import brown\n",
    "TOKENSREF = list(nltk.corpus.brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning process: Initial size of tokens = 1161192\n",
      "Initial state:\n",
      "Total term counts: 1161192\n",
      "[('the', 69971),\n",
      " (',', 58334),\n",
      " ('.', 49346),\n",
      " ('of', 36412),\n",
      " ('and', 28853),\n",
      " ('to', 26158),\n",
      " ('a', 23195),\n",
      " ('in', 21337),\n",
      " ('that', 10594),\n",
      " ('is', 10109)]\n",
      "Removing panctuation only terms...\n",
      "Total term counts: 1016830\n",
      "[('the', 69971),\n",
      " ('of', 36412),\n",
      " ('and', 28853),\n",
      " ('to', 26158),\n",
      " ('a', 23195),\n",
      " ('in', 21337),\n",
      " ('that', 10594),\n",
      " ('is', 10109),\n",
      " ('was', 9815),\n",
      " ('he', 9548)]\n",
      "Removing stopwords...\n",
      "Total term counts: 526248\n",
      "[('--', 3432),\n",
      " ('will', 2245),\n",
      " ('said', 1961),\n",
      " ('new', 1635),\n",
      " ('time', 1598),\n",
      " ('two', 1412),\n",
      " ('now', 1314),\n",
      " ('man', 1207),\n",
      " ('even', 1170),\n",
      " ('made', 1125)]\n",
      "Reduction due to punctuations and stopwords = 1111606.\n",
      "Reduction due to all numeral terms = 1747\n",
      "Reduction due to short terms = 178\n",
      "Reduction due to rare terms = 27810\n",
      "Reduction due to partially numeral terms = 49\n",
      "Reduction due to terms with not allowed symbols = 645\n",
      "The total term count reduction during this cleaning process = 1142035\n",
      "Percentage = 98%\n"
     ]
    }
   ],
   "source": [
    "TOKENSREF_TF = run_cleaning_process(Cleaner, TOKENSREF,\n",
    "                                    minL = MIN_LENGTH,\n",
    "                                    minF = MIN_FREQ,\n",
    "                                    notallowed = NOTALLOWED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words = 19157\n",
      "Number of words = 467021\n",
      "\n",
      "Most frequents ::>>\n",
      "[('will', 2245),\n",
      " ('said', 1961),\n",
      " ('new', 1635),\n",
      " ('time', 1598),\n",
      " ('two', 1412),\n",
      " ('now', 1314),\n",
      " ('man', 1207),\n",
      " ('even', 1170),\n",
      " ('made', 1125),\n",
      " ('must', 1013),\n",
      " ('back', 966),\n",
      " ('years', 950),\n",
      " ('much', 937),\n",
      " ('way', 908),\n",
      " ('people', 847),\n",
      " ('little', 831),\n",
      " ('state', 807),\n",
      " ('good', 806),\n",
      " ('make', 794),\n",
      " ('world', 787)]\n",
      "\n",
      "Least frequents ::>>\n",
      "[('quintus', 3),\n",
      " ('longue', 3),\n",
      " ('steels', 3),\n",
      " ('lovejoy', 3),\n",
      " ('fairview', 3),\n",
      " ('carraway', 3),\n",
      " ('peony', 3),\n",
      " ('ballplayers', 3),\n",
      " ('fudomae', 3),\n",
      " ('anthea', 3),\n",
      " ('herberet', 3),\n",
      " ('jennie', 3),\n",
      " ('pioneers', 3),\n",
      " ('poitrine', 3),\n",
      " ('bookies', 3),\n",
      " ('feeley', 3),\n",
      " ('crumb', 3),\n",
      " ('saleslady', 3),\n",
      " ('non-fiction', 3),\n",
      " ('quasimodo', 3)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEhCAYAAACHjCx5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d0e5b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEhCAYAAAC3AD1YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115c33860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will said  new time  two  now  man \n",
      "2245 1961 1635 1598 1412 1314 1207 \n"
     ]
    }
   ],
   "source": [
    "CRef = Corpus(TOKENSREF_TF)\n",
    "DF_Brown = summary_corpus(CRef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2245</td>\n",
       "      <td>will</td>\n",
       "      <td>0.004807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1961</td>\n",
       "      <td>said</td>\n",
       "      <td>0.004199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1635</td>\n",
       "      <td>new</td>\n",
       "      <td>0.003501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1598</td>\n",
       "      <td>time</td>\n",
       "      <td>0.003422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1412</td>\n",
       "      <td>two</td>\n",
       "      <td>0.003023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>1314</td>\n",
       "      <td>now</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>1207</td>\n",
       "      <td>man</td>\n",
       "      <td>0.002584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>1170</td>\n",
       "      <td>even</td>\n",
       "      <td>0.002505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1125</td>\n",
       "      <td>made</td>\n",
       "      <td>0.002409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1013</td>\n",
       "      <td>must</td>\n",
       "      <td>0.002169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TF  Term       wTF\n",
       "147   2245  will  0.004807\n",
       "4     1961  said  0.004199\n",
       "182   1635   new  0.003501\n",
       "370   1598  time  0.003422\n",
       "76    1412   two  0.003023\n",
       "667   1314   now  0.002814\n",
       "262   1207   man  0.002584\n",
       "1181  1170  even  0.002505\n",
       "398   1125  made  0.002409\n",
       "344   1013  must  0.002169"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_Brown.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming the terms in the corpus ..\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2245</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>0.004807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1961</td>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "      <td>0.004199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1635</td>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>0.003501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1598</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>0.003422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1412</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>0.003023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TF  Term  Stem       wTF\n",
       "147  2245  will  will  0.004807\n",
       "4    1961  said  said  0.004199\n",
       "182  1635   new   new  0.003501\n",
       "370  1598  time  time  0.003422\n",
       "76   1412   two   two  0.003023"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRef = run_stemming_process(CRef, STEMMER_FUNC)\n",
    "CRef.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Scoring in module omterms.measures:\n",
      "\n",
      "class Scoring(builtins.object)\n",
      " |  The object given term frequency distribution of a foreground specific corpus and a background\n",
      " |  reference corpus, provides tools that help to compute specificity of each term in the foreground corpus.\n",
      " |  \n",
      " |  This kind of scoring is mainly to be used for the cases where an input text around a specific\n",
      " |  theme or topic is given. The process expects a tokenized, cleaned text with term counts.\n",
      " |  \n",
      " |  Note:\n",
      " |      It consumes a Corpus object and uses its methods and attributed and mutates it unless desired otherwise.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      sCorpus (:obj:`Corpus`): A Corpus class instance of the specific corpus to be scored.\n",
      " |      rCorpus (:obj:`Corpus`): A Corpus class instance of the reference corpus.\n",
      " |      common (:obj:`list` of `str`): The common terms between the foreground and backgrouns corpus\n",
      " |      distinct (:obj:`list` of `str`): The terms observed in the foreground but not in the backgrouns corpus\n",
      " |      model: a prediction model created during instantiation process using the data of the class instance.\n",
      " |          For details see`form_prediction_model` method description.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, sCorpus, rCorpus, nsteps=3, mutate=False, model_threshold=1.0)\n",
      " |      The class constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          sCorpus (:obj:`Corpus`): A Corpus class instance of the specific corpus to be scored.\n",
      " |          rCorpus (:obj:`Corpus`): A Corpus class instance of the reference corpus.\n",
      " |          nsteps (:obj:`int`):  Number of phases to process at init.\n",
      " |              1-> raw, 2 -> raw,stem, 3 ->raw,stem,noref (default 3)\n",
      " |          mutate (:obj:`bool`, optional): A flag when true mutates the input Corpus object \n",
      " |              for specific text corpus (default False).\n",
      " |          model_threshold (:obj:`float` or None) :  The minimum score value used for prediction model.\n",
      " |  \n",
      " |  compute_commons(self)\n",
      " |      Computes the specifity score of the terms in the corpus.\n",
      " |      \n",
      " |      Note:\n",
      " |          It is a simple log likelihood measure. It compares frequency count of a term in\n",
      " |          a specific corpus versus its frequency count in the reference reference corpus.\n",
      " |          Here assumption is that the reference corpus is a large enough sample of the language\n",
      " |          at observing the occurance of a term. Then having a higher/lower observation frequency of\n",
      " |          a term in the specific corpus is a proxy indicator for the term choice while having a debate\n",
      " |          on the topic.\n",
      " |      \n",
      " |          The likelihood ratio for a term $P_t$ is calculated as:\n",
      " |          .. math::\n",
      " |              $P_t = log ( (ntS/NS) / (ntR/NR) )$\n",
      " |          \n",
      " |          where\n",
      " |              - *ntS* is the raw frequency count of the term in the entire specific corpus\n",
      " |              - *ntR* is the raw frequenccy count of the term in the reference corpus\n",
      " |              - *NS* is the total number of terms in the specific corpus\n",
      " |              - *NR* is the total number of terms in the reference corpus\n",
      " |          \n",
      " |          It should be noted that frequency counts are calculated after having applied the same tokenization\n",
      " |          and post processing such as excluding stop-words, pancuations, rare terms, etc both on the reference\n",
      " |          corpus and the specific corpus.\n",
      " |          \n",
      " |      Args:\n",
      " |          None\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  compute_distincts(self)\n",
      " |      Computes the specifity score of the terms in the corpus when neither the term nor its stems\n",
      " |          matched by the background corpus.\n",
      " |          \n",
      " |      Note:\n",
      " |          It uses a log linear regression model to predict likelihood of the dictinct terms.\n",
      " |          The model is trained using the scores and frequencies within the matching set.\n",
      " |          \n",
      " |          See `form_prediction_model` method description for details.\n",
      " |          \n",
      " |      Args:\n",
      " |          None\n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  compute_stem_commons(self)\n",
      " |      Computes the specifity score of the terms in the corpus when the term as it is not \n",
      " |          matched by a term in the reference corpus. It matches the stems. The loglikelihood\n",
      " |          ration is applied over the mean frequency counts of the matching stems.\n",
      " |          \n",
      " |          See `compute_commons` method description for details.\n",
      " |          \n",
      " |      Args:\n",
      " |          None\n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  form_prediction_model(self, threshold=1.0)\n",
      " |      The method creats the prediction model to be used for distinct terms.\n",
      " |          \n",
      " |      Note:\n",
      " |          It is based on a log-linear regression. The model is created using the observed\n",
      " |          scores and frequencies within the matching set. The model aims to fit a best line\n",
      " |          to logarithm of the observed term frequencies vs associated scores.\n",
      " |          \n",
      " |          Considering the fact that frequent distinct terms are likely among the ones with a \n",
      " |          higher specificity, the terms with relatively high scores are used for the regression.\n",
      " |          The R-squared of the regression tests have been used for validation of the approach.\n",
      " |          In the same reasoning among the all distinct terms the ones with relatively higher frequencies\n",
      " |          are considered for scoring.\n",
      " |          \n",
      " |      ToDo:\n",
      " |          As a second approach, the model training to be improved considering terms with relatively high term\n",
      " |          frequencies and high specificity scores. Observe the scatter plots for the insight.\n",
      " |          \n",
      " |          An alternative, a third approach, would be forming the logarithmic bins on frequencies and using\n",
      " |          distributional charcteristics of each bin at making predictions. For instance, by simply predicting\n",
      " |          the median value as the guess. \n",
      " |          \n",
      " |      Args:\n",
      " |          threshold (:obj:`float`, optional):  The default value is driven from regression tests on \n",
      " |              test cases (default 1.0).\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  get_scores_by(self, stype='raw')\n",
      " |      The method returns computed/available scores by the label of the terms.\n",
      " |      \n",
      " |      Note:\n",
      " |          The labels in this implementation correspond:\n",
      " |          - raw: the term as it is was identified in the background corpus, so\n",
      " |              a loglikelihood scoring was applied\n",
      " |          - stem: not the term as it is but its stem was identified, so mean of the observed\n",
      " |              stem occurances in the background was used as the reference\n",
      " |          - noref: neither the term nor its stem was identified, so the prediction model was used\n",
      " |              for the frequent ones.\n",
      " |          \n",
      " |      Args:\n",
      " |          stype (:obj:`str`, optional): The term scoring type (default 'raw').\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`dict`): The term scores.\n",
      " |  \n",
      " |  plot(self, threshold=1.0, islog=True)\n",
      " |      Scatter plot of frequency vs scores.\n",
      " |                      \n",
      " |      Args:\n",
      " |          threshold (:obj:`float`, optional):  The default value is driven from regression tests on \n",
      " |              test cases (default 1.0).\n",
      " |          \n",
      " |          islog (:obj:`bool`): Whether natural log of the frequency counts to be returned (default True).\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  predict(self, w, count, minp=0.001, minf=3)\n",
      " |      The method assigns a predicted score to a given term with a a frequency\n",
      " |          over the designated threshold. An internally formed prediction model is used.\n",
      " |          The natural logorithm of raw frequency counts is passed to the model. See \n",
      " |          `form_prediction_model` method description for details.\n",
      " |          \n",
      " |      Args:\n",
      " |          count (:obj:`int`): The raw frequency count.\n",
      " |          minp (:obj:`float`, optional): The relative frequency threshold (default 0.001).\n",
      " |          minf (:obj:`int`, optional): The raw frequency threshold (default 3).\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`float`): The predicted score.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275 / 306  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "31 / 306 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "9 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n"
     ]
    }
   ],
   "source": [
    "myScoring = Scoring(SC,CRef)\n",
    "SCored = copy.deepcopy(myScoring.sCorpus)\n",
    "DF = SCored.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117aa6a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myScoring.plot(threshold = 1.0, islog = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abuser': 4.2755982149916791,\n",
       " 'abusers': 4.2755982149916791,\n",
       " 'abusive': 5.1228960753788826,\n",
       " 'authoritys': 3.407972655098805,\n",
       " 'episodic': 4.6686408031012858,\n",
       " 'internalization': 3.2326748321841579,\n",
       " 'referent': 4.2162816378352597,\n",
       " 'reinforcement': 5.1166655256282461,\n",
       " 'relational': 3.1703413836049004}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myScoring.get_scores_by('stem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bjrn': 2.7982323816182508,\n",
       " 'clegg': 2.7982323816182508,\n",
       " 'coercive': 3.5334402907275293,\n",
       " 'constraint': 2.7982323816182508,\n",
       " 'counterpower': 3.2239874472484442,\n",
       " 'empathy': 2.9961972134478141,\n",
       " 'foucault': 3.1265933146593485,\n",
       " 'galbraith': 2.7982323816182508,\n",
       " 'gender': 2.7982323816182508,\n",
       " 'gramsci': 2.7982323816182508,\n",
       " 'hegemony': 2.9961972134478141,\n",
       " 'kelman': 2.7982323816182508,\n",
       " 'kraus': 2.7982323816182508,\n",
       " 'literacy': 3.0668539202581084,\n",
       " 'macro': 2.7982323816182508,\n",
       " 'nonrational': 2.7982323816182508,\n",
       " 'prerogative': 2.7982323816182508,\n",
       " 'protagonist': 2.9097203932677727,\n",
       " 'raven': 2.9097203932677727,\n",
       " 'reprimanded': 2.7982323816182508,\n",
       " 'tarnow': 2.7982323816182508,\n",
       " 'unmarked': 3.1783419319076303}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myScoring.get_scores_by('noref')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exporting topic specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvfile_name = OUTPUT_FOLDER + OUTPUT_FNAME_PREFIX + \".csv\"\n",
    "with open(csvfile_name, 'w') as csvfile:\n",
    "    DF.to_csv(csvfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/Power.csv\n"
     ]
    }
   ],
   "source": [
    "print(csvfile_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exporting part of data\n",
    "\n",
    "#### Selecting a specific range of scores\n",
    "\n",
    "Note that with the function below a specific slice between a mix and max value can be determined. Besides, the filterin can be applied to any column as long as its data type is a number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTF</th>\n",
       "      <th>SType</th>\n",
       "      <th>Score</th>\n",
       "      <th>wTFref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>12</td>\n",
       "      <td>rewards</td>\n",
       "      <td>reward</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>raw</td>\n",
       "      <td>6.578183</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>7</td>\n",
       "      <td>interpersonal</td>\n",
       "      <td>interperson</td>\n",
       "      <td>0.003593</td>\n",
       "      <td>raw</td>\n",
       "      <td>6.326869</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>33</td>\n",
       "      <td>tactics</td>\n",
       "      <td>tactic</td>\n",
       "      <td>0.016940</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.980346</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>behaviour</td>\n",
       "      <td>behaviour</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.767253</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>4</td>\n",
       "      <td>ultimatum</td>\n",
       "      <td>ultimatum</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.767253</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TF           Term         Stem       wTF SType     Score    wTFref\n",
       "161  12        rewards       reward  0.006160   raw  6.578183  0.000009\n",
       "65    7  interpersonal  interperson  0.003593   raw  6.326869  0.000006\n",
       "89   33        tactics       tactic  0.016940   raw  5.980346  0.000043\n",
       "25    4      behaviour    behaviour  0.002053   raw  5.767253  0.000006\n",
       "282   4      ultimatum    ultimatum  0.002053   raw  5.767253  0.000006"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/Power_min4.csv\n"
     ]
    }
   ],
   "source": [
    "min_t = 4\n",
    "aslice = pandas_filter_rows(DF, col = 'Score', min_t = min_t)\n",
    "reduced = '_min{}'.format(min_t)\n",
    "filtered_csvfile_name = OUTPUT_FOLDER + OUTPUT_FNAME_PREFIX + reduced + \".csv\"\n",
    "aslice.to_csv(filtered_csvfile_name)\n",
    "print(filtered_csvfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%connect_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
