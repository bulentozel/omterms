{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Using omterms keyword extraction package\n",
    "\n",
    "Bulent Ozel, UZH\n",
    "\n",
    "```bulent.ozel@gmail.com```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first objective of this module is to provide customizable and standardized text preprocessing phase prior to further analyses where more advanced machine learning and or statistical techniques can be applied and compared with each other. In that sense, it  provides a pipelined set of functionalities (i) to be able to inspect, organize, prune and merge texts around **one or very few specific theme(s) or topic(s)**, (ii) remove unwanted terms or literals from the texts, (iii) tokenize the texts, (iv) count the terms in texts, and (v) when desired stem the tokenized terms.\n",
    "\n",
    "The second objective of this module is to be able compare or score a foreground corpus or a specific corpus against a background corpus or reference corpus. Example use cases could be, for instance, exploring the language of a sub-culture, a community, or a movement looking at to what extend the specific use of the language of the group differentiates itself from the common language. \n",
    "\n",
    "In cases when there are more than a few number of themes or topics, and where each topic is represented with a large set of documents that validates the employment of standardized matrix decomposition based methodologies, then the scoring option of this module can be skipped entirely. More specifically, in use cases where the objective is being able to classify and differentiate a number of topics or issues from each other and where there are sufficient data that fulfills the underlining assumptions of NMF, LDA or LSI based approaches, then tools, for instance, from Python’s sklearn.decomposition package are suggested.\n",
    "\n",
    "Nevertheless, the outputs of this module such as normalized term frequencies or the specificity scores associated to them with respect to a reference background corpus can be used as input to other matrix decomposition techniques.\n",
    "\n",
    "For a general introduction on keyword and keyphrase extraction see the [readme file.](https://github.com/bulentozel/omterms/blob/master/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "A single text is provided.\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 10\n",
      "Cleaning process: Initial size of tokens = 10\n",
      "Reduction due to punctuations and stopwords = 3.\n",
      "Reduction due to all numeral terms = 1\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 5\n",
      "Percentage = 50%\n",
      "COMPLETED.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>input</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>process</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>less</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>seconds</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TF     Term  wTF\n",
       "0   1    input  0.2\n",
       "1   1     text  0.2\n",
       "2   1  process  0.2\n",
       "3   1     less  0.2\n",
       "4   1  seconds  0.2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import omterms\n",
    "from omterms.interface import *\n",
    "\n",
    "extract_terms(\"Some input X text to process less then 3 seconds.\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More detailed examples: the application interface options\n",
    "\n",
    "The application interface provides an encapsualtion and standardization at preparing a set of texts for further analyses. The standardized term extraction process covers tokenization, counting both raw and normalized term occurances, cleaning, stemming(optional), and scoring(optional) choices. The tabulated output can be exported in .csv file format and/or Pandas dataframe format.\n",
    "\n",
    "A varying number of input data formats is supported including their previously tokenized and cleaned versions. For the details on input parameters and types please see docstring documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module omterms.interface in omterms:\n",
      "\n",
      "NAME\n",
      "    omterms.interface - OpenMaker term extraction application interface.\n",
      "\n",
      "DESCRIPTION\n",
      "    Author: Bulent Ozel\n",
      "    e-mail: bulent.ozel@gmail.com\n",
      "    \n",
      "    The application interface provides an encapsualtion and standardization at preparing a set of texts for\n",
      "    further analyses. The standardized term extraction process covers tokenization, counting both raw and \n",
      "    normalized, cleaning, stemming(optional), and scoring(optional) chioices. The tabulated output can be\n",
      "    exported in .csv file format and/or Pandas dataframe format.\n",
      "    \n",
      "    The input text(s) can be provided in any of the following formats:\n",
      "    - raw text\n",
      "    - tokenized text\n",
      "    - tokenized and counted\n",
      "    \n",
      "    In the same manner if a background courpus based scoring is desired then the reference corpus\n",
      "    can be provided in any of the above formats. Depending on the desired actions on the input text,\n",
      "    the output may contain not only raw and normalized term frequency counts but also stems of\n",
      "    the terms its frequency count in the background corpus, when provided, and term's log likelihood\n",
      "    weight wrt to its prevalance in the reference corpus.\n",
      "    \n",
      "    For deatils please see the README and tuturials that comes alongs with installation \n",
      "    of this package.\n",
      "    \n",
      "    Attributes:\n",
      "        OUTPUT_FOLDER (file path): The folder to export the tabulated outputs \n",
      "            in .csv files.\n",
      "        \n",
      "        OUTPUT_FNAME  (file name): The default output file name where results \n",
      "            for multiple texts are merged and presented.\n",
      "            \n",
      "        STOPWORDS_STANDARD (file path): The location of standard stopward list,\n",
      "            if desired and exists.\n",
      "            \n",
      "        STOPWORDS_SPECIFIC (file path): The location of topic(s) specific stopward\n",
      "            list, if desired and exists. \n",
      "            \n",
      "        NOTALLOWED (:obj:`list` of `str`): The list of symbols that would flag the\n",
      "            removal of the term, if needed.\n",
      "            \n",
      "            Note: The removal would not take place if the term is a specific term or\n",
      "                marked as an exception.\n",
      "            \n",
      "        TERMS_SPECIFIC (file path): The location of exception list of terms which is\n",
      "            shielded from cleaning process, if needed.\n",
      "            \n",
      "        TOKENIZER_FUNC (x :obj:`str` -> y: :obj:`str`): A tokenizer function.\n",
      "        \n",
      "        STEMMER_FUNC (x :obj:`str` -> y: :obj:`str`): A stemmer function,\n",
      "            if needed\n",
      "        \n",
      "        MIN_LENGTH (:obj:`int`): The minimum allowed term length.\n",
      "        \n",
      "        MIN_FREQ (:obj:`float`): The minimum allowed frequency count for\n",
      "            the tabuleted outputs.\n",
      "        \n",
      "        MODEL_THRESHOLD (:obj:`int`): if scoring is requested and if the input text\n",
      "            is not driven from the reference corpus, then the paramter is used at training\n",
      "            the predection model for the terms that don't occure in the reference corpus.\n",
      "    \n",
      "    Todo:\n",
      "        * Re-implement the module as a memoized object either via a class or\n",
      "            a via wrapper function.\n",
      "        * Add a functionality where the configuration paramters can be loaded\n",
      "            from a JSON file.\n",
      "        * Make tokenization an optional process, for the cases where the input\n",
      "            is already provided in tokens.\n",
      "\n",
      "FUNCTIONS\n",
      "    extract_terms(texts, tokenizer=<function tokenize_strip_non_words at 0x10a1e0950>, merge=False, min_termlength=1, min_tf=1, topics=[], extra_process=[], stemmer=<bound method PorterStemmer.stem of <PorterStemmer>>, refcorpus=None, export=False, basefname='omterms.csv', outputdir='./output/', notallowed_symbols=\".,():;!?\\n`'=+/\\\\[]}{|><@#$%^&*_‘’“”.\", nonremovable_terms='./data/specifics_openmaker.txt', file_standard_stopwords='./data/stopwords_standard.txt', file_specific_sopwords='./data/stopwords_openmaker.txt', regression_threshold=1.0)\n",
      "        Term extraction modules main driver function.\n",
      "        \n",
      "        Args:\n",
      "            texts (:obj:`str` or :obj:`dict` of `str` or  :obj:`omterms.WikiArticles`):\n",
      "            The input text can be any of the following:\n",
      "                    - a string,\n",
      "                    - or a dictionary of strings where the key denotes the topic \n",
      "                        or any desired label/annotation regarding the text,\n",
      "                    - or a special data holder which contains labeled text scraped\n",
      "                        from Wikipedia articles.\n",
      "                    \n",
      "            tokenizer (x :obj:`str` -> y: :obj:`str`): The tokenizer,\n",
      "                (defualt omterms.tokenizer.tokenize_strip_non_words).\n",
      "                    \n",
      "            merge (:obj:`bool`): When a collection of text is provided via a dict or\n",
      "                WikiArticles, the parmater detertmines whether they should be \n",
      "                conactinated for the term extraction (default False).\n",
      "                 \n",
      "            min_termlength (:obj:`int`): The minimum allowed term length (default 1).\n",
      "            \n",
      "            min_tf (:obj:`int`): The minimum allowed frequency count for the tabuleted\n",
      "                outputs (default 4).\n",
      "                    \n",
      "            topics (:obj:`list` of `str`, optional): The list of topics from the input\n",
      "                texts to be considered (default Empty).\n",
      "                \n",
      "                If topic list is not provided and the merge is not requested but the\n",
      "                input text is given either via dict or via the WikiArticles data holder,\n",
      "                then the topic list will be driven from the input collection automatically.\n",
      "           \n",
      "            extra_process (:obj:`list` of `str`, optional): Whether stemming and/or scoring\n",
      "                is requested (default Empty).\n",
      "                - 'stem' is used/needed to flag stemming.\n",
      "                - 'compare' is used/needed to scoring texts against the designated\n",
      "                    reference corpus. \n",
      "           \n",
      "            stemmer (x :obj:`str` -> y: :obj:`str`, optional): A stemmer function,\n",
      "                if needed (default omterms.stemmer.porter).\n",
      "           \n",
      "            refcorpus (:obj:`str`\n",
      "                       or :obj:`list` of `str`\n",
      "                       or :obj:`dict` of `str`\n",
      "                       or :obj:`omterms.WikiArticles`, optional): The reference corpus\n",
      "                           (Default None)\n",
      "               The refcorpus can be any of the following:\n",
      "                    - None: if it is none yet the a scoring process is requested then\n",
      "                        NLTK's Brown corpus is loaded.\n",
      "                    - a string: A plain text.\n",
      "                    - list of words: List of words or tokens.\n",
      "                    - or a dictionary of strings where the text from the text will\n",
      "                        be unified for the reference corpus.\n",
      "                    - or a special data holder which contains labeled text scraped from\n",
      "                        Wikipedia articles, where all the texts from the collection will \n",
      "                        be combined to be used as the reference background corpus.\n",
      "        \n",
      "            export (:obj:`bool`, optional): Whether the resulting tables should be\n",
      "                exported (default False).\n",
      "            \n",
      "            basefname (:obj:`str`, optional): The output table name/prefix. Is effective\n",
      "                only when export is requested (default 'omsterms.csv').\n",
      "            \n",
      "            outputdir (:obj:`str`, optional): The file path, that is the folder to export\n",
      "                the tabulated outputs in .csv files (default './data/').\n",
      "            \n",
      "            notallowed_symbols (:obj:`list` of :obj:`str`, optional):\n",
      "                The list of symbols  that would flag the removal of the term if needed\n",
      "                (defualt omterms.tokenizer.CHARACTERS_TO_SPLIT)\n",
      "                \n",
      "            nonremovable_terms (:obj:`str`, optional): File path to the list \n",
      "                of exceptions.\n",
      "            \n",
      "            file_standard_stopwords (:obj:`str` or :obj:`list` or :obj:`set`, optional):\n",
      "                A file path to the standard stopword list, if desired and exists or a\n",
      "                stoplist or set.\n",
      "                \n",
      "                Note: The removal would not take place if the term is a specific\n",
      "                    term or marked as an exception.\n",
      "            \n",
      "            file_specific_stopwords (:obj:`str` or :obj:`list` or :obj:`set`, optional):\n",
      "                The file path to a specific stopword list, if desired and exists or list.\n",
      "                \n",
      "                Note: The removal would not take place if the term is a specific term that\n",
      "                is if marked as an exception.\n",
      "            \n",
      "            regression_threshold (:obj:`float`, optional): if scoring is requested\n",
      "                and if the input text is not driven from the reference corpus then this \n",
      "                paramter is used at training the predection model for the terms that \n",
      "                don't occure in the reference corpus (default 1.0).\n",
      "                \n",
      "        Returns:\n",
      "            (:obj:`pandas.DataFrame`, optional) The tabulated data.\n",
      "\n",
      "DATA\n",
      "    MIN_FREQ = 1\n",
      "    MIN_LENGTH = 1\n",
      "    MODEL_THRESHOLD = 1.0\n",
      "    NOTALLOWED = \".,():;!?\\n`'=+/\\\\[]}{|><@#$%^&*_‘’“”.\"\n",
      "    OUTPUT_FNAME = 'omterms.csv'\n",
      "    OUTPUT_FOLDER = './output/'\n",
      "    STOPWORDS_SPECIFIC = './data/stopwords_openmaker.txt'\n",
      "    STOPWORDS_STANDARD = './data/stopwords_standard.txt'\n",
      "    TERMS_SPECIFIC = './data/specifics_openmaker.txt'\n",
      "\n",
      "FILE\n",
      "    /Users/bulentozel/OpenMaker/GitHub/omterms/omterms/interface.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(omterms.interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function extract_terms in module omterms.interface:\n",
      "\n",
      "extract_terms(texts, tokenizer=<function tokenize_strip_non_words at 0x10a1e0950>, merge=False, min_termlength=1, min_tf=1, topics=[], extra_process=[], stemmer=<bound method PorterStemmer.stem of <PorterStemmer>>, refcorpus=None, export=False, basefname='omterms.csv', outputdir='./output/', notallowed_symbols=\".,():;!?\\n`'=+/\\\\[]}{|><@#$%^&*_‘’“”.\", nonremovable_terms='./data/specifics_openmaker.txt', file_standard_stopwords='./data/stopwords_standard.txt', file_specific_sopwords='./data/stopwords_openmaker.txt', regression_threshold=1.0)\n",
      "    Term extraction modules main driver function.\n",
      "    \n",
      "    Args:\n",
      "        texts (:obj:`str` or :obj:`dict` of `str` or  :obj:`omterms.WikiArticles`):\n",
      "        The input text can be any of the following:\n",
      "                - a string,\n",
      "                - or a dictionary of strings where the key denotes the topic \n",
      "                    or any desired label/annotation regarding the text,\n",
      "                - or a special data holder which contains labeled text scraped\n",
      "                    from Wikipedia articles.\n",
      "                \n",
      "        tokenizer (x :obj:`str` -> y: :obj:`str`): The tokenizer,\n",
      "            (defualt omterms.tokenizer.tokenize_strip_non_words).\n",
      "                \n",
      "        merge (:obj:`bool`): When a collection of text is provided via a dict or\n",
      "            WikiArticles, the parmater detertmines whether they should be \n",
      "            conactinated for the term extraction (default False).\n",
      "             \n",
      "        min_termlength (:obj:`int`): The minimum allowed term length (default 1).\n",
      "        \n",
      "        min_tf (:obj:`int`): The minimum allowed frequency count for the tabuleted\n",
      "            outputs (default 4).\n",
      "                \n",
      "        topics (:obj:`list` of `str`, optional): The list of topics from the input\n",
      "            texts to be considered (default Empty).\n",
      "            \n",
      "            If topic list is not provided and the merge is not requested but the\n",
      "            input text is given either via dict or via the WikiArticles data holder,\n",
      "            then the topic list will be driven from the input collection automatically.\n",
      "       \n",
      "        extra_process (:obj:`list` of `str`, optional): Whether stemming and/or scoring\n",
      "            is requested (default Empty).\n",
      "            - 'stem' is used/needed to flag stemming.\n",
      "            - 'compare' is used/needed to scoring texts against the designated\n",
      "                reference corpus. \n",
      "       \n",
      "        stemmer (x :obj:`str` -> y: :obj:`str`, optional): A stemmer function,\n",
      "            if needed (default omterms.stemmer.porter).\n",
      "       \n",
      "        refcorpus (:obj:`str`\n",
      "                   or :obj:`list` of `str`\n",
      "                   or :obj:`dict` of `str`\n",
      "                   or :obj:`omterms.WikiArticles`, optional): The reference corpus\n",
      "                       (Default None)\n",
      "           The refcorpus can be any of the following:\n",
      "                - None: if it is none yet the a scoring process is requested then\n",
      "                    NLTK's Brown corpus is loaded.\n",
      "                - a string: A plain text.\n",
      "                - list of words: List of words or tokens.\n",
      "                - or a dictionary of strings where the text from the text will\n",
      "                    be unified for the reference corpus.\n",
      "                - or a special data holder which contains labeled text scraped from\n",
      "                    Wikipedia articles, where all the texts from the collection will \n",
      "                    be combined to be used as the reference background corpus.\n",
      "    \n",
      "        export (:obj:`bool`, optional): Whether the resulting tables should be\n",
      "            exported (default False).\n",
      "        \n",
      "        basefname (:obj:`str`, optional): The output table name/prefix. Is effective\n",
      "            only when export is requested (default 'omsterms.csv').\n",
      "        \n",
      "        outputdir (:obj:`str`, optional): The file path, that is the folder to export\n",
      "            the tabulated outputs in .csv files (default './data/').\n",
      "        \n",
      "        notallowed_symbols (:obj:`list` of :obj:`str`, optional):\n",
      "            The list of symbols  that would flag the removal of the term if needed\n",
      "            (defualt omterms.tokenizer.CHARACTERS_TO_SPLIT)\n",
      "            \n",
      "        nonremovable_terms (:obj:`str`, optional): File path to the list \n",
      "            of exceptions.\n",
      "        \n",
      "        file_standard_stopwords (:obj:`str` or :obj:`list` or :obj:`set`, optional):\n",
      "            A file path to the standard stopword list, if desired and exists or a\n",
      "            stoplist or set.\n",
      "            \n",
      "            Note: The removal would not take place if the term is a specific\n",
      "                term or marked as an exception.\n",
      "        \n",
      "        file_specific_stopwords (:obj:`str` or :obj:`list` or :obj:`set`, optional):\n",
      "            The file path to a specific stopword list, if desired and exists or list.\n",
      "            \n",
      "            Note: The removal would not take place if the term is a specific term that\n",
      "            is if marked as an exception.\n",
      "        \n",
      "        regression_threshold (:obj:`float`, optional): if scoring is requested\n",
      "            and if the input text is not driven from the reference corpus then this \n",
      "            paramter is used at training the predection model for the terms that \n",
      "            don't occure in the reference corpus (default 1.0).\n",
      "            \n",
      "    Returns:\n",
      "        (:obj:`pandas.DataFrame`, optional) The tabulated data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(extract_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with plain texts or already tokenized texts: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 230\n"
     ]
    }
   ],
   "source": [
    "texta = \"\"\"The first objective of this module is to provide customizable and standardized text \n",
    "preprocessing phase prior to further analyses where more advanced machine learning and or statistical \n",
    "techniques can be applied and compared with each other. In that sense, it provides a pipelined set of \n",
    "functionalities (i) to be able to inspect, organize, prune and merge texts around one or very few specific \n",
    "theme(s) or topic(s), (ii) remove unwanted terms or literals from the texts, (iii) tokenize the texts, \n",
    "(iv) count the terms in texts, and (v) when desired stem the tokenized terms.\"\"\"\n",
    "\n",
    "textb = \"\"\"The second objective of this module is to be able compare or score a foreground corpus or a \n",
    "specific corpus against a background corpus or reference corpus. Example use cases could be, for instance, \n",
    "exploring the language of a sub-culture, a community, or a movement looking at to what extend the specific \n",
    "use of the language of the group differentiates itself from the common language.\n",
    "\"\"\"\n",
    "\n",
    "textc = \"\"\"In cases when there are more than a few number of themes or topics, and where each topic is \n",
    "represented with a large set of documents that validates the employment of standardized matrix decomposition \n",
    "based methodologies, then the scoring option of this module can be skipped entirely. More specifically, \n",
    "in use cases where the objective is being able to classify and differentiate a number of topics or issues \n",
    "from each other and where there are sufficient data that fulfills the underlining assumptions of NMF, LDA\n",
    "or LSI based approaches, then tools, for instance, from Python’s sklearn.decomposition package are suggested.\n",
    "\"\"\"\n",
    "\n",
    "textd = \"\"\"Nevertheless, the outputs of this module such as normalized term frequencies or the specificity\n",
    "scores associated to them with respect to a reference background corpus can be used as input to other matrix \n",
    "decomposition techniques.\n",
    "\"\"\"\n",
    "\n",
    "texts = {'a':texta, 'b':textb, 'c':textc, 'd':textd}\n",
    "textref = ' * '.join([texta,textc,textd])\n",
    "tokensref = run_tokenizing_process(textref, TOKENIZER_FUNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "A single text is provided.\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 95\n",
      "Cleaning process: Initial size of tokens = 95\n",
      "Reduction due to punctuations and stopwords = 53.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 54\n",
      "Percentage = 57%\n",
      "COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(texta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>texts</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>terms</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>objective</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>module</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>provide</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TF       Term       wTF\n",
       "27   4      texts  0.086957\n",
       "34   3      terms  0.065217\n",
       "0    1  objective  0.021739\n",
       "1    1     module  0.021739\n",
       "2    1    provide  0.021739"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# Note that TF stands for term frequency count wTF is TF/nwords in the input text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting the table  to a specific location and file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "A single text is provided.\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 95\n",
      "Cleaning process: Initial size of tokens = 95\n",
      "Reduction due to punctuations and stopwords = 53.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 54\n",
      "Percentage = 57%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/mytable.csv\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(texta, export = True, outputdir = './output/', basefname= 'mytable.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting terms from a set of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "\n",
      "Processing each topic ::>\n",
      "\n",
      "Topic = a\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 95\n",
      "Cleaning process: Initial size of tokens = 95\n",
      "Reduction due to punctuations and stopwords = 53.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 54\n",
      "Percentage = 57%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/a_omterms.csv\n",
      "\n",
      "Topic = b\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 66\n",
      "Cleaning process: Initial size of tokens = 66\n",
      "Reduction due to punctuations and stopwords = 40.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 40\n",
      "Percentage = 61%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/b_omterms.csv\n",
      "\n",
      "Topic = c\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 100\n",
      "Cleaning process: Initial size of tokens = 100\n",
      "Reduction due to punctuations and stopwords = 57.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 57\n",
      "Percentage = 57%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/c_omterms.csv\n",
      "\n",
      "Topic = d\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 35\n",
      "Cleaning process: Initial size of tokens = 35\n",
      "Reduction due to punctuations and stopwords = 17.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 17\n",
      "Percentage = 49%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/d_omterms.csv\n",
      "Results are exported to file: ./output/omterms.csv\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(texts, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>a-TF</th>\n",
       "      <th>a-wTF</th>\n",
       "      <th>b-TF</th>\n",
       "      <th>b-wTF</th>\n",
       "      <th>c-TF</th>\n",
       "      <th>c-wTF</th>\n",
       "      <th>d-TF</th>\n",
       "      <th>d-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>able</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advanced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>against</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>analyses</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>applied</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>approaches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>around</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>associated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>assumptions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>background</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Term  a-TF     a-wTF  b-TF     b-wTF  c-TF     c-wTF  d-TF     d-wTF\n",
       "0         able   1.0  0.021739   1.0  0.030303   1.0  0.020833   NaN       NaN\n",
       "1     advanced   1.0  0.021739   NaN       NaN   NaN       NaN   NaN       NaN\n",
       "2      against   NaN       NaN   1.0  0.030303   NaN       NaN   NaN       NaN\n",
       "3     analyses   1.0  0.021739   NaN       NaN   NaN       NaN   NaN       NaN\n",
       "4      applied   1.0  0.021739   NaN       NaN   NaN       NaN   NaN       NaN\n",
       "5   approaches   NaN       NaN   NaN       NaN   1.0  0.020833   NaN       NaN\n",
       "6       around   1.0  0.021739   NaN       NaN   NaN       NaN   NaN       NaN\n",
       "7   associated   NaN       NaN   NaN       NaN   NaN       NaN   1.0  0.055556\n",
       "8  assumptions   NaN       NaN   NaN       NaN   1.0  0.020833   NaN       NaN\n",
       "9   background   NaN       NaN   1.0  0.030303   NaN       NaN   1.0  0.055556"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifiying a subset of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "\n",
      "Processing each topic ::>\n",
      "\n",
      "Topic = a\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 95\n",
      "Cleaning process: Initial size of tokens = 95\n",
      "Reduction due to punctuations and stopwords = 53.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 54\n",
      "Percentage = 57%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "COMPLETED.\n",
      "\n",
      "Topic = c\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 100\n",
      "Cleaning process: Initial size of tokens = 100\n",
      "Reduction due to punctuations and stopwords = 57.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 57\n",
      "Percentage = 57%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(texts, topics = ['a','c'], extra_process = ['stem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>a-TF</th>\n",
       "      <th>a-wTF</th>\n",
       "      <th>c-TF</th>\n",
       "      <th>c-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>able</td>\n",
       "      <td>abl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advanced</td>\n",
       "      <td>advanc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>analyses</td>\n",
       "      <td>analys</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>applied</td>\n",
       "      <td>appli</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>approaches</td>\n",
       "      <td>approach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Term      Stem  a-TF     a-wTF  c-TF     c-wTF\n",
       "0        able       abl   1.0  0.021739   1.0  0.020833\n",
       "1    advanced    advanc   1.0  0.021739   NaN       NaN\n",
       "2    analyses    analys   1.0  0.021739   NaN       NaN\n",
       "3     applied     appli   1.0  0.021739   NaN       NaN\n",
       "4  approaches  approach   NaN       NaN   1.0  0.020833"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring/comparing wrt  a background text\n",
    "\n",
    "The details of the scoring including the prediction model on missing terms on the background see the custom processing session below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "Preparing the reference corpus ::>\n",
      "Cleaning the reference corpus ...\n",
      "Cleaning process: Initial size of tokens = 230\n",
      "Reduction due to punctuations and stopwords = 137.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 138\n",
      "Percentage = 60%\n",
      "Stemming the word in the reference corpus ...\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "Done: Reference corpus process.\n",
      "A single text is provided.\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 95\n",
      "Cleaning process: Initial size of tokens = 95\n",
      "Reduction due to punctuations and stopwords = 53.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 54\n",
      "Percentage = 57%\n",
      "41 / 41  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "0 / 41 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "0 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(texta, extra_process = ['compare'], refcorpus = tokensref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "      <th>SType</th>\n",
       "      <th>Score</th>\n",
       "      <th>wTFref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>texts</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>terms</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>0.026786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>provide</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>customizable</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TF          Term       wTF SType     Score    wTFref\n",
       "27   4         texts  0.086957   raw  0.889857  0.035714\n",
       "34   3         terms  0.065217   raw  0.889857  0.026786\n",
       "2    1       provide  0.021739   raw  0.889857  0.008929\n",
       "3    1  customizable  0.021739   raw  0.889857  0.008929\n",
       "5    1          text  0.021739   raw  0.889857  0.008929"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score** is the log likelihood of the normalized term frequencies wrt to the reference corpus.\n",
    "\n",
    "**SType** stands for scoring type which can be either one of:\n",
    "- raw: the term as it is was identified in the background corpus, so a loglikelihood scoring was applied\n",
    "- stem: not the term as it is but its stem was identified, so mean of the observed stem occurances in the background was used as the reference\n",
    "- noref: neither the term nor its stem was identified, so **the prediction model, a log-linear regression based model** is used for the frequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "Preparing the reference corpus ::>\n",
      "An untokenized reference corpus is identified.\n",
      "Tokenizing the reference corpus ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 230\n",
      "Cleaning the reference corpus ...\n",
      "Cleaning process: Initial size of tokens = 230\n",
      "Reduction due to punctuations and stopwords = 137.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 138\n",
      "Percentage = 60%\n",
      "Stemming the word in the reference corpus ...\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "Done: Reference corpus process.\n",
      "\n",
      "Processing each topic ::>\n",
      "\n",
      "Topic = a\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 95\n",
      "Cleaning process: Initial size of tokens = 95\n",
      "Reduction due to punctuations and stopwords = 53.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 1\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 54\n",
      "Percentage = 57%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "41 / 41  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "0 / 41 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "0 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n",
      "\n",
      "Topic = b\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 66\n",
      "Cleaning process: Initial size of tokens = 66\n",
      "Reduction due to punctuations and stopwords = 40.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 40\n",
      "Percentage = 61%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "10 / 26  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "16 / 26 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "3 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n",
      "\n",
      "Topic = c\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 100\n",
      "Cleaning process: Initial size of tokens = 100\n",
      "Reduction due to punctuations and stopwords = 57.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 57\n",
      "Percentage = 57%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "43 / 43  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "0 / 43 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "0 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n",
      "\n",
      "Topic = d\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 35\n",
      "Cleaning process: Initial size of tokens = 35\n",
      "Reduction due to punctuations and stopwords = 17.\n",
      "Reduction due to all numeral terms = 0\n",
      "Reduction due to short terms = 0\n",
      "Reduction due to rare terms = 0\n",
      "Reduction due to partially numeral terms = 0\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 17\n",
      "Percentage = 49%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "18 / 18  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "0 / 18 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "0 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bulentozel/anaconda/envs/omterms/lib/python3.6/site-packages/sklearn/linear_model/base.py:509: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(texts, extra_process = ['stem','compare'], refcorpus = textref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTFref</th>\n",
       "      <th>SType</th>\n",
       "      <th>a-Score</th>\n",
       "      <th>a-TF</th>\n",
       "      <th>a-wTF</th>\n",
       "      <th>b-Score</th>\n",
       "      <th>b-TF</th>\n",
       "      <th>b-wTF</th>\n",
       "      <th>c-Score</th>\n",
       "      <th>c-TF</th>\n",
       "      <th>c-wTF</th>\n",
       "      <th>d-Score</th>\n",
       "      <th>d-TF</th>\n",
       "      <th>d-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>against</td>\n",
       "      <td>against</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common</td>\n",
       "      <td>common</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>community</td>\n",
       "      <td>commun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>culture</td>\n",
       "      <td>cultur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>example</td>\n",
       "      <td>exampl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exploring</td>\n",
       "      <td>explor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>extend</td>\n",
       "      <td>extend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>foreground</td>\n",
       "      <td>foreground</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>group</td>\n",
       "      <td>group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>language</td>\n",
       "      <td>languag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.320604</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>looking</td>\n",
       "      <td>look</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Term        Stem  wTFref  SType  a-Score  a-TF  a-wTF   b-Score  \\\n",
       "0      against     against     NaN  noref      NaN   NaN    NaN       NaN   \n",
       "1       common      common     NaN  noref      NaN   NaN    NaN       NaN   \n",
       "2    community      commun     NaN  noref      NaN   NaN    NaN       NaN   \n",
       "3      culture      cultur     NaN  noref      NaN   NaN    NaN       NaN   \n",
       "4      example      exampl     NaN  noref      NaN   NaN    NaN       NaN   \n",
       "5    exploring      explor     NaN  noref      NaN   NaN    NaN       NaN   \n",
       "6       extend      extend     NaN  noref      NaN   NaN    NaN       NaN   \n",
       "7   foreground  foreground     NaN  noref      NaN   NaN    NaN       NaN   \n",
       "8        group       group     NaN  noref      NaN   NaN    NaN       NaN   \n",
       "9     language     languag     NaN  noref      NaN   NaN    NaN  2.320604   \n",
       "10     looking        look     NaN  noref      NaN   NaN    NaN       NaN   \n",
       "\n",
       "    b-TF     b-wTF  c-Score  c-TF  c-wTF  d-Score  d-TF  d-wTF  \n",
       "0    1.0  0.030303      NaN   NaN    NaN      NaN   NaN    NaN  \n",
       "1    1.0  0.030303      NaN   NaN    NaN      NaN   NaN    NaN  \n",
       "2    1.0  0.030303      NaN   NaN    NaN      NaN   NaN    NaN  \n",
       "3    1.0  0.030303      NaN   NaN    NaN      NaN   NaN    NaN  \n",
       "4    1.0  0.030303      NaN   NaN    NaN      NaN   NaN    NaN  \n",
       "5    1.0  0.030303      NaN   NaN    NaN      NaN   NaN    NaN  \n",
       "6    1.0  0.030303      NaN   NaN    NaN      NaN   NaN    NaN  \n",
       "7    1.0  0.030303      NaN   NaN    NaN      NaN   NaN    NaN  \n",
       "8    1.0  0.030303      NaN   NaN    NaN      NaN   NaN    NaN  \n",
       "9    3.0  0.090909      NaN   NaN    NaN      NaN   NaN    NaN  \n",
       "10   1.0  0.030303      NaN   NaN    NaN      NaN   NaN    NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTFref</th>\n",
       "      <th>SType</th>\n",
       "      <th>a-Score</th>\n",
       "      <th>a-TF</th>\n",
       "      <th>a-wTF</th>\n",
       "      <th>b-Score</th>\n",
       "      <th>b-TF</th>\n",
       "      <th>b-wTF</th>\n",
       "      <th>c-Score</th>\n",
       "      <th>c-TF</th>\n",
       "      <th>c-wTF</th>\n",
       "      <th>d-Score</th>\n",
       "      <th>d-TF</th>\n",
       "      <th>d-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tools</td>\n",
       "      <td>tool</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>topic</td>\n",
       "      <td>topic</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.196710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>topics</td>\n",
       "      <td>topic</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>underlining</td>\n",
       "      <td>underlin</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>unwanted</td>\n",
       "      <td>unwant</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.889857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.915138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>used</td>\n",
       "      <td>use</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.828127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>validates</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>compare</td>\n",
       "      <td>compar</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>stem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.221991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>differentiates</td>\n",
       "      <td>differenti</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>stem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.221991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>score</td>\n",
       "      <td>score</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>stem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.221991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Term        Stem    wTFref SType   a-Score  a-TF     a-wTF  \\\n",
       "97            tools        tool  0.008929   raw       NaN   NaN       NaN   \n",
       "98            topic       topic  0.017857   raw  0.196710   1.0  0.021739   \n",
       "99           topics       topic  0.017857   raw       NaN   NaN       NaN   \n",
       "100     underlining    underlin  0.008929   raw       NaN   NaN       NaN   \n",
       "101        unwanted      unwant  0.008929   raw  0.889857   1.0  0.021739   \n",
       "102             use         use  0.008929   raw       NaN   NaN       NaN   \n",
       "103            used         use  0.008929   raw       NaN   NaN       NaN   \n",
       "104       validates       valid  0.008929   raw       NaN   NaN       NaN   \n",
       "105         compare      compar  0.008929  stem       NaN   NaN       NaN   \n",
       "106  differentiates  differenti  0.008929  stem       NaN   NaN       NaN   \n",
       "107           score       score  0.008929  stem       NaN   NaN       NaN   \n",
       "\n",
       "      b-Score  b-TF     b-wTF   c-Score  c-TF     c-wTF   d-Score  d-TF  \\\n",
       "97        NaN   NaN       NaN  0.847298   1.0  0.020833       NaN   NaN   \n",
       "98        NaN   NaN       NaN  0.154151   1.0  0.020833       NaN   NaN   \n",
       "99        NaN   NaN       NaN  0.847298   2.0  0.041667       NaN   NaN   \n",
       "100       NaN   NaN       NaN  0.847298   1.0  0.020833       NaN   NaN   \n",
       "101       NaN   NaN       NaN       NaN   NaN       NaN       NaN   NaN   \n",
       "102  1.915138   2.0  0.060606  0.847298   1.0  0.020833       NaN   NaN   \n",
       "103       NaN   NaN       NaN       NaN   NaN       NaN  1.828127   1.0   \n",
       "104       NaN   NaN       NaN  0.847298   1.0  0.020833       NaN   NaN   \n",
       "105  1.221991   1.0  0.030303       NaN   NaN       NaN       NaN   NaN   \n",
       "106  1.221991   1.0  0.030303       NaN   NaN       NaN       NaN   NaN   \n",
       "107  1.221991   1.0  0.030303       NaN   NaN       NaN       NaN   NaN   \n",
       "\n",
       "        d-wTF  \n",
       "97        NaN  \n",
       "98        NaN  \n",
       "99        NaN  \n",
       "100       NaN  \n",
       "101       NaN  \n",
       "102       NaN  \n",
       "103  0.055556  \n",
       "104       NaN  \n",
       "105       NaN  \n",
       "106       NaN  \n",
       "107       NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on larger texts crawled from Wikipedia.\n",
    "\n",
    "For the purpose and convenience a data holder named WikiArticles is designed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class WikiArticles in module omterms.datauis:\n",
      "\n",
      "class WikiArticles(builtins.object)\n",
      " |  The object contains a set of tools to process the set of \n",
      " |      documents collected and cleaned by the wiki crawler.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      collection_json (:obj:`str`): This is a filename to the scraped data.\n",
      " |          Each JSON document is expected to have following fields:\n",
      " |          - theme: Topic identifier, ex: Sustainability\n",
      " |          - theme.id: A unique category identifier\n",
      " |          - document.id: A unique document id\n",
      " |          - title: Title of the document\n",
      " |          - url: Full URL of the document\n",
      " |          - depth: The link distance from the seed docuement. The seed documents depth is 0.\n",
      " |          - text: The string data scraped from the page without tags. Pancuations are not \n",
      " |              required but terms are expected to be delineated by white space. \n",
      " |      collection (:obj:`list` of :obj:`dict`): Loaded json file into native list of dictionaries.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, collection)\n",
      " |      The class constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          collection (:obj:`str`): A filename to a previously scraped data.\n",
      " |  \n",
      " |  collate(self, by_theme_id=None, by_doc_ids=[], marker='\\n')\n",
      " |      The method collects the desired set of documents concatenates them creating a unified document.\n",
      " |          The order of merge is as follows:\n",
      " |          - When neither list of theme nor doc ids is provided, it collates entire text.\n",
      " |          - If a theme is given then all the documents under that theme are to be joined first.\n",
      " |          - When a list of docs is given, only those in the list are kept.\n",
      " |          Note that if both theme id and doc ids provided, precedence is on themes.\n",
      " |      \n",
      " |      Args:\n",
      " |          by_theme_id (:obj:`int`, optional): The theme id of the docs to be collated.\n",
      " |          by_doc_ids (:obj:`list` of :obj:`int`, optional): The list of doc ids to be collated (default Empty). \n",
      " |          marker (:obj:`str`, optional): A delimiter (default newline)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`str`): The collated text.\n",
      " |  \n",
      " |  display_documents_list(self, tid=None, stdout=True)\n",
      " |      List the articles meta data and crawling information on them.\n",
      " |      \n",
      " |      Args:\n",
      " |          tid (:obj:`int`, optional): Used if documents info under a specific theme is desired \n",
      " |              otherwise a summary of whole set is returned or displayed (default None).\n",
      " |          stdout (:obj:`bool`, optional): Whether the info is to be displayed/printed\n",
      " |              to standard io (default True).\n",
      " |              \n",
      " |      Returns:\n",
      " |          ( :obj:`list`): A summary list of documents in the collection.\n",
      " |  \n",
      " |  get_document_fields(self)\n",
      " |      The method lists the fields of each json field of its collection.\n",
      " |        \n",
      " |      Args:\n",
      " |          None  \n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`dict_keys`): List of keys.\n",
      " |          None: When the collection is empty.\n",
      " |  \n",
      " |  get_theme_id(self, theme_name)\n",
      " |      The method returns topic id of the first match theme name.\n",
      " |        \n",
      " |      Args:\n",
      " |          theme_name (:obj:`str`): The theme or topic name. \n",
      " |          \n",
      " |      Returns:\n",
      " |          ( :obj:`int`): A unique theme identifier.\n",
      " |  \n",
      " |  get_theme_title(self, theme_id)\n",
      " |      The method returns topic name.\n",
      " |        \n",
      " |      Args:\n",
      " |          theme_id (:obj:`int`): The unique theme id. \n",
      " |          \n",
      " |      Returns:\n",
      " |          ( :obj:`str`): Topic name.\n",
      " |  \n",
      " |  list_themes(self)\n",
      " |      The method lists the summary of themes/topics in the collection.\n",
      " |        \n",
      " |      Args:\n",
      " |          None  \n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list` of :obj:`dict`): List of dictionry where keys are\n",
      " |              - name: theme's textual descriptor\n",
      " |              - id: theme's unique id\n",
      " |              - count: number of articles under the theme.\n",
      " |  \n",
      " |  load_corpus(self, collection=None)\n",
      " |      The method loads imports json file into a native collection.\n",
      " |        \n",
      " |      Args:\n",
      " |          collection (:obj:`str`): A filename to a previously scraped data.\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  prune(self, themes_to_keep=[], docs_to_drop=[], istodrop=<function WikiArticles.<lambda> at 0x110201730>)\n",
      " |      The method is used to filter out documents from the set.\n",
      " |          The order of prunning is as follows:\n",
      " |          - when a none empty list is provide all the documents not belonging themes to be kept\n",
      " |              are prunned entirely. Note that when initial list is empty it doesn't have an effect.\n",
      " |          - of remaing documents those appear in docs_to_drop are prunned\n",
      " |          - of the remaing docs those produce a True at a call on the predicate function are dropped.\n",
      " |          \n",
      " |          The function can be repeatedly called until a desired level of prunning is achieved.\n",
      " |      \n",
      " |      Args:\n",
      " |          themes_to_keep (:obj:`list` of :obj:`int`, optional): The list of theme ids to be kept (default Empty).\n",
      " |          docs_to_drop (:obj:`list`, optional): The list of doc ids to be dropt (default Empty). \n",
      " |          f (x :obj:`dict_item` -> :obj:`bool`, optional): A predicate function (default lambda x:False)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(WikiArticles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and preparing the WikiCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the corpus: 563\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'name': 'universalism', 'num_of_articles': 205},\n",
       " {'id': 2, 'name': 'hedonism', 'num_of_articles': 85},\n",
       " {'id': 3, 'name': 'achievement', 'num_of_articles': 46},\n",
       " {'id': 4, 'name': 'power', 'num_of_articles': 24},\n",
       " {'id': 5, 'name': 'self-direction', 'num_of_articles': 37},\n",
       " {'id': 6, 'name': 'benevolence', 'num_of_articles': 57},\n",
       " {'id': 7, 'name': 'conformity', 'num_of_articles': 42},\n",
       " {'id': 8, 'name': 'tradition', 'num_of_articles': 18},\n",
       " {'id': 9, 'name': 'stimulation', 'num_of_articles': 7},\n",
       " {'id': 10, 'name': 'security', 'num_of_articles': 32}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WIKI_DOCS = \"data/corpora/schwartz.json\"\n",
    "WikiC = WikiArticles(WIKI_DOCS)\n",
    "WikiC.list_themes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the configuration paremeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"./output/\"\n",
    "OUTPUT_FNAME = \"schwartz.csv\"\n",
    "\n",
    "STOPWORDS_STANDARD = \"./data/stopwords_standard.txt\"\n",
    "STOPWORDS_SPECIFIC = \"./data/stopwords_openmaker.txt\"\n",
    "NOTALLOWED = tokenizer.CHARACTERS_TO_SPLIT\n",
    "TERMS_SPECIFIC = \"./data/specifics_openmaker.txt\"\n",
    "\n",
    "TOKENIZER_FUNC = tokenizer.tokenize_strip_non_words\n",
    "STEMMER_FUNC = porter\n",
    "\n",
    "MIN_LENGTH = 2\n",
    "MIN_FREQ = 3\n",
    "MODEL_THRESHOLD = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "\n",
      "Processing each topic ::>\n",
      "\n",
      "Topic = universalism\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 701497\n",
      "Cleaning process: Initial size of tokens = 701497\n",
      "Reduction due to punctuations and stopwords = 666886.\n",
      "Reduction due to all numeral terms = 601\n",
      "Reduction due to short terms = 267\n",
      "Reduction due to rare terms = 19485\n",
      "Reduction due to partially numeral terms = 42\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 687281\n",
      "Percentage = 98%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/universalism_schwartz.csv\n",
      "\n",
      "Topic = hedonism\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 210302\n",
      "Cleaning process: Initial size of tokens = 210302\n",
      "Reduction due to punctuations and stopwords = 193608.\n",
      "Reduction due to all numeral terms = 216\n",
      "Reduction due to short terms = 169\n",
      "Reduction due to rare terms = 9926\n",
      "Reduction due to partially numeral terms = 16\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 203935\n",
      "Percentage = 97%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/hedonism_schwartz.csv\n",
      "\n",
      "Topic = achievement\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 124988\n",
      "Cleaning process: Initial size of tokens = 124988\n",
      "Reduction due to punctuations and stopwords = 114578.\n",
      "Reduction due to all numeral terms = 211\n",
      "Reduction due to short terms = 64\n",
      "Reduction due to rare terms = 5830\n",
      "Reduction due to partially numeral terms = 14\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 120697\n",
      "Percentage = 97%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/achievement_schwartz.csv\n",
      "\n",
      "Topic = power\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 59284\n",
      "Cleaning process: Initial size of tokens = 59284\n",
      "Reduction due to punctuations and stopwords = 50484.\n",
      "Reduction due to all numeral terms = 90\n",
      "Reduction due to short terms = 62\n",
      "Reduction due to rare terms = 5766\n",
      "Reduction due to partially numeral terms = 17\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 56419\n",
      "Percentage = 95%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/power_schwartz.csv\n",
      "\n",
      "Topic = self-direction\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 88900\n",
      "Cleaning process: Initial size of tokens = 88900\n",
      "Reduction due to punctuations and stopwords = 78653.\n",
      "Reduction due to all numeral terms = 197\n",
      "Reduction due to short terms = 95\n",
      "Reduction due to rare terms = 6334\n",
      "Reduction due to partially numeral terms = 23\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 85302\n",
      "Percentage = 96%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/self-direction_schwartz.csv\n",
      "\n",
      "Topic = benevolence\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 156450\n",
      "Cleaning process: Initial size of tokens = 156450\n",
      "Reduction due to punctuations and stopwords = 141999.\n",
      "Reduction due to all numeral terms = 396\n",
      "Reduction due to short terms = 131\n",
      "Reduction due to rare terms = 8697\n",
      "Reduction due to partially numeral terms = 12\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 151235\n",
      "Percentage = 97%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/benevolence_schwartz.csv\n",
      "\n",
      "Topic = conformity\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 92224\n",
      "Cleaning process: Initial size of tokens = 92224\n",
      "Reduction due to punctuations and stopwords = 82395.\n",
      "Reduction due to all numeral terms = 74\n",
      "Reduction due to short terms = 86\n",
      "Reduction due to rare terms = 6008\n",
      "Reduction due to partially numeral terms = 7\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 88570\n",
      "Percentage = 96%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/conformity_schwartz.csv\n",
      "\n",
      "Topic = tradition\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 48257\n",
      "Cleaning process: Initial size of tokens = 48257\n",
      "Reduction due to punctuations and stopwords = 40348.\n",
      "Reduction due to all numeral terms = 66\n",
      "Reduction due to short terms = 62\n",
      "Reduction due to rare terms = 5509\n",
      "Reduction due to partially numeral terms = 5\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 45990\n",
      "Percentage = 95%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/tradition_schwartz.csv\n",
      "\n",
      "Topic = stimulation\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 29302\n",
      "Cleaning process: Initial size of tokens = 29302\n",
      "Reduction due to punctuations and stopwords = 23646.\n",
      "Reduction due to all numeral terms = 51\n",
      "Reduction due to short terms = 39\n",
      "Reduction due to rare terms = 4040\n",
      "Reduction due to partially numeral terms = 11\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 27787\n",
      "Percentage = 95%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/stimulation_schwartz.csv\n",
      "\n",
      "Topic = security\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 86698\n",
      "Cleaning process: Initial size of tokens = 86698\n",
      "Reduction due to punctuations and stopwords = 76712.\n",
      "Reduction due to all numeral terms = 78\n",
      "Reduction due to short terms = 82\n",
      "Reduction due to rare terms = 6225\n",
      "Reduction due to partially numeral terms = 8\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 83105\n",
      "Percentage = 96%\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/security_schwartz.csv\n",
      "Results are exported to file: ./output/schwartz.csv\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(WikiC,\n",
    "                  tokenizer = TOKENIZER_FUNC,\n",
    "                  min_termlength = MIN_LENGTH,\n",
    "                  min_tf = MIN_FREQ,\n",
    "                  stemmer = STEMMER_FUNC,\n",
    "                  export = True,\n",
    "                  basefname = OUTPUT_FNAME,\n",
    "                  outputdir = OUTPUT_FOLDER, \n",
    "                  notallowed_symbols = NOTALLOWED,\n",
    "                  nonremovable_terms = TERMS_SPECIFIC,\n",
    "                  file_standard_stopwords = STOPWORDS_STANDARD,\n",
    "                  file_specific_sopwords = STOPWORDS_SPECIFIC,\n",
    "                  regression_threshold = MODEL_THRESHOLD\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Ach-TF</th>\n",
       "      <th>Ach-wTF</th>\n",
       "      <th>Ben-TF</th>\n",
       "      <th>Ben-wTF</th>\n",
       "      <th>Con-TF</th>\n",
       "      <th>Con-wTF</th>\n",
       "      <th>Hed-TF</th>\n",
       "      <th>Hed-wTF</th>\n",
       "      <th>Pow-TF</th>\n",
       "      <th>...</th>\n",
       "      <th>Sec-TF</th>\n",
       "      <th>Sec-wTF</th>\n",
       "      <th>Sel-TF</th>\n",
       "      <th>Sel-wTF</th>\n",
       "      <th>Sti-TF</th>\n",
       "      <th>Sti-wTF</th>\n",
       "      <th>Tra-TF</th>\n",
       "      <th>Tra-wTF</th>\n",
       "      <th>Uni-TF</th>\n",
       "      <th>Uni-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18495</th>\n",
       "      <td>zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18496</th>\n",
       "      <td>zurvanism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18497</th>\n",
       "      <td>zygmunt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18498</th>\n",
       "      <td>zygote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18499</th>\n",
       "      <td>zzz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Term  Ach-TF   Ach-wTF  Ben-TF  Ben-wTF  Con-TF  Con-wTF  Hed-TF  \\\n",
       "18495     zurich     NaN       NaN     NaN      NaN     NaN      NaN     NaN   \n",
       "18496  zurvanism     NaN       NaN     NaN      NaN     NaN      NaN     NaN   \n",
       "18497    zygmunt     3.0  0.000046     NaN      NaN     NaN      NaN     NaN   \n",
       "18498     zygote     NaN       NaN     NaN      NaN     NaN      NaN     NaN   \n",
       "18499        zzz     NaN       NaN     NaN      NaN     NaN      NaN     NaN   \n",
       "\n",
       "       Hed-wTF  Pow-TF    ...     Sec-TF  Sec-wTF  Sel-TF   Sel-wTF  Sti-TF  \\\n",
       "18495      NaN     3.0    ...        NaN      NaN     NaN       NaN     NaN   \n",
       "18496      NaN     NaN    ...        NaN      NaN     NaN       NaN     NaN   \n",
       "18497      NaN     NaN    ...        NaN      NaN     NaN       NaN     NaN   \n",
       "18498      NaN     NaN    ...        NaN      NaN     NaN       NaN     NaN   \n",
       "18499      NaN     NaN    ...        NaN      NaN     3.0  0.000068     NaN   \n",
       "\n",
       "       Sti-wTF  Tra-TF  Tra-wTF  Uni-TF   Uni-wTF  \n",
       "18495      NaN     NaN      NaN     NaN       NaN  \n",
       "18496      NaN     NaN      NaN     4.0  0.000010  \n",
       "18497      NaN     NaN      NaN     NaN       NaN  \n",
       "18498      NaN     NaN      NaN     3.0  0.000008  \n",
       "18499      NaN     NaN      NaN     NaN       NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "Term extraction on the combined text from collection is requested.\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 1597902\n",
      "Cleaning process: Initial size of tokens = 1597902\n",
      "Reduction due to punctuations and stopwords = 1543723.\n",
      "Reduction due to all numeral terms = 1219\n",
      "Reduction due to short terms = 423\n",
      "Reduction due to rare terms = 29708\n",
      "Reduction due to partially numeral terms = 80\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 1575153\n",
      "Percentage = 99%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(WikiC,\n",
    "                  tokenizer = TOKENIZER_FUNC,\n",
    "                  merge = True,\n",
    "                  min_termlength = MIN_LENGTH,\n",
    "                  min_tf = MIN_FREQ,\n",
    "                  extra_process = ['stem'],\n",
    "                  stemmer = STEMMER_FUNC,\n",
    "                  notallowed_symbols = NOTALLOWED,\n",
    "                  nonremovable_terms = TERMS_SPECIFIC,\n",
    "                  file_standard_stopwords = STOPWORDS_STANDARD,\n",
    "                  file_specific_sopwords = STOPWORDS_SPECIFIC,\n",
    "                  regression_threshold = MODEL_THRESHOLD\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>4461</td>\n",
       "      <td>social</td>\n",
       "      <td>social</td>\n",
       "      <td>0.005068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2970</td>\n",
       "      <td>people</td>\n",
       "      <td>peopl</td>\n",
       "      <td>0.003374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>2845</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>0.003232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2254</td>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>0.002561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>2230</td>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>0.002534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>1942</td>\n",
       "      <td>environmental</td>\n",
       "      <td>environment</td>\n",
       "      <td>0.002206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>1893</td>\n",
       "      <td>states</td>\n",
       "      <td>state</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1870</td>\n",
       "      <td>theory</td>\n",
       "      <td>theori</td>\n",
       "      <td>0.002125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1759</td>\n",
       "      <td>used</td>\n",
       "      <td>use</td>\n",
       "      <td>0.001998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>1736</td>\n",
       "      <td>united</td>\n",
       "      <td>unit</td>\n",
       "      <td>0.001972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TF           Term         Stem       wTF\n",
       "1011  4461         social       social  0.005068\n",
       "101   2970         people        peopl  0.003374\n",
       "419   2845          human        human  0.003232\n",
       "381   2254          world        world  0.002561\n",
       "892   2230            new          new  0.002534\n",
       "895   1942  environmental  environment  0.002206\n",
       "1023  1893         states        state  0.002151\n",
       "279   1870         theory       theori  0.002125\n",
       "742   1759           used          use  0.001998\n",
       "1022  1736         united         unit  0.001972"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using an external corpus for the background\n",
    "\n",
    "When a comparison requested but a background corpus is not specified. NLTK's Brown corpus is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the first time the Corpus may need to be downloaded.\n",
    "# In that case uncomment the following line.\n",
    "#nltk.download()\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "TOKENSREF = list(nltk.corpus.brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring the text cleaner ...\n",
      "Preparing the reference corpus ::>\n",
      "Comparions/Scoring is requested but no reference corpus text or tokens is provided.\n",
      "Loading nltk.corpus.brown ...\n",
      "Cleaning the reference corpus ...\n",
      "Cleaning process: Initial size of tokens = 1161192\n",
      "Reduction due to punctuations and stopwords = 1111606.\n",
      "Reduction due to all numeral terms = 1747\n",
      "Reduction due to short terms = 178\n",
      "Reduction due to rare terms = 27810\n",
      "Reduction due to partially numeral terms = 49\n",
      "Reduction due to terms with not allowed symbols = 645\n",
      "The total term count reduction during this cleaning process = 1142035\n",
      "Percentage = 98%\n",
      "Stemming the word in the reference corpus ...\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "Done: Reference corpus process.\n",
      "\n",
      "Processing each topic ::>\n",
      "\n",
      "Topic = power\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 59284\n",
      "Cleaning process: Initial size of tokens = 59284\n",
      "Reduction due to punctuations and stopwords = 50484.\n",
      "Reduction due to all numeral terms = 90\n",
      "Reduction due to short terms = 62\n",
      "Reduction due to rare terms = 5766\n",
      "Reduction due to partially numeral terms = 17\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 56419\n",
      "Percentage = 95%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "2517 / 2865  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "348 / 2865 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "84 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/power_schwartz.csv\n",
      "\n",
      "Topic = universalism\n",
      "Extracting the terms ...\n",
      "Tokenizing the input text ..\n",
      "Done. Number of terms: 701497\n",
      "Cleaning process: Initial size of tokens = 701497\n",
      "Reduction due to punctuations and stopwords = 666886.\n",
      "Reduction due to all numeral terms = 601\n",
      "Reduction due to short terms = 267\n",
      "Reduction due to rare terms = 19485\n",
      "Reduction due to partially numeral terms = 42\n",
      "Reduction due to terms with not allowed symbols = 0\n",
      "The total term count reduction during this cleaning process = 687281\n",
      "Percentage = 98%\n",
      "Stemming the terms in the corpus ..\n",
      "Done.\n",
      "8950 / 14216  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "5266 / 14216 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "1261 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n",
      "COMPLETED.\n",
      "Results are exported to file: ./output/universalism_schwartz.csv\n",
      "Results are exported to file: ./output/schwartz.csv\n"
     ]
    }
   ],
   "source": [
    "df = extract_terms(\n",
    "    WikiC,\n",
    "    tokenizer = TOKENIZER_FUNC,\n",
    "    merge = False,\n",
    "    min_termlength = MIN_LENGTH,\n",
    "    min_tf = MIN_FREQ,\n",
    "    topics = ['power', 'universalism'],\n",
    "    extra_process = ['stem', 'compare'],\n",
    "    stemmer = STEMMER_FUNC,\n",
    "    refcorpus = None,#refcorpus = TOKENSREF  \n",
    "    export = True,\n",
    "    basefname = OUTPUT_FNAME,\n",
    "    outputdir = OUTPUT_FOLDER, \n",
    "    notallowed_symbols = NOTALLOWED,\n",
    "    nonremovable_terms = TERMS_SPECIFIC,\n",
    "    file_standard_stopwords = STOPWORDS_STANDARD,\n",
    "    file_specific_sopwords = STOPWORDS_SPECIFIC,\n",
    "    regression_threshold = MODEL_THRESHOLD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTFref</th>\n",
       "      <th>SType</th>\n",
       "      <th>Pow-Score</th>\n",
       "      <th>Pow-TF</th>\n",
       "      <th>Pow-wTF</th>\n",
       "      <th>Uni-Score</th>\n",
       "      <th>Uni-TF</th>\n",
       "      <th>Uni-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12882</th>\n",
       "      <td>veto</td>\n",
       "      <td>veto</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.136333</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>collapse</td>\n",
       "      <td>collaps</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.082428</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>1.543837</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8591</th>\n",
       "      <td>islamic</td>\n",
       "      <td>islam</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.799861</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>3.700468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>citation</td>\n",
       "      <td>citat</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.678500</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>4.240464</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.000743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>participants</td>\n",
       "      <td>particip</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.545627</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>2.160023</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8504</th>\n",
       "      <td>interpersonal</td>\n",
       "      <td>interperson</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.463388</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.887058</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13030</th>\n",
       "      <td>wealth</td>\n",
       "      <td>wealth</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.445039</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>1.521709</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9679</th>\n",
       "      <td>obedience</td>\n",
       "      <td>obedi</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.440916</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>-0.057404</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12338</th>\n",
       "      <td>template</td>\n",
       "      <td>templat</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.380007</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>3.540300</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9287</th>\n",
       "      <td>mid</td>\n",
       "      <td>mid</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.320288</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>3.777429</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Term         Stem    wTFref SType  Pow-Score  Pow-TF  \\\n",
       "12882           veto         veto  0.000021   raw   5.136333    98.0   \n",
       "5546        collapse      collaps  0.000015   raw   5.082428    65.0   \n",
       "8591         islamic        islam  0.000006   raw   4.799861    21.0   \n",
       "5443        citation        citat  0.000011   raw   4.678500    31.0   \n",
       "9975    participants     particip  0.000015   raw   4.545627    38.0   \n",
       "8504   interpersonal  interperson  0.000006   raw   4.463388    15.0   \n",
       "13030         wealth       wealth  0.000047   raw   4.445039   108.0   \n",
       "9679       obedience        obedi  0.000019   raw   4.440916    44.0   \n",
       "12338       template      templat  0.000011   raw   4.380007    23.0   \n",
       "9287             mid          mid  0.000006   raw   4.320288    13.0   \n",
       "\n",
       "        Pow-wTF  Uni-Score  Uni-TF   Uni-wTF  \n",
       "12882  0.003642        NaN     NaN       NaN  \n",
       "5546   0.002416   1.543837    27.0  0.000070  \n",
       "8591   0.000780   3.700468   100.0  0.000260  \n",
       "5443   0.001152   4.240464   286.0  0.000743  \n",
       "9975   0.001412   2.160023    50.0  0.000130  \n",
       "8504   0.000557   0.887058     6.0  0.000016  \n",
       "13030  0.004014   1.521709    83.0  0.000216  \n",
       "9679   0.001635  -0.057404     7.0  0.000018  \n",
       "12338  0.000855   3.540300   142.0  0.000369  \n",
       "9287   0.000483   3.777429   108.0  0.000281  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = 'Pow-Score', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTFref</th>\n",
       "      <th>SType</th>\n",
       "      <th>Pow-Score</th>\n",
       "      <th>Pow-TF</th>\n",
       "      <th>Pow-wTF</th>\n",
       "      <th>Uni-Score</th>\n",
       "      <th>Uni-TF</th>\n",
       "      <th>Uni-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>environmental</td>\n",
       "      <td>environment</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>raw</td>\n",
       "      <td>3.105265</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>5.718224</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>0.004562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7759</th>\n",
       "      <td>global</td>\n",
       "      <td>global</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>raw</td>\n",
       "      <td>3.952563</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>5.194495</td>\n",
       "      <td>594.0</td>\n",
       "      <td>0.001544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12897</th>\n",
       "      <td>vietnam</td>\n",
       "      <td>vietnam</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>2.853951</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>4.789030</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.000772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>labour</td>\n",
       "      <td>labour</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>raw</td>\n",
       "      <td>3.770241</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>4.391112</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>citation</td>\n",
       "      <td>citat</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.678500</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>4.240464</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.000743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13650</th>\n",
       "      <td>enlightenment</td>\n",
       "      <td>enlighten</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>stem</td>\n",
       "      <td>2.630807</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>4.229919</td>\n",
       "      <td>283.0</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621</th>\n",
       "      <td>non</td>\n",
       "      <td>non</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>raw</td>\n",
       "      <td>3.918661</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>4.195774</td>\n",
       "      <td>547.0</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10295</th>\n",
       "      <td>portal</td>\n",
       "      <td>portal</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.320288</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>4.189048</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8590</th>\n",
       "      <td>islam</td>\n",
       "      <td>islam</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>3.834780</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>4.145154</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.000406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8035</th>\n",
       "      <td>hindu</td>\n",
       "      <td>hindu</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.078905</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.000380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Term         Stem    wTFref SType  Pow-Score  Pow-TF  \\\n",
       "7012   environmental  environment  0.000015   raw   3.105265     9.0   \n",
       "7759          global       global  0.000009   raw   3.952563    12.0   \n",
       "12897        vietnam      vietnam  0.000006   raw   2.853951     3.0   \n",
       "8757          labour       labour  0.000009   raw   3.770241    10.0   \n",
       "5443        citation        citat  0.000011   raw   4.678500    31.0   \n",
       "13650  enlightenment    enlighten  0.000011  stem   2.630807     4.0   \n",
       "9621             non          non  0.000021   raw   3.918661    29.0   \n",
       "10295         portal       portal  0.000006   raw   4.320288    13.0   \n",
       "8590           islam        islam  0.000006   raw   3.834780     8.0   \n",
       "8035           hindu        hindu  0.000006   raw        NaN     NaN   \n",
       "\n",
       "        Pow-wTF  Uni-Score  Uni-TF   Uni-wTF  \n",
       "7012   0.000334   5.718224  1755.0  0.004562  \n",
       "7759   0.000446   5.194495   594.0  0.001544  \n",
       "12897  0.000111   4.789030   297.0  0.000772  \n",
       "8757   0.000372   4.391112   266.0  0.000691  \n",
       "5443   0.001152   4.240464   286.0  0.000743  \n",
       "13650  0.000149   4.229919   283.0  0.000736  \n",
       "9621   0.001078   4.195774   547.0  0.001422  \n",
       "10295  0.000483   4.189048   163.0  0.000424  \n",
       "8590   0.000297   4.145154   156.0  0.000406  \n",
       "8035        NaN   4.078905   146.0  0.000380  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = 'Uni-Score', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTFref</th>\n",
       "      <th>SType</th>\n",
       "      <th>Pow-Score</th>\n",
       "      <th>Pow-TF</th>\n",
       "      <th>Pow-wTF</th>\n",
       "      <th>Uni-Score</th>\n",
       "      <th>Uni-TF</th>\n",
       "      <th>Uni-wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12882</th>\n",
       "      <td>veto</td>\n",
       "      <td>veto</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.136333</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>collapse</td>\n",
       "      <td>collaps</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.082428</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>1.543837</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8591</th>\n",
       "      <td>islamic</td>\n",
       "      <td>islam</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.799861</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>3.700468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>citation</td>\n",
       "      <td>citat</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.678500</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>4.240464</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.000743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>participants</td>\n",
       "      <td>particip</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.545627</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>2.160023</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8504</th>\n",
       "      <td>interpersonal</td>\n",
       "      <td>interperson</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.463388</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.887058</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13030</th>\n",
       "      <td>wealth</td>\n",
       "      <td>wealth</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.445039</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>1.521709</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9679</th>\n",
       "      <td>obedience</td>\n",
       "      <td>obedi</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.440916</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>-0.057404</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12338</th>\n",
       "      <td>template</td>\n",
       "      <td>templat</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.380007</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>3.540300</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10295</th>\n",
       "      <td>portal</td>\n",
       "      <td>portal</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.320288</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>4.189048</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9287</th>\n",
       "      <td>mid</td>\n",
       "      <td>mid</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.320288</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>3.777429</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13185</th>\n",
       "      <td>wrought</td>\n",
       "      <td>wrought</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.240245</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.704736</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11626</th>\n",
       "      <td>shocks</td>\n",
       "      <td>shock</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.240245</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13410</th>\n",
       "      <td>citations</td>\n",
       "      <td>citat</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>stem</td>\n",
       "      <td>4.188952</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>3.428660</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>experimenter</td>\n",
       "      <td>experiment</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.188952</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692</th>\n",
       "      <td>assent</td>\n",
       "      <td>assent</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.175706</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.887058</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639</th>\n",
       "      <td>dominance</td>\n",
       "      <td>domin</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.144935</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.686387</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5704</th>\n",
       "      <td>computers</td>\n",
       "      <td>comput</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.077726</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.376232</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>productivity</td>\n",
       "      <td>product</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.063789</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.496191</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8482</th>\n",
       "      <td>interactions</td>\n",
       "      <td>interact</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>raw</td>\n",
       "      <td>4.057923</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>3.084282</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Term         Stem    wTFref SType  Pow-Score  Pow-TF  \\\n",
       "12882           veto         veto  0.000021   raw   5.136333    98.0   \n",
       "5546        collapse      collaps  0.000015   raw   5.082428    65.0   \n",
       "8591         islamic        islam  0.000006   raw   4.799861    21.0   \n",
       "5443        citation        citat  0.000011   raw   4.678500    31.0   \n",
       "9975    participants     particip  0.000015   raw   4.545627    38.0   \n",
       "8504   interpersonal  interperson  0.000006   raw   4.463388    15.0   \n",
       "13030         wealth       wealth  0.000047   raw   4.445039   108.0   \n",
       "9679       obedience        obedi  0.000019   raw   4.440916    44.0   \n",
       "12338       template      templat  0.000011   raw   4.380007    23.0   \n",
       "10295         portal       portal  0.000006   raw   4.320288    13.0   \n",
       "9287             mid          mid  0.000006   raw   4.320288    13.0   \n",
       "13185        wrought      wrought  0.000006   raw   4.240245    12.0   \n",
       "11626         shocks        shock  0.000011   raw   4.240245    20.0   \n",
       "13410      citations        citat  0.000011  stem   4.188952    19.0   \n",
       "7209    experimenter   experiment  0.000011   raw   4.188952    19.0   \n",
       "4692          assent       assent  0.000009   raw   4.175706    15.0   \n",
       "6639       dominance        domin  0.000024   raw   4.144935    40.0   \n",
       "5704       computers       comput  0.000011   raw   4.077726    17.0   \n",
       "10541   productivity      product  0.000036   raw   4.063789    57.0   \n",
       "8482    interactions     interact  0.000006   raw   4.057923    10.0   \n",
       "\n",
       "        Pow-wTF  Uni-Score  Uni-TF   Uni-wTF  \n",
       "12882  0.003642        NaN     NaN       NaN  \n",
       "5546   0.002416   1.543837    27.0  0.000070  \n",
       "8591   0.000780   3.700468   100.0  0.000260  \n",
       "5443   0.001152   4.240464   286.0  0.000743  \n",
       "9975   0.001412   2.160023    50.0  0.000130  \n",
       "8504   0.000557   0.887058     6.0  0.000016  \n",
       "13030  0.004014   1.521709    83.0  0.000216  \n",
       "9679   0.001635  -0.057404     7.0  0.000018  \n",
       "12338  0.000855   3.540300   142.0  0.000369  \n",
       "10295  0.000483   4.189048   163.0  0.000424  \n",
       "9287   0.000483   3.777429   108.0  0.000281  \n",
       "13185  0.000446   0.704736     5.0  0.000013  \n",
       "11626  0.000743        NaN     NaN       NaN  \n",
       "13410  0.000706   3.428660   127.0  0.000330  \n",
       "7209   0.000706        NaN     NaN       NaN  \n",
       "4692   0.000557   0.887058     8.0  0.000021  \n",
       "6639   0.001487   0.686387    18.0  0.000047  \n",
       "5704   0.000632   0.376232     6.0  0.000016  \n",
       "10541  0.002118   0.496191    23.0  0.000060  \n",
       "8482   0.000372   3.084282    54.0  0.000140  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = ['Pow-Score','Uni-Score'], ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic by topic custom process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing  modules from omterm package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from omterms import tokenizer\n",
    "from omterms.datauis import WikiArticles, Corpus\n",
    "from omterms.cleaner import TextCleaner\n",
    "from omterms.measures import Scoring\n",
    "from omterms.utilities import *\n",
    "from omterms.stemmer import porter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing a crawled Wikipedia collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Loading and examining harvested Wikipedia articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class WikiArticles in module omterms.datauis:\n",
      "\n",
      "class WikiArticles(builtins.object)\n",
      " |  The object contains a set of tools to process the set of \n",
      " |      documents collected and cleaned by the wiki crawler.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      collection_json (:obj:`str`): This is a filename to the scraped data.\n",
      " |          Each JSON document is expected to have following fields:\n",
      " |          - theme: Topic identifier, ex: Sustainability\n",
      " |          - theme.id: A unique category identifier\n",
      " |          - document.id: A unique document id\n",
      " |          - title: Title of the document\n",
      " |          - url: Full URL of the document\n",
      " |          - depth: The link distance from the seed docuement. The seed documents depth is 0.\n",
      " |          - text: The string data scraped from the page without tags. Pancuations are not \n",
      " |              required but terms are expected to be delineated by white space. \n",
      " |      collection (:obj:`list` of :obj:`dict`): Loaded json file into native list of dictionaries.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, collection)\n",
      " |      The class constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          collection (:obj:`str`): A filename to a previously scraped data.\n",
      " |  \n",
      " |  collate(self, by_theme_id=None, by_doc_ids=[], marker='\\n')\n",
      " |      The method collects the desired set of documents concatenates them creating a unified document.\n",
      " |          The order of merge is as follows:\n",
      " |          - When neither list of theme nor doc ids is provided, it collates entire text.\n",
      " |          - If a theme is given then all the documents under that theme are to be joined first.\n",
      " |          - When a list of docs is given, only those in the list are kept.\n",
      " |          Note that if both theme id and doc ids provided, precedence is on themes.\n",
      " |      \n",
      " |      Args:\n",
      " |          by_theme_id (:obj:`int`, optional): The theme id of the docs to be collated.\n",
      " |          by_doc_ids (:obj:`list` of :obj:`int`, optional): The list of doc ids to be collated (default Empty). \n",
      " |          marker (:obj:`str`, optional): A delimiter (default newline)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`str`): The collated text.\n",
      " |  \n",
      " |  display_documents_list(self, tid=None, stdout=True)\n",
      " |      List the articles meta data and crawling information on them.\n",
      " |      \n",
      " |      Args:\n",
      " |          tid (:obj:`int`, optional): Used if documents info under a specific theme is desired \n",
      " |              otherwise a summary of whole set is returned or displayed (default None).\n",
      " |          stdout (:obj:`bool`, optional): Whether the info is to be displayed/printed\n",
      " |              to standard io (default True).\n",
      " |              \n",
      " |      Returns:\n",
      " |          ( :obj:`list`): A summary list of documents in the collection.\n",
      " |  \n",
      " |  get_document_fields(self)\n",
      " |      The method lists the fields of each json field of its collection.\n",
      " |        \n",
      " |      Args:\n",
      " |          None  \n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`dict_keys`): List of keys.\n",
      " |          None: When the collection is empty.\n",
      " |  \n",
      " |  get_theme_id(self, theme_name)\n",
      " |      The method returns topic id of the first match theme name.\n",
      " |        \n",
      " |      Args:\n",
      " |          theme_name (:obj:`str`): The theme or topic name. \n",
      " |          \n",
      " |      Returns:\n",
      " |          ( :obj:`int`): A unique theme identifier.\n",
      " |  \n",
      " |  get_theme_title(self, theme_id)\n",
      " |      The method returns topic name.\n",
      " |        \n",
      " |      Args:\n",
      " |          theme_id (:obj:`int`): The unique theme id. \n",
      " |          \n",
      " |      Returns:\n",
      " |          ( :obj:`str`): Topic name.\n",
      " |  \n",
      " |  list_themes(self)\n",
      " |      The method lists the summary of themes/topics in the collection.\n",
      " |        \n",
      " |      Args:\n",
      " |          None  \n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list` of :obj:`dict`): List of dictionry where keys are\n",
      " |              - name: theme's textual descriptor\n",
      " |              - id: theme's unique id\n",
      " |              - count: number of articles under the theme.\n",
      " |  \n",
      " |  load_corpus(self, collection=None)\n",
      " |      The method loads imports json file into a native collection.\n",
      " |        \n",
      " |      Args:\n",
      " |          collection (:obj:`str`): A filename to a previously scraped data.\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  prune(self, themes_to_keep=[], docs_to_drop=[], istodrop=<function WikiArticles.<lambda> at 0x110201730>)\n",
      " |      The method is used to filter out documents from the set.\n",
      " |          The order of prunning is as follows:\n",
      " |          - when a none empty list is provide all the documents not belonging themes to be kept\n",
      " |              are prunned entirely. Note that when initial list is empty it doesn't have an effect.\n",
      " |          - of remaing documents those appear in docs_to_drop are prunned\n",
      " |          - of the remaing docs those produce a True at a call on the predicate function are dropped.\n",
      " |          \n",
      " |          The function can be repeatedly called until a desired level of prunning is achieved.\n",
      " |      \n",
      " |      Args:\n",
      " |          themes_to_keep (:obj:`list` of :obj:`int`, optional): The list of theme ids to be kept (default Empty).\n",
      " |          docs_to_drop (:obj:`list`, optional): The list of doc ids to be dropt (default Empty). \n",
      " |          f (x :obj:`dict_item` -> :obj:`bool`, optional): A predicate function (default lambda x:False)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(WikiArticles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the corpus: 563\n",
      "\n",
      "10562749\n"
     ]
    }
   ],
   "source": [
    "# Loading:\n",
    "WikiC = WikiArticles(WIKI_DOCS)\n",
    "print(len(WikiC.collate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output file prefix: Power\n"
     ]
    }
   ],
   "source": [
    "# Selecting a specific topic\n",
    "TOPIC_NAME = 'power'\n",
    "TOPIC_ID = WikiC.get_theme_id(TOPIC_NAME)\n",
    "OUTPUT_FNAME_PREFIX = format_output_fname(TOPIC_NAME)\n",
    "print('The output file prefix: {}'.format(OUTPUT_FNAME_PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['theme', 'theme.id', 'document.id', 'title', 'url', 'depth', 'text'])\n",
      "4\n",
      "power\n"
     ]
    }
   ],
   "source": [
    "# Getting fields name on each document in the collection\n",
    "print(WikiC.get_document_fields())\n",
    "print(WikiC.get_theme_id(TOPIC_NAME))\n",
    "print(WikiC.get_theme_title(TOPIC_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Filtering out by a set of use case creteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function prune in module omterms.datauis:\n",
      "\n",
      "prune(self, themes_to_keep=[], docs_to_drop=[], istodrop=<function WikiArticles.<lambda> at 0x110201730>)\n",
      "    The method is used to filter out documents from the set.\n",
      "        The order of prunning is as follows:\n",
      "        - when a none empty list is provide all the documents not belonging themes to be kept\n",
      "            are prunned entirely. Note that when initial list is empty it doesn't have an effect.\n",
      "        - of remaing documents those appear in docs_to_drop are prunned\n",
      "        - of the remaing docs those produce a True at a call on the predicate function are dropped.\n",
      "        \n",
      "        The function can be repeatedly called until a desired level of prunning is achieved.\n",
      "    \n",
      "    Args:\n",
      "        themes_to_keep (:obj:`list` of :obj:`int`, optional): The list of theme ids to be kept (default Empty).\n",
      "        docs_to_drop (:obj:`list`, optional): The list of doc ids to be dropt (default Empty). \n",
      "        f (x :obj:`dict_item` -> :obj:`bool`, optional): A predicate function (default lambda x:False)\n",
      "        \n",
      "    Returns:\n",
      "        (:obj:`bool`): True.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(WikiArticles.prune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document.id :: theme.id :: theme :: depth :: url\n",
      "19 4 power 0 https://en.wikipedia.org/wiki/Power_(social_and_political)\n",
      "21 4 power 0 https://en.wikipedia.org/wiki/Authority\n",
      "361 4 power 0 https://en.wikipedia.org/wiki/Wealth\n",
      "54 4 power 1 https://en.wikipedia.org/wiki/The_Anatomy_of_Revolution\n",
      "55 4 power 1 https://en.wikipedia.org/wiki/Personal_boundaries\n",
      "56 4 power 1 https://en.wikipedia.org/wiki/State_collapse\n",
      "57 4 power 1 https://en.wikipedia.org/wiki/Discourse_of_power\n",
      "58 4 power 1 https://en.wikipedia.org/wiki/Speaking_truth_to_power\n",
      "59 4 power 1 https://en.wikipedia.org/wiki/Amity-enmity_complex\n",
      "60 4 power 1 https://en.wikipedia.org/wiki/Social_control\n",
      "66 4 power 1 https://en.wikipedia.org/wiki/Veto\n",
      "67 4 power 1 https://en.wikipedia.org/wiki/Cognitive_authority\n",
      "69 4 power 1 https://en.wikipedia.org/wiki/Cratology\n",
      "70 4 power 1 https://en.wikipedia.org/wiki/Appeal_to_authority\n",
      "71 4 power 1 https://en.wikipedia.org/wiki/Religious_authority\n",
      "72 4 power 1 https://en.wikipedia.org/wiki/Authority_(management)\n",
      "73 4 power 1 https://en.wikipedia.org/wiki/Petty_authority\n",
      "74 4 power 1 https://en.wikipedia.org/wiki/Milgram_experiment\n",
      "75 4 power 1 https://en.wikipedia.org/wiki/Anti-authoritarianism\n",
      "76 4 power 1 https://en.wikipedia.org/wiki/Dominance_(ethology)\n",
      "77 4 power 1 https://en.wikipedia.org/wiki/Control_of_time_in_power_relationships\n",
      "82 4 power 1 https://en.wikipedia.org/wiki/Authoritarianism\n",
      "368 4 power 1 https://en.wikipedia.org/wiki/Gross_National_Happiness\n",
      "371 4 power 1 https://en.wikipedia.org/wiki/Happiness_economics\n",
      "374 4 power 1 https://en.wikipedia.org/wiki/Productivity_improving_technologies_(historical)\n",
      "document.id :: theme.id :: theme :: depth :: url\n",
      "19 4 power 0 https://en.wikipedia.org/wiki/Power_(social_and_political)\n",
      "21 4 power 0 https://en.wikipedia.org/wiki/Authority\n"
     ]
    }
   ],
   "source": [
    "# Some random prunning\n",
    "WikiC.prune(themes_to_keep = [TOPIC_ID])\n",
    "WikiC.display_documents_list(tid=TOPIC_ID, stdout = True)\n",
    "DOCS = [19,21]\n",
    "WikiC.prune(istodrop = lambda x: x['document.id'] not in DOCS)\n",
    "WikiC.display_documents_list()\n",
    "TEXT = WikiC.collate(by_theme_id = TOPIC_ID, by_doc_ids = DOCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the corpus: 563\n",
      "\n",
      "document.id :: theme.id :: theme :: depth :: url\n",
      "19 4 power 0 https://en.wikipedia.org/wiki/Power_(social_and_political)\n",
      "21 4 power 0 https://en.wikipedia.org/wiki/Authority\n",
      "361 4 power 0 https://en.wikipedia.org/wiki/Wealth\n",
      "57 4 power 1 https://en.wikipedia.org/wiki/Discourse_of_power\n",
      "58 4 power 1 https://en.wikipedia.org/wiki/Speaking_truth_to_power\n",
      "59 4 power 1 https://en.wikipedia.org/wiki/Amity-enmity_complex\n",
      "60 4 power 1 https://en.wikipedia.org/wiki/Social_control\n",
      "66 4 power 1 https://en.wikipedia.org/wiki/Veto\n",
      "67 4 power 1 https://en.wikipedia.org/wiki/Cognitive_authority\n",
      "69 4 power 1 https://en.wikipedia.org/wiki/Cratology\n",
      "70 4 power 1 https://en.wikipedia.org/wiki/Appeal_to_authority\n",
      "71 4 power 1 https://en.wikipedia.org/wiki/Religious_authority\n",
      "72 4 power 1 https://en.wikipedia.org/wiki/Authority_(management)\n",
      "73 4 power 1 https://en.wikipedia.org/wiki/Petty_authority\n",
      "74 4 power 1 https://en.wikipedia.org/wiki/Milgram_experiment\n",
      "75 4 power 1 https://en.wikipedia.org/wiki/Anti-authoritarianism\n",
      "76 4 power 1 https://en.wikipedia.org/wiki/Dominance_(ethology)\n",
      "77 4 power 1 https://en.wikipedia.org/wiki/Control_of_time_in_power_relationships\n",
      "82 4 power 1 https://en.wikipedia.org/wiki/Authoritarianism\n",
      "368 4 power 1 https://en.wikipedia.org/wiki/Gross_National_Happiness\n",
      "371 4 power 1 https://en.wikipedia.org/wiki/Happiness_economics\n",
      "374 4 power 1 https://en.wikipedia.org/wiki/Productivity_improving_technologies_(historical)\n",
      "document.id :: theme.id :: theme :: depth :: url\n",
      "19 4 power 0 https://en.wikipedia.org/wiki/Power_(social_and_political)\n",
      "21 4 power 0 https://en.wikipedia.org/wiki/Authority\n",
      "57 4 power 1 https://en.wikipedia.org/wiki/Discourse_of_power\n",
      "58 4 power 1 https://en.wikipedia.org/wiki/Speaking_truth_to_power\n",
      "59 4 power 1 https://en.wikipedia.org/wiki/Amity-enmity_complex\n",
      "60 4 power 1 https://en.wikipedia.org/wiki/Social_control\n",
      "66 4 power 1 https://en.wikipedia.org/wiki/Veto\n",
      "67 4 power 1 https://en.wikipedia.org/wiki/Cognitive_authority\n",
      "69 4 power 1 https://en.wikipedia.org/wiki/Cratology\n",
      "70 4 power 1 https://en.wikipedia.org/wiki/Appeal_to_authority\n",
      "71 4 power 1 https://en.wikipedia.org/wiki/Religious_authority\n",
      "72 4 power 1 https://en.wikipedia.org/wiki/Authority_(management)\n",
      "73 4 power 1 https://en.wikipedia.org/wiki/Petty_authority\n",
      "74 4 power 1 https://en.wikipedia.org/wiki/Milgram_experiment\n",
      "75 4 power 1 https://en.wikipedia.org/wiki/Anti-authoritarianism\n",
      "76 4 power 1 https://en.wikipedia.org/wiki/Dominance_(ethology)\n",
      "77 4 power 1 https://en.wikipedia.org/wiki/Control_of_time_in_power_relationships\n",
      "82 4 power 1 https://en.wikipedia.org/wiki/Authoritarianism\n",
      "368 4 power 1 https://en.wikipedia.org/wiki/Gross_National_Happiness\n",
      "371 4 power 1 https://en.wikipedia.org/wiki/Happiness_economics\n",
      "document.id :: theme.id :: theme :: depth :: url\n",
      "19 4 power 0 https://en.wikipedia.org/wiki/Power_(social_and_political)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'theme': 'power',\n",
       "  'theme.id': 4,\n",
       "  'document.id': 19,\n",
       "  'title': 'Power (social and political)',\n",
       "  'url': 'https://en.wikipedia.org/wiki/Power_(social_and_political)',\n",
       "  'depth': 0}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some more random prunning examples\n",
    "WikiC = WikiArticles(WIKI_DOCS)\n",
    "WikiC.prune(themes_to_keep = [TOPIC_ID],\n",
    "            docs_to_drop = [54, 55,56],\n",
    "            istodrop = lambda x: not 0 <= x['depth'] < 2)\n",
    "WikiC.display_documents_list()\n",
    "WikiC.prune(docs_to_drop = [374,361,255])\n",
    "WikiC.display_documents_list()\n",
    "WikiC.prune(istodrop = lambda x: len(x['text']) < 10000 or x['depth'] == 1 )\n",
    "WikiC.display_documents_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Joining a subset of articles within a topic for further analysis.\n",
    "\n",
    "It should be noted such document unification is a convenience if tokenization, frequency counts etc are done around a single topic. In other words, if the corpus holds a large set of documents and $tf$ $x$ $idf$ style examinations are intended, then merging the documents may cause loss of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function collate in module omterms.datauis:\n",
      "\n",
      "collate(self, by_theme_id=None, by_doc_ids=[], marker='\\n')\n",
      "    The method collects the desired set of documents concatenates them creating a unified document.\n",
      "        The order of merge is as follows:\n",
      "        - When neither list of theme nor doc ids is provided, it collates entire text.\n",
      "        - If a theme is given then all the documents under that theme are to be joined first.\n",
      "        - When a list of docs is given, only those in the list are kept.\n",
      "        Note that if both theme id and doc ids provided, precedence is on themes.\n",
      "    \n",
      "    Args:\n",
      "        by_theme_id (:obj:`int`, optional): The theme id of the docs to be collated.\n",
      "        by_doc_ids (:obj:`list` of :obj:`int`, optional): The list of doc ids to be collated (default Empty). \n",
      "        marker (:obj:`str`, optional): A delimiter (default newline)\n",
      "        \n",
      "    Returns:\n",
      "        (:obj:`str`): The collated text.\n",
      "\n",
      "Length of the corpus in terms of characters: 40701\n"
     ]
    }
   ],
   "source": [
    "help(WikiArticles.collate)\n",
    "TEXT = WikiC.collate(by_theme_id = TOPIC_ID, marker = \" \")\n",
    "print('Length of the corpus in terms of characters: {}'.format(len(TEXT)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenizing\n",
    "A custom tokenizer is developed and is being used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module omterms.tokenizer in omterms:\n",
      "\n",
      "NAME\n",
      "    omterms.tokenizer - OpenMaker text tokenizer.\n",
      "\n",
      "DESCRIPTION\n",
      "    Author: Bulent Ozel\n",
      "    e-mail: bulent.ozel@gmail.com\n",
      "    \n",
      "    The module contains a set of basic tools in order to tokenize a given inout text.\n",
      "    \n",
      "    Todo:\n",
      "        * Nothing at the moment ;)\n",
      "\n",
      "FUNCTIONS\n",
      "    normalise(s)\n",
      "        Basic string normalisation.\n",
      "        \n",
      "        Args:\n",
      "            s: (:obj:`str`): Input string to normalise.\n",
      "        \n",
      "        Returns:\n",
      "            (:obj:`str`): Normalised string.\n",
      "    \n",
      "    tokenize(raw)\n",
      "        The function tokenizes by splitting them on spaces, line breaks or characters\n",
      "            in CHARACTERS_TO_SPLIT.\n",
      "        \n",
      "        Args:\n",
      "            raw: (:obj:`str`): Input string to split\n",
      "        \n",
      "        Returns:\n",
      "            (:obj:`list` of :obj:`str`): list of terms\n",
      "    \n",
      "    tokenize_strip_non_words(raw)\n",
      "        Same as tokenize, but also removes non-word characters.\n",
      "        \n",
      "        Args:\n",
      "            raw: (:obj:`str`): Input string to split\n",
      "        \n",
      "        Returns:\n",
      "            (:obj:`list` of :obj:`str`): list of terms\n",
      "    \n",
      "    tokenized_pprint(tokens)\n",
      "        A pretty print function for strings tokenized by tokenize.\n",
      "        \n",
      "        Args:\n",
      "            tokens: (:obj:`list` of :obj:`str`): list of terms \n",
      "        \n",
      "        Returns:\n",
      "            (:obj:`str`): The joined terms.\n",
      "\n",
      "DATA\n",
      "    ALLOWED_SYMBOLS = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', '...\n",
      "    CHARACTERS_TO_SPLIT = \".,():;!?\\n`'=+/\\\\[]}{|><@#$%^&*_‘’“”.\"\n",
      "    REPLACEMENTS = {'&': 'and', \"'\": ' ', '-': ' ', r'\\x05': ' ', '`': ' '...\n",
      "\n",
      "FILE\n",
      "    /Users/bulentozel/OpenMaker/GitHub/omterms/omterms/tokenizer.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOKENS = tokenizer.tokenize_strip_non_words(TEXT)\n",
    "#tokenizer.tokenized_pprint(TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term counts: Power Corpus = 6190\n"
     ]
    }
   ],
   "source": [
    "print('Term counts: {} Corpus = {}'.format(TOPIC_NAME.capitalize(), len(TOKENS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning and counting\n",
    "A set of custome text cleaning tools is developed.\n",
    "\n",
    "This is an example case for post proceesing in terms of cleaning. The pre-processing, that is data cleaning/preperation during or right after harvesting could be further improved to avoid such processes at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TextCleaner in module omterms.cleaner:\n",
      "\n",
      "class TextCleaner(builtins.object)\n",
      " |  An object that contains a set of tools to clean and preprocess textual data.\n",
      " |  \n",
      " |  Note:\n",
      " |      The object uses nltk.FreqDist object\n",
      " |      For stem checks during pruninng it needs an external stemmer.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      exceptions (:obj:`list` of :obj:`str`): List of excepted terms.\n",
      " |      stopwords (:obj:`list` of :obj:`str`): List of stopwords.\n",
      " |      stemf: A stemmer funtion.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, stopwords=[], exceptions=[], fstemmer=<function TextCleaner.<lambda> at 0x110203400>, stemcheck=False)\n",
      " |      The class constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          stopwords (:obj:`list` of :obj:`str`, optional): list of stopwords (default None).\n",
      " |          exceptions (:obj:`set` of :obj:`str`, optional): list of excepted terms (default None).\n",
      " |          fstemmer (x :obj:`str` -> y: :obj:`str`, optional): A stemmer function (default f(x) = x)\n",
      " |          stemcheck (:obj:`bool`): A flag to determine whether stems of exceptions should also be considered\n",
      " |              (default False)\n",
      " |  \n",
      " |  clean(self, words, display_top=10, logging=True, exceptions=[])\n",
      " |      Removes panctuations and stopwords from a corpus.\n",
      " |          \n",
      " |      Args:\n",
      " |          words (:obj:`list` of :obj:`str`): The input corpus as list of words.\n",
      " |          display_top (:obj:`int`, optional): Logging size (default 10).\n",
      " |          logging (:obj:`bool`): Optional. When true stdout logging is done (default True).\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The list terms that will not \n",
      " |              be pruned (default None).\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns the trimmed corpus as the NLTK obj.\n",
      " |  \n",
      " |  extend_stopwords(self, spointer)\n",
      " |      The method extends a new stopwords list.\n",
      " |          \n",
      " |      Args:\n",
      " |          spointer (:obj:`list` of :obj:`str`, :obj:`str`): Either file path string or\n",
      " |              a list of stopwords.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: True if successful, False otherwise.\n",
      " |      \n",
      " |      Raises:\n",
      " |          FileNotFoundError: Raised if a given file is not accessable.\n",
      " |  \n",
      " |  isexception(self, term, exceptions=[], stemcheck=False)\n",
      " |      The static makes the exception list and returns it.\n",
      " |      \n",
      " |      Args:\n",
      " |          term (:obj:`str`): The term.\n",
      " |          exceptions (:obj:`list`, optional): The list of exception terms (default None).\n",
      " |          stemcheck (:obj:`bool`, optional): if the list to be extended via the stems (default False)\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`bool`):\n",
      " |  \n",
      " |  load_stopwords(self, spointer)\n",
      " |      The method reloads a new stopwords list.\n",
      " |      \n",
      " |      Note:\n",
      " |          Internal stopword is overwritten.\n",
      " |          \n",
      " |      Args:\n",
      " |          spointer (:obj:`list` of :obj:`str`or :obj:`str`): Either file path string or\n",
      " |              a list of stopwords.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: True if successful, False otherwise.\n",
      " |      \n",
      " |      Raises:\n",
      " |          FileNotFoundError: Raised if a given file is not accessable.\n",
      " |  \n",
      " |  remove_contains(self, freq_dist, literals=\".,():;!?\\n`'=+/\\\\[]}{|><@#$%^&*_‘’“”.\", exceptions=[])\n",
      " |      Removes the terms that contains the specific literals.\n",
      " |              \n",
      " |      Args:\n",
      " |          freq_dist (:obj:`nltk.FreqDist`): list of words and more.\n",
      " |          literals (:obj:`list` of  :obj:`str`): list of literals.\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The exception list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  remove_numerals(self, freq_dist, remove_any=False, exceptions=[])\n",
      " |      The method removes terms with numeral literals.\n",
      " |          \n",
      " |      Note:\n",
      " |          When remove_any is selected, literals such as 3D would vanish.\n",
      " |          \n",
      " |      Args:\n",
      " |          freq_dist (:obj:`nltk.FreqDist`): list of words and more.\n",
      " |          remove_any (:obj:`bool`, optional): If True mumeral and literal mixed terms are removed.\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The exception list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  remove_panctuation(self, freq_dist, exceptions=[])\n",
      " |      The static method removes punctuation only terms.\n",
      " |          \n",
      " |      Args:\n",
      " |          freq_dist (:obj:`nltk.FreqDist`): list of words and more.\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The exception list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  remove_rare_terms(self, freq_dist, below=3, exceptions=[])\n",
      " |      The method removes terms that have rare occurances.\n",
      " |      \n",
      " |      Note:\n",
      " |          Such removal may help reduce errenous and random terms.\n",
      " |          \n",
      " |      Args:\n",
      " |          freq_dist (:obj:`nltk.FreqDist`): list of words and more.\n",
      " |          below (:obj:`int`, optional): The minumum allowed frequency count (default 3).\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The exception list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  remove_short_terms(self, freq_dist, threshold=1, exceptions=[])\n",
      " |      The method removes terms that are below a certain length.\n",
      " |      \n",
      " |      Args:\n",
      " |          freq_dist (:obj:`nltk.FreqDist`): list of words and more.\n",
      " |          threshold (:obj:`int`, optional): The charcter length of a term (default 1).\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The exception list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  remove_stopwords(self, freq_dist, exceptions=[])\n",
      " |      The static method removes stopwords.\n",
      " |          \n",
      " |      Args:\n",
      " |          freq_dist (:obj:`nltk.FreqDist`): list of words and more.\n",
      " |          exceptions (:obj:`list` of :obj:`str`, optional): The exception list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  reset_exceptions(self)\n",
      " |      Resets the exception set to empty.\n",
      " |      \n",
      " |      Args:\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`bool`):\n",
      " |  \n",
      " |  set_exceptions(self, exceptions, stemcheck=False)\n",
      " |      Sets instance-wide exception set.\n",
      " |      \n",
      " |      Args:\n",
      " |          exceptions (:obj:`list` of `str`): The list of exception terms.\n",
      " |          stemcheck (:obj:`bool`, optional): if the list to be extended via the stems (default False)\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  freq_dist(words)\n",
      " |      The static method computes frequency distribution of a word list.\n",
      " |          \n",
      " |      Args:\n",
      " |          words (:obj:`list` of :obj:`str`, :obj:`str`): list of words.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`nltk.FreqDist`): Returns frequency dist.\n",
      " |  \n",
      " |  make_exceptions(exceptions, stemf=<function TextCleaner.<lambda> at 0x1102039d8>, stemcheck=False)\n",
      " |      The static method makes the exception list and returns it.\n",
      " |      \n",
      " |      Args:\n",
      " |          exceptions (:obj:`list`): The list of exception terms.\n",
      " |          stemf (x :obj:`str` -> y: :obj:`str`, optional): A stemmer function (default f(x) = x)\n",
      " |          stemcheck (:obj:`bool`, optional): if the list to be extended via the stems (default False)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`set`): The exception set. If stemcheck is opted both terms and their stems \n",
      " |              is be represented in the list.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TextCleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Forming stopwords list\n",
    "A domain specific stop-word is added to standard stopwords. Domain specific in this tutorial is examplary and it needs to be extended.\n",
    "\n",
    "A larger list of stopwords can be generated either\n",
    "- by repeating the examination flow that is outlined in this tutorial, which would give insight on the subject\n",
    "- or via adoption of state of art methods that specifically focus on theme specific stopward generation, which itself is an interesting and crucial research and development issue within NLP and Text Analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cleaner = TextCleaner()\n",
    "Cleaner.load_stopwords(STOPWORDS_STANDARD)\n",
    "Cleaner.extend_stopwords(STOPWORDS_SPECIFIC)\n",
    "#pp.pprint(Cleaner.stopwords)\n",
    "len(Cleaner.stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Adding/notifying list of theme/topic specific terms\n",
    "A maker culture speficic term such as 3-D or 3D, reprap, c2c, or abbrieviations such as oss (open source software) are important in the discourse of the community but maybe considered or skipped in most text cleaning techniques. Besides, each community movement generates and created its own terms which may not be present in the common culture and so in a background corpus.\n",
    "\n",
    "Adding a precompiled list of specific terms, if exists or needed, right after the instantiation stage of the cleaner stage also helps to protect them in later cleaning and prunning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/specifics_openmaker.txt'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TERMS_SPECIFIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3-d',\n",
      " '3d',\n",
      " 'abatement',\n",
      " 'affordable',\n",
      " 'agenda21',\n",
      " 'anarchism',\n",
      " 'autonomous',\n",
      " 'biodiesel',\n",
      " 'biodiversity',\n",
      " 'biofuel',\n",
      " 'biogas',\n",
      " 'biomass',\n",
      " 'biosphere',\n",
      " 'bricolage',\n",
      " 'brundtland',\n",
      " 'c2c',\n",
      " 'cad',\n",
      " 'cap-and-trade',\n",
      " 'carfree',\n",
      " 'cdm',\n",
      " 'christensen',\n",
      " 'co-creation',\n",
      " 'co-develop',\n",
      " 'co-invention',\n",
      " 'co-inventor',\n",
      " 'coextinction',\n",
      " 'cognition',\n",
      " 'commons-based',\n",
      " 'computer-aided',\n",
      " 'conferencing',\n",
      " 'consortium',\n",
      " 'constraints',\n",
      " 'construct',\n",
      " 'copyleft',\n",
      " 'copyright',\n",
      " 'cradle-to-cradle',\n",
      " 'crowdsourcing',\n",
      " 'crowdworker',\n",
      " 'cuvier',\n",
      " 'deforestation',\n",
      " 'desalination',\n",
      " 'displaystyle',\n",
      " 'diy',\n",
      " 'eco',\n",
      " 'eco-innovation',\n",
      " 'ecology',\n",
      " 'ecopsychology',\n",
      " 'ecosystem',\n",
      " 'edupunk',\n",
      " 'electromagnetic',\n",
      " 'extrinsic',\n",
      " 'f-oss',\n",
      " 'fab',\n",
      " 'fairtrade',\n",
      " 'footprint',\n",
      " 'foss',\n",
      " 'fossil',\n",
      " 'freshwater',\n",
      " 'geothermal',\n",
      " 'glazunov',\n",
      " 'gnu',\n",
      " 'google',\n",
      " 'graphics',\n",
      " 'greenoman',\n",
      " 'grid',\n",
      " 'groupware',\n",
      " 'hackerspace',\n",
      " 'high-technology',\n",
      " 'hippel',\n",
      " 'holistic ',\n",
      " 'how-to',\n",
      " 'hydro',\n",
      " 'hydroelectricity',\n",
      " 'hydropower',\n",
      " 'hype',\n",
      " 'hyperdiffusionism',\n",
      " 'ideation',\n",
      " 'ieee',\n",
      " 'ietf',\n",
      " 'infrastructure',\n",
      " 'internet',\n",
      " 'interoperability',\n",
      " 'intranet',\n",
      " 'iso',\n",
      " 'isoiec',\n",
      " 'itu-t',\n",
      " 'kludge',\n",
      " 'kluge',\n",
      " 'landfill',\n",
      " 'laser',\n",
      " 'life-cycle',\n",
      " 'lifecycle',\n",
      " 'lifestyles',\n",
      " 'linux',\n",
      " 'liveable',\n",
      " 'marginalize',\n",
      " 'methane',\n",
      " 'microsoft',\n",
      " 'mit',\n",
      " 'nikolay',\n",
      " 'non-discriminatory',\n",
      " 'online',\n",
      " 'open-source',\n",
      " 'openbts',\n",
      " 'opencores',\n",
      " 'organisation',\n",
      " 'osi',\n",
      " 'oss',\n",
      " 'participatory',\n",
      " 'pearce',\n",
      " 'permaculture',\n",
      " 'photovoltaic',\n",
      " 'photovoltaics',\n",
      " 'post-partisanship',\n",
      " 'programmable',\n",
      " 'proprietary',\n",
      " 'prosumer',\n",
      " 'prosumption',\n",
      " 'prototype',\n",
      " 'psychometric',\n",
      " 'racism',\n",
      " 'rainwater',\n",
      " 'recycled',\n",
      " 'recycling',\n",
      " 'reprap',\n",
      " 'reuse',\n",
      " 'rimsky-korsakov',\n",
      " 'robotics',\n",
      " 'schmidhuber',\n",
      " 'schumpeter',\n",
      " 'software',\n",
      " 'sparkfun',\n",
      " 'stakeholders',\n",
      " 'sternberg',\n",
      " 'sub-saharan',\n",
      " 'sustainable',\n",
      " 'telepresence',\n",
      " 'thingiverse',\n",
      " 'toolkit',\n",
      " 'unsustainable',\n",
      " 'value-added',\n",
      " 'w3c',\n",
      " 'website',\n",
      " 'wiki',\n",
      " 'wikinomics'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cleaner.set_exceptions(load_from_file(TERMS_SPECIFIC))\n",
    "pp.pprint(Cleaner.exceptions)\n",
    "len(Cleaner.exceptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Removing panctuations and stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6190\n",
      "Initial state:\n",
      "Total term counts: 6190\n",
      "[('the', 326),\n",
      " ('power', 245),\n",
      " ('of', 224),\n",
      " ('and', 203),\n",
      " ('to', 179),\n",
      " ('in', 119),\n",
      " ('a', 119),\n",
      " ('is', 102),\n",
      " ('that', 81),\n",
      " ('as', 71)]\n",
      "Removing panctuation only terms...\n",
      "Total term counts: 6190\n",
      "[('the', 326),\n",
      " ('power', 245),\n",
      " ('of', 224),\n",
      " ('and', 203),\n",
      " ('to', 179),\n",
      " ('in', 119),\n",
      " ('a', 119),\n",
      " ('is', 102),\n",
      " ('that', 81),\n",
      " ('as', 71)]\n",
      "Removing stopwords...\n",
      "Total term counts: 3541\n",
      "[('power', 245),\n",
      " ('people', 40),\n",
      " ('tactics', 33),\n",
      " ('powerful', 31),\n",
      " ('social', 27),\n",
      " ('control', 23),\n",
      " ('group', 23),\n",
      " ('influence', 22),\n",
      " ('use', 20),\n",
      " ('coercive', 20)]\n"
     ]
    }
   ],
   "source": [
    "print(len(TOKENS))\n",
    "TOKENS_TF = Cleaner.clean(TOKENS,logging = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 4560 punctuations and stopword occurances are removed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('power', 245),\n",
       " ('people', 40),\n",
       " ('tactics', 33),\n",
       " ('powerful', 31),\n",
       " ('social', 27),\n",
       " ('control', 23),\n",
       " ('group', 23),\n",
       " ('influence', 22),\n",
       " ('use', 20),\n",
       " ('coercive', 20)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('A total of {} punctuations and stopword occurances are removed.'.format(len(TOKENS) - len(TOKENS_TF)))\n",
    "TOKENS_TF.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Removing all numeral terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction due to all numeral terms = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('power', 245),\n",
       " ('people', 40),\n",
       " ('tactics', 33),\n",
       " ('powerful', 31),\n",
       " ('social', 27),\n",
       " ('control', 23),\n",
       " ('group', 23),\n",
       " ('influence', 22),\n",
       " ('use', 20),\n",
       " ('coercive', 20)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS_TFu = Cleaner.remove_numerals(TOKENS_TF, remove_any = False, exceptions = [])\n",
    "print(\"Reduction due to all numeral terms = {}\".format(len(TOKENS_TF) - len(TOKENS_TFu)))\n",
    "TOKENS_TF = TOKENS_TFu\n",
    "TOKENS_TF.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Removing terms that has numerals in them\n",
    "This would remove literals such as 20th, 3D, etc unless they are in the exception of the cleaner object or marked as exception during the function call. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction due to partially numeral terms = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('power', 245),\n",
       " ('people', 40),\n",
       " ('tactics', 33),\n",
       " ('powerful', 31),\n",
       " ('social', 27),\n",
       " ('control', 23),\n",
       " ('group', 23),\n",
       " ('influence', 22),\n",
       " ('use', 20),\n",
       " ('coercive', 20)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS_TFu = Cleaner.remove_numerals(TOKENS_TF, remove_any = True, exceptions = [])\n",
    "print(\"Reduction due to partially numeral terms = {}\".format(len(TOKENS_TF) - len(TOKENS_TFu)))\n",
    "TOKENS_TF = TOKENS_TFu\n",
    "TOKENS_TF.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Removing very short terms\n",
    "Terms such a, s, *, -, etc are removed  via the operation below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction due to short terms = 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('power', 245),\n",
       " ('people', 40),\n",
       " ('tactics', 33),\n",
       " ('powerful', 31),\n",
       " ('social', 27),\n",
       " ('control', 23),\n",
       " ('group', 23),\n",
       " ('influence', 22),\n",
       " ('use', 20),\n",
       " ('coercive', 20)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS_TFu = Cleaner.remove_short_terms(TOKENS_TF, threshold = MIN_LENGTH, exceptions = [])\n",
    "print(\"Reduction due to short terms = {}\".format(len(TOKENS_TF) - len(TOKENS_TFu)))\n",
    "TOKENS_TF = TOKENS_TFu\n",
    "TOKENS_TF.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Removing terms with low occurance frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction due to rare terms = 1309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('power', 245),\n",
       " ('people', 40),\n",
       " ('tactics', 33),\n",
       " ('powerful', 31),\n",
       " ('social', 27),\n",
       " ('control', 23),\n",
       " ('group', 23),\n",
       " ('influence', 22),\n",
       " ('use', 20),\n",
       " ('coercive', 20)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS_TFu = Cleaner.remove_rare_terms(TOKENS_TF, below = MIN_FREQ)\n",
    "print(\"Reduction due to rare terms = {}\".format(len(TOKENS_TF) - len(TOKENS_TFu)))\n",
    "TOKENS_TF = TOKENS_TFu\n",
    "TOKENS_TF.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Removing terms that contain not allowed symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\".,():;!?\\n`'=+/\\\\[]}{|><@#$%^&*_‘’“”.\"\n",
      "Reduction due to terms with not allowed symbols = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('power', 245),\n",
       " ('people', 40),\n",
       " ('tactics', 33),\n",
       " ('powerful', 31),\n",
       " ('social', 27),\n",
       " ('control', 23),\n",
       " ('group', 23),\n",
       " ('influence', 22),\n",
       " ('use', 20),\n",
       " ('coercive', 20)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.pprint(NOTALLOWED)\n",
    "TOKENS_TFu = Cleaner.remove_contains(TOKENS_TF, literals = NOTALLOWED)\n",
    "print(\"Reduction due to terms with not allowed symbols = {}\".format(len(TOKENS_TF) - len(TOKENS_TFu)))\n",
    "TOKENS_TF = TOKENS_TFu\n",
    "TOKENS_TF.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total term count reduction during cleaning process = 5884\n",
      "Percentage = 4.9%\n"
     ]
    }
   ],
   "source": [
    "print(\"The total term count reduction during cleaning process = {}\".format(len(TOKENS) - len(TOKENS_TFu)))\n",
    "print(\"Percentage = {}%\".format((round(100 * len(TOKENS_TFu)/len(TOKENS),1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Anayzing a cleaned corpus\n",
    "A generic Corpus module that is designed and implemented for this provides a collection of tools for the purpose.\n",
    "\n",
    "\n",
    "Inspection below can be beneficial for both to improve cleaning and tokenization steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Corpus in module omterms.datauis:\n",
      "\n",
      "class Corpus(builtins.object)\n",
      " |  A generic class to be used for foreground or background corpuses.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      tf_dist: (:obj:`nltk.FreqDist`): An NLTK container for tokenized and cleaned\n",
      " |          terms in the corpus.\n",
      " |      stemmer (x :obj:`str` -> y: :obj:`str`): A stemmer function.\n",
      " |      stems (:obj:`dict`): A dictionary of terms and their stems\n",
      " |      labels (:obj:`dict`): Term level labels.\n",
      " |      scores (:obj:`dict`): A dictionary of terms and their corpus sepcificity scores\n",
      " |          as of a reference corpus\n",
      " |      ref (:obj:`dict`): A dictionary of terms that holds normalized occurance frequency of\n",
      " |          the term at a reference corpus.\n",
      " |      sepficifs (:obj:`set`): A set of terms appointed/associated with the corpus externally.        \n",
      " |      To be implemented:\n",
      " |          texts_raw (:obj:`json`): A JSON collection of raw texts of the corpus.\n",
      " |      \n",
      " |          texts_clean (:obj:`json`): A JSON collection of cleaned/processed\n",
      " |          texts of the corpus.\n",
      " |      \n",
      " |          tf_idf (:obj:`json`): Tf-Idf analyses of the corpus (to be implemented).\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, tf_dist, stemmer=None)\n",
      " |      The class constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          tf_dist (:obj:`nltk.FreqDist`): An NLTK container for tokenized and cleaned\n",
      " |          terms in the corpus.\n",
      " |          stemmer (x :obj:`str` -> y: :obj:`str`): A stemmer function (default None)\n",
      " |  \n",
      " |  compute_stems(self)\n",
      " |      The function returns the a dictionary of terms and their corresponding stems.\n",
      " |      \n",
      " |      Args:\n",
      " |          stemmer (x :obj:`str` -> y: :obj:`str`): A stemmer function (default None)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True\n",
      " |  \n",
      " |  difference(self, other, as_corpus=False, stats=False)\n",
      " |      The method identifies and returns the difference of the self from the other.\n",
      " |      \n",
      " |      Note:\n",
      " |          Implementation needs style and refactoring.\n",
      " |          \n",
      " |      Args:\n",
      " |          other (:obj:`Corpus`): An instance of this Corpus Class object.\n",
      " |          as_corpus (bool): When True it returns a new Corpus (default False).\n",
      " |          stats (bool): When True and as_corpus is false returns the frequency \n",
      " |              count of the difference set.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`dict`): A dictionary of terms and their frequency counts.\n",
      " |  \n",
      " |  get_count_uniques(self)\n",
      " |      The method identifies and returns top frequent terms.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`int`): Returns an integer.\n",
      " |  \n",
      " |  get_least_frequents(self, bottom=42)\n",
      " |      The method identifies and returns least frequent terms.\n",
      " |      \n",
      " |      Args:\n",
      " |          bottom (int): Size of the short list (default 42).\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list` of :obj:`tuple` of :obj:`str` and :obj:`int`): Returns the frequency dist\n",
      " |              for the least frequent terms as list of tuples of term and frequency pairs.\n",
      " |  \n",
      " |  get_size(self)\n",
      " |      The returns the size of the corpus in terms of number of terms it has.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`int`): Returns an integer. It is summation of raw frequency counts.\n",
      " |  \n",
      " |  get_stems(self)\n",
      " |      The function returns the a dictionary of terms and their corresponding stems.\n",
      " |      \n",
      " |      Args:\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`dict`): A dictionary of {term:stem of the term}.\n",
      " |  \n",
      " |  get_top_frequents(self, top=42)\n",
      " |      The method identifies and returns top frequent terms.\n",
      " |      \n",
      " |      Args:\n",
      " |          top (int): Size of the short list (default 42).\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list` of :obj:`tuple` of :obj:`str` and :obj:`int`): Returns the frequency dist\n",
      " |              for top terms as list of tuples of term and frequency pairs.\n",
      " |  \n",
      " |  intersection(self, other, as_corpus=False, stats=False)\n",
      " |      The method identifies and returns the intersection of two corpora.\n",
      " |      \n",
      " |      Args:\n",
      " |          other (:obj:`Corpus`): An instance of this Class object.\n",
      " |          as_corpus (bool): When True it returns a new Corpus (default False).\n",
      " |          stats (bool): When True and as_corpus is false returns the frequency \n",
      " |              count of the intersections.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list` of :obj:`str`): If as_corpus is False and stats is False \n",
      " |              it returns the list of joint terms.\n",
      " |          (:obj:`list` of :obj:`tuple` of :obj:`str` and :obj:`int`): Returns the frequency dist\n",
      " |              for the joint terms, if as_corpus is False and stats is True. \n",
      " |          (:obj:`Corpus`): In all other cases it returns a nrew Corpus class for the intersection.\n",
      " |              Frequencies are the minimum of the two occurances.\n",
      " |  \n",
      " |  label(self, marker, labels=None)\n",
      " |      The function labels yet not labeled terms according to the user defined scheme.\n",
      " |      \n",
      " |      Args:\n",
      " |          marker (x :obj:`str` -> y: :obj:`str`): A marker function\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`dict`): A dictionary of {term:label of term}.\n",
      " |  \n",
      " |  list_terms(self)\n",
      " |      It returns the list terms in the corpus\n",
      " |      \n",
      " |      Note:\n",
      " |          Implementation needs refactoring.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list`): An alphabetically sorted list.\n",
      " |  \n",
      " |  plot(self, top, cumulative=False)\n",
      " |      Plotting.\n",
      " |      \n",
      " |      Note:\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True\n",
      " |  \n",
      " |  set_specific_set(self, terms)\n",
      " |      The function sets the set of corpus specific terms.\n",
      " |      \n",
      " |      Args:\n",
      " |          terms (:obj:`set`): The list of corpus specific terms\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  set_stemmer(self, stemmer)\n",
      " |      The appointing a new stemmer function to the corpus.\n",
      " |      \n",
      " |      Args:\n",
      " |          stemmer (x :obj:`str` -> y: :obj:`str`): A stemmer function (default None)\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True\n",
      " |  \n",
      " |  tabulate(self, top)\n",
      " |      Tabulating.\n",
      " |      \n",
      " |      Note:\n",
      " |          Works better when used to see few top terms.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True\n",
      " |  \n",
      " |  to_pandas(self)\n",
      " |      The function exports its data into pandas dataframe.\n",
      " |      \n",
      " |      Note:\n",
      " |          ToDo: The function needs parameterization, generalization and error checks.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (:obj:`pandas.DataFrame`) The tabulated data\n",
      " |  \n",
      " |  union(self, other, as_corpus=False, stats=False)\n",
      " |      The method identifies and returns the union of two corpora.\n",
      " |      \n",
      " |      Args:\n",
      " |          other (:obj:`Corpus`): An instance of this Class object.\n",
      " |          as_corpus (bool): When True it returns a new Corpus (default False).\n",
      " |          stats (bool): When True and as_corpus is false returns the frequency \n",
      " |              count of the union.\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`list` of :obj:`str`): If as_corpus is False and stats is False \n",
      " |              it returns the list of union of terms in both cases.\n",
      " |          (:obj:`list` of :obj:`tuple` of :obj:`str` and :obj:`int`): Returns the frequency dist\n",
      " |              for the union terms, ff as_corpus is False and stats is True. \n",
      " |          (:obj:`Corpus`): In all other cases it returns a nrew Corpus class for the intersection.\n",
      " |              Frequencies are the minimum of the two occurances.\n",
      " |      \n",
      " |      Examples:\n",
      " |          >>> Corpus(FreqDist('abbbc')).union(Corpus(FreqDist('bccd')), stats = True)\n",
      " |          [('a', 1), ('b', 3), ('c', 2), ('d', 1)]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __slotnames__ = []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words = 306\n",
      "Number of words = 1948\n",
      "\n",
      "Most frequents ::>>\n",
      "[('power', 245),\n",
      " ('people', 40),\n",
      " ('tactics', 33),\n",
      " ('powerful', 31),\n",
      " ('social', 27),\n",
      " ('control', 23),\n",
      " ('group', 23),\n",
      " ('influence', 22),\n",
      " ('use', 20),\n",
      " ('coercive', 20),\n",
      " ('person', 19),\n",
      " ('theory', 18),\n",
      " ('others', 18),\n",
      " ('will', 15),\n",
      " ('actions', 14),\n",
      " ('given', 14),\n",
      " ('relationship', 14),\n",
      " ('individuals', 13),\n",
      " ('tend', 13),\n",
      " ('less', 13),\n",
      " ('change', 12),\n",
      " ('relationships', 12),\n",
      " ('rewards', 12),\n",
      " ('authority', 11),\n",
      " ('reward', 11),\n",
      " ('negative', 10),\n",
      " ('personal', 10),\n",
      " ('leads', 10),\n",
      " ('different', 10),\n",
      " ('political', 9),\n",
      " ('much', 9),\n",
      " ('referent', 9),\n",
      " ('rational', 9),\n",
      " ('choice', 9),\n",
      " ('counterpower', 9),\n",
      " ('positive', 9),\n",
      " ('likely', 9),\n",
      " ('members', 9),\n",
      " ('ability', 8),\n",
      " ('used', 8),\n",
      " ('soft', 8),\n",
      " ('unmarked', 8)]\n",
      "\n",
      "Least frequents ::>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('love', 3),\n",
       " ('attention', 3),\n",
       " ('particularly', 3),\n",
       " ('include', 3),\n",
       " ('collaboration', 3),\n",
       " ('harsh', 3),\n",
       " ('nonrational', 3),\n",
       " ('parties', 3),\n",
       " ('carry', 3),\n",
       " ('stage', 3)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SC = Corpus(TOKENS_TF)\n",
    "print('Number of unique words = {}'.format(SC.get_count_uniques()))\n",
    "print('Number of words = {}'.format(SC.get_size()))\n",
    "print('\\nMost frequents ::>>')\n",
    "pp.pprint(SC.get_top_frequents(top = 42))\n",
    "print('\\nLeast frequents ::>>')\n",
    "SC.get_least_frequents(bottom = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAE7CAYAAADHHRb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXd4lFX2+D8noYaqUoyUUAQRkGKigODauyt2RHFFXXG/67qWdUVXXfuurn3xp+sqVlAUK6CIiIKCAiZIR5DeQZAeSsr5/XHvwJANmXdmMpmEnM/zvM/M3HnPvWeS933Pvfece66oKoZhGIZRlJRkK2AYhmGUT8xAGIZhGMViBsIwDMMoFjMQhmEYRrGYgTAMwzCKxQyEYRiGUSxmIAzDMIxiMQNhGIZhFEtCDYSI1BeR90XkJxGZJyI9ROQBEVklItP9cW7Y+XeLyEIRmS8iZyVSN8MwDKNkJJErqUXkDeBbVX1FRKoBacCtwHZVfbLIue2Bd4DjgSOAL4G2qlpwoPobNGigLVq0iEm3nTt3UrNmzZhkTb586GDyJm/yscnn5ORsUNWGEU9U1YQcQD1gCd4IhZU/ANxRzPl3A3eHfR4D9CipjczMTI2V7OzsmGVNvnzoYPImb/KxAWRrgOd4IqeYWgK/AK+JyI8i8oqI1PLf/UlEZorIqyJyiC9rAqwIk1/pywzDMIwkkLApJhHJAiYDPVV1iog8B2wFngc2AAo8DKSr6nUi8jwwWVWHePnBwGhVfb9IvQOAAQDp6emZI0eOjEm/3Nxc0tLSYvtxJl8udDB5kzf52OSzsrJyVDUr4olBhhmxHMDhwNKwzycCnxY5pwUwW22KqcLJlwcdTN7kTT42SPYUk6quBVaIyFG+6DRgroikh512ETDbvx8BXCEi1UWkJdAGmJoo/QzDMIySqZLg+m8GhvoIpsXAtcC/RaQLboppKXAjgKrOEZH3gLlAPnCTlhDBZBiGYSSWhBoIVZ0OFJ3nurqE8x8FHk2kToZhGEYwbCW1YRhGBUNV2ZlfmPB2Ej3FZBiGYZQSW3LzGJ6zgrenLKdlnUJ6dUtse2YgDMMwyjkzVmxmyORljJy5ml15buSwa1cqBYVKaookrF0zEIZhGOWQnXsKGDljNUOmLGPmyi17y09s04B+3TM4JHdlQo0DmIEwDMMoVyz6ZTtDJi/jg5yVbN2VD0C9mlW5LLMpV3XPoGUDl5AiJ2dVwnUxA2EYhpFk8goKGTt3HUMmL+O7RRv3lndpVp9+3TM4v1M6NaqmlrleZiAMwzCSxJotO3ln6gqGTV3O+m27AahZNZXeXY6gX/cMOjapl1T9zEAYhmGUIYWFyqRFGxg0aRM5H3xNQaHLh9e6YS36dc/g4mObUq9m1SRr6TADYRiGUQZs2rGH93NWMnTKMpZuzAWgSopw3jHp9OueQfdWhyKSWKdztJiBMAzDSBCqyvQVmxkyeTmjZq5mt1/cll6vBic1rcLtvbvRqG6NJGt5YMxAGIZhlDK5e/IZMd2FqM5etXVv+W/aNqRft+ac2q4RM6b/WK6NA5iBMAzDKDUWrt/GkMnL+WDaSrb5ENX6aVW5PKsZVx7fnBYNakWooXxhBsIwDCMO9uQX8sXctQyZvIzJi3/dW961eX2u7p7BucckJ0S1NDADYRiGEQMbcgt46ov5DPthBb+Ehahe2LUJ/bo3p8MRyQ1RLQ3MQBiGYQSksFD5duEGhkxexri5v1DILwC0aVSbft0zuOjYJtStUT5CVEsDMxCGYRgR2LRjD8NzVjB0ynKWhUJUBc49Jp2ru2dwfMvyF6JaGiTUQIhIfeAVoCNuB7nrgPnAu7j9qJcCl6vqJnF/3eeAc4FcoL+qTkukfoZhGAdCVflxxWaGfL+MUbPWsMeHqDapX5MruzWnXbVfOa3nsUnWMrEkegTxHPC5ql7qtx1NA/4GjFPVx0TkLuAuYCBwDm4f6jZAN+BF/2oYhlFm7NidzyfTVzNk8jLmrnEhqiJw8lEN6dctg1PaNSI1RcjJyUmypoknYQZCROoBvwH6A6jqHmCPiPQGTvanvQGMxxmI3sCbqqrAZBGpLyLpqromUToahmGE+HndNoZMXsaH01axbbcLUT20VjUuy2rKVcdn0PywtCRrWPYkcgTREvgFeE1EOgM5wC1A47CH/lqgsX/fBFgRJr/Sl5mBMAwjIezJL+TzOS5EdeqSfSGqmRmHcHX3DM455nCqV6mYIaqlgbgOewIqFskCJgM9VXWKiDwHbAVuVtX6YedtUtVDRGQU8JiqTvTl44CBqppdpN4BwACA9PT0zJEjR8akX25uLmlpsfcIKrt8edDB5E0+Vvn1OwoYPX8LE1bms2W38y3UqCL8pnkNzmqdRov6kSORKvLvz8rKylHVrIgnqmpCDuBwYGnY5xOBT3FO6nRflg7M9+9fAvqGnb/3vAMdmZmZGivZ2dkxy5p8+dDB5E0+GgoLCzV76Ub9w1vZ2vKuUZox0B1nPj1B3/xuiW7duSeh7ZcneSBbAzzHEzbFpKprRWSFiBylqvOB04C5/rgGeMy/fuJFRgB/EpFhOOf0FjX/g2EYcZJXUMjo2WsZPHEJM1ZsBlwW1ROaVueW87qSlXHIQRmiWhokOorpZmCoj2BaDFwLpADvicj1wDLgcn/uZ7gQ14W4MNdrE6ybYRgHMVt25jFs6nLe+G4pq7fsAlxepKu6Ned3PVqw8uc5ZLY4NMlalm8SaiBUdTpQ3DzXacWcq8BNidTHMIyDn2Ubd/DapKW8l72C3D0FALRqWIvrerbkkmObUrOaczqvTKaSFQRbSW0YRoVHVflh6SZe+XYxY+etIxR70/PIw7i+V0tObtuIlBSbRooWMxCGYVRY8goK+XTmGgZPXMKsVVsAqJaawgVdjuC6ni1pf0TdJGtYsTEDYRhGhWNz7h4+/Gk7N435mrVbnX/h0FrV6NetOf16ZNCoTvneiKeiYAbCMIwKw+JftvPapKW8n7OSnXnOv9CmUW2u79WSC7s2qbD7LpRXzEAYhlGuUVW+X7yRVycuYdxP6/f6Fzo3rsbt53XhN20aWJhqgjADYRhGuWRPfiEjZ6xm8MQle5PmVauSwsVdm3Bdr5ZsW7mAzLYNk6zlwY0ZCMMwyhW/7tjD21OW8cb3y/bu1NagdjWu7t6Cq7o3p0Ht6gDkWJxqwjEDYRhGuWDh+u28OmkJH+SsZLffe6Hd4XW4rldLLuh8hPkXkoAZCMMwkoaqMmnhRl6ZuJjx83/ZW37KUQ25vlcreh55mPkXkogZCMMwypxdeQV8tSSXe779lp/WbgOgepUULslsynU9W3Jko9pJ1tAAMxCGYZQhG7bvZujk5bw1eSkbtu8BoGGd6lzTI4Mru2VwaK1qSdbQCMcMhGEYCWfBum0M/nYJH01ftXdv55b1q/CnMzpwfuf0Sr0pT3nGDIRhGAlBVfnm5w288u1ivv15A+D2dj796EZc36sVVTctISuzaZK1NErCDIRhGKXKrrwCPv5xFYMnLuHn9dsBqFk1lUszm3Jtzxa0auj8Czk5S5OopREEMxCGYZQK67ftYsj3yxgyZTm/7nD+hcPr1uCaE1rQ9/hm1E8z/0JFwwyEYRhxMW/NVgZPXMKI6avZU+D8C8c0qcfvT2zJucekUzU1JckaGrFiBsIwjKgpLFRy1uzi6VcmM2nhRsD5F87q0Jjre7XiuBa2jefBQEINhIgsBbYBBUC+qmaJyAPADUBoVczfVPUzf/7dwPX+/D+r6phE6mcYRnTsyS/k4x9X8dI3i1j0yw4AalVL5bKsZlzbswUZh9VKsoZGaVIWI4hTVHVDkbJnVPXJ8AIRaQ9cAXQAjgC+FJG2qlpQBjoahlECuXvyGTZ1BS9/u5g1fn/nBjVTGHBKW/oc15x6NasmWUMjEZSnKabewDBV3Q0sEZGFwPHA98lVyzAqL1ty83jz+6W89t3SvY7nto1r88eTjyQ9fw3djmudXAWNhCIaSq6eiMpFlgCbAAVeUtX/+imm/sBWIBv4i6puEpHngcmqOsTLDgZGq+r7ReocAAwASE9Pzxw5cmRMuuXm5pKWlhaTrMmXDx1MPnHym3YVMGpBLmMW5bIz3z0j2hxalUuOrkVmenVSRMq1/iZfMllZWTmqmhXxRFVN2AE08a+NgBnAb4DGQCqQAjwKvOrPeR7oFyY7GLi0pPozMzM1VrKzs2OWNfnyoYPJl7788o079J6PZmqbez7TjIGjNGPgKL3q5ck6aeEvWlhYmPD2Tb5s5IFsDfAMT+gUk6qu8q/rReQj4HhV/Sb0vYi8DIzyH1cBzcLEm/oywzASzIJ123hx/CJGzFhNQaEbMZzVoTF/PPlIOjern2TtjGSRMAMhIrWAFFXd5t+fCTwkIumqusafdhEw278fAbwtIk/jnNRtgKmJ0s8wDPhx+SZeGL+IsXPXAZCaIlx8bBP+76TWtGlcJ8naGckmkSOIxsBHPha6CvC2qn4uIm+JSBecX2IpcCOAqs4RkfeAuUA+cJNaBJNhlDqqyneLNvLYhF+ZtX4t4FJt9zmuGTec2Ipmh8bnmzIOHhJmIFR1MdC5mPKrS5B5FOeXMAwjASxYt42HR83dmzyvdvUqXN0jg+t6tqRhnepJ1s4ob5SnMFfDMBLExu27eebLBbw9ZTmFCnVrVOG8I2tw1yUn2BoG44CYgTCMg5g9+YW8+f1Snhv3M9t25ZOaIvyue3NuPb0tS36aZcbBKBEzEIZxEKKqjJ27jn98No+lG3MBOLFNA+47vz1tvfN5STIVNCoEZiAM4yBj3pqtPDxqLt8tckn0Wjesxb3ntefkoxpaAj0jKiIaCB+iulNVC0WkLdAOt8I5L+HaGYYRmA3bd/PUFwt49wfnZ6hXsyq3nd6Gq7pnWMptIyaCjCC+AU4UkUOAL4AfgD7AVYlUzDCMYOzOL+D1SUsZ9NVCtu92fob+PTK49fQ2tkmPERdBDISoaq6IXA+8oKr/EpHpiVbMMIySUVU+n72Gf3z2E8t/dX6GU45qyD3nHc2RjWyRmxE/gQyEiPTAjRiu92WpiVPJMIxIzF61hfsn/MqcX9wK6DaNanPv+e05qW3DJGtmHEwEMRC3AHcDH/nVzq2ArxOrlmEYxbF+2y6eHDOf4TkrUYVD0qpy+xlt6Xt8c6qYn8EoZYIYiMaqekHog6ouFpFvE6iTYRhF2JVXwOCJS3jh64Xs2FNAlRTh7CNr8mjfXtRLs7UMRmIIYiDuBoYHKDMMo5RRVT6btZZ/jp7Hyk07ATj96Mb87dx2bFo+34yDkVAOaCBE5BzgXKCJiPw77Ku6uGR6hmEkkJkrN/PwqLn8sHQTAEc1rsN957enV5sGAOQsT6Z2RmWgpBHEatyObxcAOWHl24DbEqmUYVRm1m3dxb8+n88H01YCcFitatx+Zlv6ZDUzP4NRphzQQKjqDGCGiLxti+IMI/Hsyivg5W8W88L4RezMK6BqqnBdz5bcdOqR1K1hU0lG2RPEB3G830c6w58vgKpqq0QqZhiVBVVlxIzVPD76J1Zv2QW43dzuPudoWjSolWTtjMpMEAMxGDellAPYBj6GUYr8uHwTD4+ay7TlmwFon16X+85vT4/WhyVZM8MIZiC2qOroWCoXkaU4n0UBkK+qWSJyKPAu0AK3o9zlqrpJXBax53CO8Vygv6pOi6VdwyjvrNmyk+embOab5d8B0KB2df56VlsuzWxGaool1DPKB0EMxNci8gTwIbA7VBjFw/sUVd0Q9vkuYJyqPiYid/nPA4FzcPtQtwG6AS/6V8M4aNid7/wMz3+9kF15hVSrksL1vVryx5NbU8f8DEY5I4iBCD2ks8LKFDg1xjZ7Ayf7928A43EGojfwpqoqMFlE6otIuqquibEdwyhXTFjwCw+MmMOSDTsA6NG0Ov+68gTbA9oot0Q0EKp6Shz1K/CFiCjwkqr+F7cyO/TQXws09u+bACvCZFf6MjMQRoVm1eadPDxyLp/PWQvAkY1q81DvDlTfvMyMg1GuEddhL+EEkb8XV66qD0WsXKSJqq4SkUbAWOBmYISq1g87Z5OqHiIio4DHVHWiLx8HDFTV7CJ1DgAGAKSnp2eOHDkykhrFkpubS1pa7DdnZZcvDzqUd/m8AmXkgh0Mn7edPQVQI1W4vENtzm2TRtUUKff6m/zBK5+VlZWjqlkRT1TVEg/gL2HHPcD3wKuR5Iqp5wHgDmA+kO7L0oH5/v1LQN+w8/eed6AjMzNTYyU7OztmWZMvHzqUZ/kJ89fryU98rRkDR2nGwFF609AcXb05t8zaN3mTLwkgWwM8t4NMMT0V/llEngTGRJLzO9GlqOo2//5M4CFgBHAN8Jh//cSLjAD+JCLDcH6PLWr+B6OCsWrzTh4ZNZfRs910UuuGtXiod0d6HtkgyZoZRvTEsid1GtA0wHmNgY/8HrhVgLdV9XMR+QF4z29AtAy43J//GS7EdSEuzPXaGHQzjKSwJ7+QVyYuZtC4hezMKyCtWip/Pq0N1/VsSbUqlh7DqJgE2ZN6Fs7ZDG6joIa4kUCJqOpioHMx5RuB04opV+CmSPUaRnnj259/4f4Rc1j8i4tOOu+YdO4572iOqF8zyZoZRnwEGUGcH/Y+H1inqpbN1aj0bMwt4Kah0/h0lpsJbdWgFg/27sCJbWxXN+PgIIgPYpmIdAZO9EXfADMTqpVhlGP25Bfy6qQlPPvFBnYVKDWrpnLzaUdyfa+WVK9iu/EaBw9BpphuAW7AraQGGCoi/1XVQQnVzDDKITnLNvG3D2cxf902AM495nDuOa89TWw6yTgICTLFdD3QTVV3AIjI47hQVzMQRqVh2648nhgzn7cmL0MVMg5L4+r21fn9eZnJVs0wEkYQAyHsn8W1wJcZRqVgzJy13P/JHNZu3UWVFGHASa3482ltmDNzerJVM4yEEsRAvAZMEZGP/OcLcSnADeOgZu2WXdw/YjZj5qwDoHOz+jx28TEcnV43yZoZRtkQxEn9tIiMB3r5omtV9ceEamUYSaSwUBk6ZRmPfz6f7bvzqVUtlTvPbke/7hmWituoVBzQQIjIcUADVR2tLrX3NF9+roikqGrOgWQNo6Iyf+027v5w5t4NfE4/ujEP9e5gaxqMSklJI4jHKX418xzctFOs6b4No9yxK6+A579ayH8mLCK/UGlUpzoP9e7AWR0Ox2cDMIxKR0kGoo6qLita6NdFWGIZ46Dhu0UbuOej2Xv3aejXvTl3nt2OuraBj1HJKclAHFLCd5bE3qjwbNtdyF+Hz2B4zkoA2jSqzT8vPoasFocmWTPDKB+UZCC+FJFHgXt9niT8vtEPAl+VhXKGkQhUlREzVnPfmA1s3V1ItdQUbj71SG48qbUl1jOMMEoyEH8BXgEWikgo4LszkA38PtGKGUYiWPFrLvd8PJtvFvwCQLeWh/KPi4+hdcPaSdbMMMofBzQQfuV0XxFpBXTwxXN8llbDqFDkF7j8SU+PXcCuvELq1qjCVR3TuPOS7uaENowDEGQdxGLAjIJRYZm5cjN3fTCLuWu2AnBB5yO47/z2LF8w24yDYZRALBsGGUaFYMfufJ4eu4DXJi2hUKFJ/Zo8clFHTjmqEQDLk6yfYZR3Em4gRCQV57dYparni8jrwEnAFn9Kf1Wd7h3gz+F2lcv15dMSrZ9xcPL1T+u59+PZrNq8kxSBG05syW1ntCWtmvWJDCMoge4WEekFtFHV10SkIVBbVZcEbOMWYB4QnsDmr6r6fpHzzgHa+KMb8KJ/NYzArN+2i4dGzmXUTLeJT8cmdfnnRZ04pmm9JGtmGBWPIPtB3A9kAUfhVlBXBYYAPQPINgXOAx4Fbo9wem/gTR9SO1lE6otIuqquidSOYRQWKu9lr+Afn81j6658alZN5S9ntqX/CS2okmqhq4YRC0FGEBcBXfG5mFR1tYjUCVj/s8CdQNHzHxWRvwPjgLtUdTfQBFgRds5KX2YGwiiRheu387ePZjF1ya8AnNS2IY9c2JFmh9p6TsOIB/Fr4A58gshUVT1eRKap6rEiUgv4XlU7RZA7HzhXVf8oIicDd3gfRDqwFqgG/BdYpKoPicgo4DFVnejlxwEDVTW7SL0DgAEA6enpmSNHjozld5Obm0taWuwPkMouXx502LJtB2NWKB/M205+IdSrnsJ1XerQs1mNQNFJydbf5E0+WfJZWVk5qpoV8URVLfEA7gBewoW63oDbTe7mAHL/xI0CluIMQi4wpMg5JwOj/PuXgL5h380H0ktqIzMzU2MlOzs7ZlmTT74OU5ds1J6PjNaMgaM0Y+AovXP4DN20Y3eZtW/yJl+R5YFsjfAMV9VA6yCeFJEzgK04P8TfVXVsALm7gbsBwkYQ/UJ+BR+1dCEw24uMAP4kIsNwzuktav4Howi78gp4/POfeG3SUgBaNajFoxcdQ4/WhyVXMcM4CAnipL4deDeIUQjIUB8JJcB04A++/DNciOtC3GijuFTjRiVm9qot3PrudBau306VFKH3UWk8euWJ1KiammzVDOOgJIiTug7whYj8CrwLDFfVddE0oqrjgfH+fbH7SPhhz03R1GtUDgoKlf9MWMQzYxeQX6i0aliLZ/t0IW/dIjMOhpFAgkwxPQg8KCKdgD7ABBFZqaqnJ1w7o9KzfGMut703nZxlmwDof0ILBp7djprVUsmJqptiGEa0RLOsdD3O2bwRaJQYdQzDoerWNTw0ci479hTQqE51nrisMye1bZhs1Qyj0hDEB/FH4HKgITAcuEFV5yZaMaPysmH7bu7+cBZj57ohwnnHpPPIhR05pFa1JGtmGJWLICOIZsCtqjo94pmGESdfzl3HXR/OZMP2PdSpUYWHe3ekd5cjLOuqYSSBAxoIEamrqluBJ/zn/fZhVNVfE6ybUYnYsTufRz6dyztT3WL6Hq0O48nLO9Okfs0ka2YYlZeSRhBvA+cDOYDiwlJDKNAqgXoZlYicZb9y27szWP5rLtVSU7jz7KO4rmdLUlJs1GAYyaSkHeXO968ty04dozKRX6g8OWY+L4xfSKFCu8Pr8OwVXWh3eN3IwoZhJJwgTupxqnpapDLDiIaF67fxt682smjTOkTgxpNacfsZbalexdY1GEZ5oSQfRA0gDWggIoewb4qpLi7LqmFEjaoyZMpyHhk1l935hTSpX5OnL+9Mt1aWKsMwyhsljSBuBG4FjsD5IUIGYivwfIL1Mg5CNufu4c73Z/KFD189OaMGg649kTo1qiZZM8MwiqMkH8RzwHMicrOqDipDnYyDkCmLN3Lru9NZs2UXdapX4R8XH8MR+WvMOBhGOSZIqo1BItIRaA/UCCt/M5GKGQcH+QWFDPpqIYO++plCha7N6/PvK7rS7NA0cnIsWa9hlGeCbjl6Ms5AfIbbO3oiYAbCKJFVm3dy27DpTF36KyJw0ymtufX0tlS1LUANo0IQZCX1pUBn4EdVvVZEGuP2pDaMA/L57DUM/GAWW3bm0ahOdZ7p04WeRzZItlqGYURBEAOxU1ULRSRfROrikvY1S7BeRgVlV14BD4+ay9ApywE4tV0jnri0E4fVrp5kzQzDiJYgBiJbROoDL+Oimbbjth01jP2Yv3YbN78zjQXrtlMtNYW7z21H/xNaWB4lw6igBHFS/9G//Y+IfA7UVdWZiVXLqEioKkOnLOdhv7ahVcNaDOrblQ5H1Eu2aoZhxEFJC+WOLek7VZ0WpAERSQWygVWqer6ItASGAYfhRiRXq+oeEamOc3xn4vac6KOqSwP/EiMpbM7dw10fzOLzOWsBuDyrKQ9c0IG0atFsNWIYRnmkpLv4qRK+U6DYrUOL4RZgHm4FNsDjwDOqOkxE/gNcD7zoXzep6pEicoU/r0/ANowkMPeXPdz8xbes9msbHr34GC7ofESy1TIMo5QoaaHcKfFWLiJNgfOAR4HbxU1Gnwpc6U95A3gAZyB6+/cA7wPPi4j4vaqNckRBoTLoq5/59/hfKWT/tQ2GYRw8SKTnr4j8rrjyIAvlROR94J9AHeAOoD8wWVWP9N83A0arakcRmQ2craor/XeLgG6quqFInQOAAQDp6emZI0eOjKRGseTm5pKWFvsDrbLKb8gt4Nkpm5m3IQ8BLmpXiz4dalMlhtTcFfVvYPImX9Hls7KyclQ1K+KJqlriAQwKO14GFgPvB5A7H3jBvz8ZGAU0ABaGndMMmO3fzwaahn23CGhQUhuZmZkaK9nZ2THLVlb50bPWaKcHxmjGwFF63CNj9dVPJ5W5DiZv8iYfvzyQrRGe4aoaKIrp5vDPPuR1WETLAz2BC0TkXFyKjrrAc0B9EamiqvlAU2CVP3+VNxgrRaQKUA/nrDaSzK68Ah75dC5DJru1Dacc1ZAnL+vM0vmzk6yZYRiJJJacBzuAiJsIqerdqtpUVVsAVwBfqepVwNe41dkA1wCf+Pcj/Gf89195S2ckkQXrttH7+UkMmbycaqkp/P389rza/zhb+GYYlYAguZhG4qKWwBmU9sB7cbQ5EBgmIo8APwKDfflg4C0RWQj8ijMqRpJQVd6ZuoKHRs1hV14hrRrU4t99u9Kxia1tMIzKQpBg9SfD3ucDy9Q7koOiquOB8f79YuD4Ys7ZBVwWTb1GYtiSm8ddH85k9Gy3tuGyTLe2oVZ1W9tgGJWJID6ICQA+D1MV//5QVf01wboZSeCHpb9yyzs/snrLLmpXr8KjF3WkdxfbQNAwKiNBppgGAA8Bu4BC3M5yCrRKrGpGWVJQqPy/rxfy7JcLKFTo3Kw+g67oSvPDbG2DYVRWgswZ/BXoqEXWIxgHD2u27OTWYdOZssQNCv9wUmv+cqbt22AYlZ0gBmIRkJtoRYzk8MWctdz5wUw25+bRsE51nr68Mye2aZhstQzDKAcEMRB3A9+JyBRgd6hQVf+cMK2MhLOnQLn/k9m88f0yAE72axsaWPiqYRieIAbiJeArYBbOB2FUcBb/sp2B4zayfEs+VVOFu845mmtPaEFKDOkyDMM4eAliIKqq6u0J18QoEyYv3siNb+WwZWc+LRu4fRtsbYNhGMURxECM9pFMI9l/isnCXCsYH+Ss5K4PZ5JXoGSlV+f1P/Sitq1tMAzjAAR5OvT1r3dzr2PmAAAgAElEQVSHlVmYawWisFB55ssFDPpqIQDX92rJWYfnmnEwDKNEgiyUi5h3ySi/7Mor4I7hMxg1cw2pKcIDF3Tg6u4Z5OTkJFs1wzDKOUEWysW8H4SRXDZu380Nb2YzbflmalevwvNXduXkoxolWy3DMCoIQeYYjgt7XwM4DZiG2z/aKKcsXL+Na1//gRW/7qRJ/ZoM7p9Fu8PrRhY0DMPwJHI/CCNJTFq4gT8MyWHbrnw6Na3HK9dk0ahOjWSrZRhGBSMWL2Wg/SCM5PDuD8u556PZ5BcqZ3c4nGf6dKFmtdRkq2UYRgUkGftBGAmgsFD515j5/GfCIgBuPKkVA89qZ4vfDMOImTLZD8JILDv3FHD7e9MZPXstqSnCIxd2pO/xzZOtlmEYFZwDGggRORJoHNoPIqy8p4hUV9VFJVUsIjWAb4Dqvp33VfV+EXkdOAnY4k/tr6rTRURwe1afi0sO2F9Vp8X4uyoN67ft4oY3spmxcgt1alThxasy6dWmQbLVMgzjIKCkEcSz7L84LsRW/91vI9S9GzhVVbeLSFVgooiM9t/9VVXfL3L+OUAbf3QDXvSvxgGYv3Yb173+A6s276TpITV5rf9xtGlcJ9lqGYZxkFCSgWisqrOKFqrqLBFpEaliVVVgu/9Y1R96YAl6A296uckiUl9E0lV1TaS2KiM/rt3NsyO+Y/vufLo2r8/Lv8uyTKyGYZQqJe0IU7+E72oGqVxEUkVkOrAeGKuqU/xXj4rITBF5RkRCT7UmwIow8ZW+zCjC8OwV/GPiJrbvzue8Tum8c0N3Mw6GYZQ64jrsxXwh8g7wlaq+XKT898AZqtoncCNu7cRHwM3ARmAtUA34L7BIVR8SkVHAY6o60cuMAwaqanaRugYAAwDS09MzR44cGVSN/cjNzSUtLfbtNJMlP3ZxLv/J2QrAxe1q0bdjbVIk+kilePUvjTpM3uRNPjnyWVlZOaqaFfFEVS32ABoD3wHjgaf8MQH4Hjj8QHIl1Pd34I4iZScDo/z7l4C+Yd/NB9JLqjMzM1NjJTs7O2bZZMm/+d0SzRg4SjMGjtJ7h04o8/ZLuw6TN3mTT448kK0BntsHnGJS1XWqegLwILDUHw+qag9VXRvJ8IhIQz9yQERqAmcAP4lIui8T4EJgthcZAfxOHN2BLWr+h728NmkJ930yB4D7zm/PhUfVSrJGhmEc7ARJtfE18HUMdacDb4hIKs7X8Z6qjhKRr0SkISDAdOAP/vzPcCGuC3FhrtfG0OZBycvfLObRz+YB8FDvDvyuRwtycmw7DsMwEkvCNgRQ1ZlA12LKTz3A+QrclCh9KiovjF/Ivz6fD8A/LjqGK7vZAjjDMMoG2zGmHDNo3M88NXYBIvD4xZ24/LhmyVbJMIxKhBmIcoiq8uyXP/PcuJ9JEXji0s5cktk02WoZhlHJMANRzlBVnvxiPv/v60WkCDzTpwu9u9hyEMMwyh4zEOUIVeWx0T/x0jeLSU0R/n1FV87rlJ5stQzDqKSYgSgnqCoPj5rHq5OWUCVFeP7Krpzd0YyDYRjJwwxEOUBVeWDEHN74fhlVU4UXrsrkjPaNk62WYRiVHDMQSaawULn3k9m8PWU51aqk8FK/TE5p1yjZahmGYZiBSCaFhcrdH87i3ewVVK+Swsu/y+I3bRsmWy3DMAzADETSKFDljvdn8OG0VdSomsLga46j55G20Y9hGOUHMxBJIL+gkEFTt/Dt8l2kVUvl1f7H0b3VYclWyzAMYz/MQJQxBYXKHcNn8O3yXdSqlsrr1x3PcS0OTbZahmEY/4MZiDJEVbnno1l8PH01NaoIb17fjcyMQ5KtlmEYRrGYgSgjVJUHR85l2A8rqFE1hb/1rG/GwTCMco0ZiDLiiTHzef27pVRLTeG/V2dRa9vyZKtkGIZRIiXtSW2UEs9/9TMvjF9Eql8hbaGshmFUBMxAJJhXvl3Mk18sIEXg2T5dOLPD4clWyTAMIxAJMxAiUkNEporIDBGZIyIP+vKWIjJFRBaKyLsiUs2XV/efF/rvWyRKt7Ji6JRlPPKp2wnu8Us68dvORyRZI8MwjOAkcgSxGzhVVTsDXYCz/V7TjwPPqOqRwCbgen/+9cAmX/6MP6/C8uG0ldz7sdtu++HeHbgsyzb7MQyjYpEwA6GO7f5jVX8ocCrwvi9/A7jQv+/tP+O/P01EJFH6JZJPZ67hjuEzUIW7z2nH1T1aJFslwzCMqEmoD0JEUkVkOrAeGAssAjarar4/ZSUQ2g2nCbACwH+/Bahwy4vHzVvHLcN+pFDhltPacONJrZOtkmEYRkyIqia+EZH6wEfAfcDrfhoJEWkGjFbVjiIyGzhbVVf67xYB3VR1Q5G6BgADANLT0zNHjhwZk065ubmkpaXF+pOKlZ+xbjf/nLiJvEK4oG0av+tUhwMNghLRflnKlwcdTN7kTT42+aysrBxVzYp4oqqWyQH8HfgrsAGo4st6AGP8+zFAD/++ij9PSqozMzNTYyU7Oztm2eLkpy7ZqO3uHa0ZA0fpvR/N0sLCwjJtv6zly4MOJm/yJh8bQLYGeG4nMoqpoR85ICI1gTOAecDXwKX+tGuAT/z7Ef4z/vuv/A8p98xYsZlrX/uBnXkFXJrZlAcv6HDAkYNhGEZFIZErqdOBN0QkFefreE9VR4nIXGCYiDwC/AgM9ucPBt4SkYXAr8AVCdSt1Ji3Ziu/e3Uq23fnc36ndB6/pBMpKWYcDMOo+CTMQKjqTKBrMeWLgeOLKd8FXJYofRLBwvXbuXrwFLbszOP0oxvzTJ8upJpxMAzjIMFWUsfIuh359HtlChu27+HENg14/squVE21P6dhGAcPlqwvBtZs2ckD4zexPreA41scyn+vzqJG1dRkq2UYhlGqWJc3SnblFTDgzRzW5xbQuVl9BvfPomY1Mw6GYRx8mIGIAlXlvo9nM2vVFhrVSuX1/sdRp0bVZKtlGIaREMxARMHQKcsZnrOSGlVTGHhCfQ6pVS3ZKhmGYSQMMxAByVm2iQdHzgHgsYs70aK+jRwMwzi4MQMRgPXbdvHHoTnkFSjX9mzBhV2bRBYyDMOo4JiBiEBeQSE3DZ3Guq27Ob7Fofzt3KOTrZJhGEaZYAYiAo9+Oo8flm6icd3qPH+VrXUwDKPyYE+7Evjox5W8/t1SqqYKL/bLpFGdGslWyTAMo8wwA3EA5qzewt0fzgLggQs6cGzzQ5KskWEYRtliBqIYNufu4ca3ctiVV8jlWU258vjmyVbJMAyjzDEDUYSCQuXPw6azctNOOjWtx0O9O1rqbsMwKiVmIIrw9Nj5fLPgFw6tVY0X+2VajiXDMCotZiDC+Hz2Wv7f14tIEXi+b1ea1K+ZbJUMwzCShhkIz8L127lj+AwA7jqnHScc2SDJGhmGYSQXMxDA9t353PhWNtt353Nep3RuOLFVslUyDMNIOonck7qZiHwtInNFZI6I3OLLHxCRVSIy3R/nhsncLSILRWS+iJyVKN3CUVXueG8Gi37ZQdvGtfnXJZ3MKW0YhkFiNwzKB/6iqtNEpA6QIyJj/XfPqOqT4SeLSHvcPtQdgCOAL0WkraoWJFBHXpywiM/nrKVOjSq8dHUWtarbHkqGYRiQwBGEqq5R1Wn+/TZgHlBSlrvewDBV3a2qS4CFFLN3dWnyzYJfeHLMfACe7dOFlg1qJbI5wzCMCoWoauIbEWkBfAN0BG4H+gNbgWzcKGOTiDwPTFbVIV5mMDBaVd8vUtcAYABAenp65siRI2PSaemG7dw/aQfb9yiXt69Fnw51opLPzc0lLS0tprYPBvnyoIPJm7zJxyaflZWVo6pZEU9U1YQeQG0gB7jYf24MpOJGL48Cr/ry54F+YXKDgUtLqjszM1NjIXd3vp78z881Y+Ao7f/qFC0oKIy6juzs7JjaPljky4MOJm/yJh8bQLYGeH4nNIpJRKoCHwBDVfVDb5DWqWqBqhYCL7NvGmkV0CxMvKkvK3Xu+XgWSzbnk3FYGs/26UpKijmlDcMwipLIKCbBjQLmqerTYeXpYaddBMz270cAV4hIdRFpCbQBpiZCt5PaNqRu9RReujqTemm2M5xhGEZxJDJkpydwNTBLRKb7sr8BfUWkC6DAUuBGAFWdIyLvAXNxEVA3aYIimHp3aUKD3atpd3jdRFRvGIZxUJAwA6GqE4Hi5m4+K0HmUZxfIuHUqGJrBA3DMErCnpKGYRhGsZiBMAzDMIrFDIRhGIZRLGYgDMMwjGIxA2EYhmEUixkIwzAMo1jMQBiGYRjFUibJ+hKFiPwCLItRvAGwIY7mK7t8edDB5E3e5GMjQ1UbRjwrSMKmg/EgYLIqky+/Opi8yZt87PJBDptiMgzDMIrFDIRhGIZRLJXZQPzX5OMm2TqYvMmbfAKp0E5qwzAMI3FU5hGEYRiGUQJmIAzDMIxiMQNhGIZhFEulMRAikioiT5ZSXWkxyrUWker+/cki8mcRqV8aOlUURORiEXlaRJ4SkYtikE8TkftE5GX/uY2InB+FfE0ROSradr2siEg/Efm7/9xcRI6PJFekjiYicoKI/CZ0RCGbGq3OJdR1iIh0Kq36ArZZLq7/eK5BEblMROr49/eKyIcicmxiNE0+lcpJLSKTVbV7HPInAK8AtVW1uYh0Bm5U1T8GlJ8OZAEtcDvrfQJ0UNVzI8gNwm3RWiyq+ucI8iMjyF8QQX7WAeTFiWugB42IvAAcCbzji/oAi1T1piDyvo53gRzgd6ra0Rvr71S1SwDZ3wJPAtVUtaXf+vahSL8/TP5FoBA4VVWPFpFDgC9U9biA8o/jfvNcILSdrkbR/mLgA+A1VZ0bRKaI/HjgAtxOkjnAemCSqt4eQa60/v8xXf9h8m2BvwIZhO2GqaqnBpH3dcR1DYrITFXtJCK9gEeAJ4C/q2q3EmQO9PcL6R/YUIvIv3y7O4HPgU7Abao6JGgd0ZDIPanLIz+KyAhgOLAjVKiqHwaUfwY4Cxjh5WZE0wMEClU13/daBqnqIBH5MYBcdhRtFEe8I6fAPfQInAocrb5XIiJvAHOirKO1qvYRkb4AqporIsVtbVscDwDHA+O97HQRaRlF291U9djQ/0xVN4lItSjkLwSOUtXdUciE0xm4AnhFRFKAV4Fhqro1oHw9Vd0qIr8H3lTV+0VkZgC50vr/x3r9hxgO/Ad4mX0GNlrivQZD7Z4H/FdVPxWRRyLIhP5+ISP0ln+9Kop2Q5ypqnf6v+FS4GLgG8AMRClQA9iIu0hCKBDUQKCqK4o8j6K5UPP8g+0a4Le+rGqANt+Ioo3i5CfEKb8335WINAZCPeapqro+iqoWAs3Zlz+rmS+Lhj0iUhPfIxOR1kDQB26eqm4p8v+LZgid56d5Qm03xI0ogrIY9/+OyUCo6jbcw/FlETkJeBt4RkTeBx5W1Uh/yyoikg5cDtwTRbux5jsrSkzXfxj5qvpinDrEew2uEpGXgDOAx/2UWYlT9aG/n4icoapdw766S0SmAXdF0X7omX0eMLyY67lUqVQGQlWvjbOKFX6aSUWkKnALMC8K+WuBPwCPquoS33t9K4LMXkTka4p5oAUdYotIG+CfQHucsQzJtwoofzluSD0eN70wSET+qqrvB5EH6gDzRGQq7nccD2T7UV3EqS7P/bihdTMRGQr0BPoHbH+OiFwJpPq/xZ+B7wLKAvwb+AhoJCKPApcC90YhnwtMF5FxhBmJSFOEIbxxOg93HbUAngKGAifipmzaRqjiQWAMMFFVfxCRVsDPAdrdRslTTHWD6E+c1z8wUkT+iPsfhP/9fo2ijnivwcuBs4EnVXWzN7h/Ddi2iEhPVZ3kP5xA9H7gUSLyE26K6f98J2VXlHUEprL5INoCLwKN/fx1J+ACVY00RAzJNwCeA07H3RxfALeo6saA8rWAXapa4D+nAtVVNTegfGbYxxrAJbhe1Z0B5SfiHrDP4Hpw1wIpqvr3gPIzgDNCowZ/cX6pqp0Dyp9U0vdBRzoichjQHfc/mKyqgTJaen/FPcCZXnYMrucd+AYTkXbAaV5+nKoG7iCIyDXFlQcdIXofxNfAYFX9rsh3/y7J0Phr7c+q+kxQfcsbIrKkmGIN2sHxdcR0DYrIoRHkIhopf/++CtTDXT+bgOtUdVok2WJ02aKqBf6arquqa6OpIzCJzARY3g5gAq7H8GNY2ewybH8yzsEd+lwb52CNp86pUZyb419nFS0LKD+ryOeUomVl8De8CDeXHvpcH7gwhnpS/Y0Vjcy/gRPi1L8a0NEfVaPU9+9lda0UkavrXw8t7oiinp7AWGABbrptCbC4LK+fOP52S8J19q9LYvkNOANRL0Y9LgPq+Pf34qbHj03U765UU0xAmqpOLTJnlx9JKN4oojBqqOr2MLntEkXIbJFeTAqQibvYgrLbOzd/FpE/AatwRioon4vIGPaPAPksqHCRqYpquPnnHRp8igLgflX9KPRB3TD/fuDjAO2/jZviKAB+AOqKyHOq+kTAtnOAe8WFyX6EcxAHDiAQkZOBN3DORcFNk12jqt9EklXXWzwfeChoe8UwSUSeB95l/yCNSD3Yt3GO1hzc/y/8BlIgaA9+MHCbrydqJ7O/V24HmqvqAD9NeJSqjgogO1FVexUzXRZomkxVowlmOJAO1XGj/hY4f1Co7mj+p/ep6nAfRXU6bsr3ReCAUVTxUNkMxAbv1Aw5GS8F1gSQizeKKMQOETk2dEP6IefOKOTDb9B8XO/l+ijkbwHScHPvD+Oc9cVOexSHqv5VRC4Gevmi/4Y/rAPI1wm995FHvXFTRdFQ3Jxt0Ou4vboonquA0TjnYA7uJouIuqmgN7yhvgTnpGyuqm0Ctv8ULgplPuyd8nwHZ+iDEOsDPkQoFDj8gaTsH7TxP6hqKApnEm4U/q2q/hSwzXC2qOroGORCvIb7f53gP6/CRTZFNBCq2su/1ol0biTEhTe3YX8/XkQjjwvr3YL7DbFGssUSRRUzlc0H0QqXAfEE3PzfEuAqjTJKQ0Tq4nod26KUOw4YBqzGPeQPB/qoak4Euct8r6GVqi6Ops3Sws9hf6mqp5RyvT/q/pEdkc5/FdgM/D9fdBNumqN/ANk5uIfk28DzqjpBfFx7lDofjxs99QbmqepvI4iE5P6nrWja90EKRVGNYh1APIjIKTiH+IlAa2Aazlg8F1D+MdxU2Yfs72QOZOBEJFtVs8KvGRGZoQF9YGH1pAKN2X8txfKAsr/HdbSaAtNxHZzvg/wPRGS2qnaMRtdi6hiFM4xnAMfiOphTo/0bBKVSjSD8w/V07yxOieEBn4XrxdRxH2UzzslU4gM+rP0fvJMztJJ3vqrmBRC9G9dTeh93UUSFiDyrqrfKARbMaYDoIT/FUSgi9VR1S7Q6eD0uDvuYgls0FW0Exs3AfbheNLg57aAL7f6D6xTMBL4RkQxcjy4Q4hYpXQQs8u0/rKqbg8rjomVeYV/Mej+iGJ3Ga5zFhSj/AzhCVc8RkfZAD1UdHLD9r0XkG1yY8ym46bqOuMCNIISmQbLCqyXCCCaMeEKc8TI34wI11rEvRFlxC86CcAvu909W1VP8/fyPgLLficgxqjorGp2LEE8UVdRUthHEIpyj+FtczyeqRVriFhXdpKrf+s+9gBci9QBF5FRV/arIA3IvGmGhnoiMZV9I3v8MZSM94EUkU1VzDhTBocGjhz4BuuIeyuFTHEHDNF8L+5iPm4t/WaNbSxEz3lcRQnFGKlVV7wsofyPwgQaMmipGvjrOmIWm6L7FXT+BHnIiUg/3cAstzpyAWwkeyMiJyGhcB+ceVe0sIlVwARvHBJQfB9QCvve6Tyyr/51v/0xcFFp7XARhT6C/qo6Poo6FuAWPgSIPi5H/QVWPE7cqvJuq7haROaraIYDsXNwq7iU4wxbVSvSwenoBbVT1NR9JWFtVi4vwiptKNYLAXVjdcEPkJ7yzcaaqBs3HUhAyDgCqOlFEIjq5gZOAr9i3OCicIAv1zsONHN7CzWNHRdgIJxvYqaqFsC/MNoqqPuR/dQ3cw9D416GE5u3vwDv6wuoO0gvdHva+BnAOAdaxiEg7P+f+A9BcRJqHfx90isQbgqeBp70fo2lQ4+B5FZiN60UCXI174Bfb8SiGBqr6nojc7fXJF5FonMUzcf6SjriR12YR+V5VA/nR4jVwqvqFiOSwL8T5lhiM9QqiGDUWw0px+aM+BsaKyCb2LbqLxDlxtAvs7eRk4WYhXsMFegzBGctSp7IZiAIgz78W4nLRRNMDmiBuFeU7uAdjH2C8+GRdB3pQqGqo5/pQUUsvAVI9qOoeEfkBmBC0t38AxuEiH0IPypq4ntgJB5TYn/pF55tF5JagjYtIU2AQ+y7mb3E3+cqgdbAv3cIrRBkJo6r7GVdxyRvHBBC9HRhA8cY58BSJFJMLSUS+U9Xbgsjj0oxcEvb5Qd+TDcoOcWtIQlM03YniYRnSU1yyuv64B9ThBO9kxGXg/BTp28AIVd0R6fwisqF8U4tx9+yn7O8HeTpIPWGdyQe8T6gebuFmENllxfX+g/4Gz0W4Ufw0X+dq//9ICJXNQGwFZuF6cS/HMMwMOYLuL1LelWAPig/4Xx/C+wSIYvE+gIjD2AjEFWaLi3gqOt/cv5iyA/Ea7ga/zH/u58vOiEKH0ki3ECIN52wsEVUd4F/jddDHmgspxE4R6aWqEwFEpCfRRcHdjssj1lpEJgENcavBAyEuNPpE3PW6FPfA/7YkmSLEa+CexHXKHvMdpmHAKA220DH0EF3uj2r+iIoio8dQZ+9wX2ck2dLo/e9RVRWRkJGvFYVs1FQ2A9EXN//7R+D3IvId8I2qjgsiHOsDwjuyOgD1ivgh6hIWKheA6RJfssGYwmzF5c+5Emjp2w9RB4gmzUFDVQ33Q7wuIrdGIQ9xpFuQ/bNqpuIekIFj0EXkJmBoyDEtLtyxr6q+ELCKmHIhhfF/uDDb0NqXTQRPM4KqTvN+qKNwUzRBgyRC1MB1rnJUNcjUalHiMnB+9DzBT42eCtyAM1IR19Go6oNFy8StCaqtwZMdAnzKvlDzGkBLYD7u/o5EafT+3/OzGPVF5AbgOlx+roRQqQyEqn4CfOIf2OcAtwJ34qZaIhLHHOpRuIVG9dnfD7ENd5EHJd5kg7cCw0VkvzDbAHLf4daLNGD/aZZtuHnpoGwUkX7sW2jXF/d7oiG0biM8ciPoYq3wrKT5wLooH3Q3qGoovBZ12VxvAIIaiJhyIYW1Nx3oLC7MmigfbCGOZ5//5lgRQVXfDNh+vFmBww2c4DoX/aOpwEcx/RZ33R6LW3gYjXxciyWLOvT99HKgdP+UQu9fVZ8UkTNwsyFH4VbXj422nqBUtiimD3DTRIvwkUzAlIBD1JD8bPZdlFcDnVU16BxqD1X9PmrFSxFxSQajDbMtrbYzcD6IHriH+ne4/ECBYtCTjR+BdFJ/0/ie7MyAESxx50KSOMNUReQt3PqF6ey/H0XQTAClQqwGTkTewxm4z3FhxhNCARdR1DFdVbuIWyx5LH6xZLSRREXqnBUkEkxE7sAtsDsDlzTzOuBtVR0Ua9uJplKNIHD/lB/VJ8uLgXjnUP8gIvOKTFE8parXBRGW+JMNVsX14kIjoPEi8lJQI+Gnxx4HGuF6gIGzefoH5MUacHOcEuqJOd1CKTAGeNcP8QFuJLiDssBP1cWTLO91fJiq/7wA96AMZCBw89/tQwaurBCRfqo6JMxRHCoHgjuIcb+zbxz3L0BVfx9ciFssmRfq0QehyG9IwRmZ1QHFG+J8jnt7/7igkSDtllZG3aioNFuOemYAN4nI+/642V8sQdnpoxCAmJyEnTRsYZWqbsLNSQblZdyiuTwvPxO3gUxQXsQ5GF/wR6YvC8q/cAapnqrWVdU6QS9Mf1P3jaKtA/EasIf90y0kLNVAEe7EhSv/nz/G+bKgTBKR50XkRBE5NnREId9AVd/DL/Dy02PRPCxn46YVy5rQVEqdYo6IUTwiEppSrQX0Frdl6N4jSl1ewjnYa7FvsWQ0I5lw3avjfBK9A8qeoapjVfWvqnqHnxoKFPoauteKOQLfg7FQ2UYQL+IiB0Jzxlf7st8HlI/LSQikiMgh3jCEku9F8z+IKdlgGMfp/kvyvxKXwjso6zSK9NbFEG8uIYhvR7mY8SOgN1X1KlyYbSzElAspjJjCVGXfCvo6wFxxeyGEO/jjGtVFQlVDI64v1e+FEKZbkAie8HVEIQdx+Gs0G379G5eVN8QycSlEgsr/j7M7EiLyfzg/RSvZP2qtDi6/VbmlshmIuB6QpeAkfAr4XkSG4y7uS4FHo5CPNdlgiAIRaa2qi7x8K6LrgWaL2xP6Y/Z/wAS9QUMPyNBNFrrBo8klFHe6hVjwU0QZIlJNVffEWEe8YbKxhqnG61wuLQbxv2HexZXth+5bRzSb/bPJKrBFRLr4ezMiUiSjathXJUazSXz7ur+NSw75T/bfPW5bkOi7ZFLZDERcD8h4nYSq+qa4laChB8XFGt3m8zfhkg22E5FV+GSDUcjfAXwtbuMZcDdJNKub6+J2RTszrCyaHtwo/vcG3xrNDU58O8rFy2LcKGgE+4+AAs2hl8L1E1OYqg8PRUQeV9WBRXR6HBeNlzBEpAduSrBhkTn8urhw46Bk4vwoI3C//3xcFN0fRGS4qv4rQB2xZlQNGdmLcdN0oXxafXF5nQ6Ij3LcQulMsZYplS2K6TTcHPZ+D0hVLS5LZnHyceWyCaunEfunCo4qikdiTzZ4Gc7R2gLnpOuB+y1R7WgVKz7EsLgbvAVuf90gNzgS445y8SL753LaS9Bph9K4fsRtU9mC/dOMBApTFZFpqnpskbKos9lGizdqJ+PCS8On57YBI1U1UKivuESB56pf7CkitXE+gLNxkUjtA9QRV0ZV8RllI5UdLFS2EcQknJPqNFzK6DG4xGNBiSuXjYhcgJtmOgKX4iMDl1ea0xEAAArXSURBVAso0AppKZJsEIgq2SD7NhupixvFPEkUm41I/KkymuJ2vwrd4PfjbvDf4Hp0EQ2EiIQisELGsb24WP4g+fjjImQIRCRNA24TW4R4r59iw1SBEg1E2Bx462LmwKPZkzsmdN8Ct9c1ytT6RWjE/r3+PFxE304RCToaiDejai0JS7svLlVOQlczJ5PKZiDexEUsPOw/X4lLgHfZASX2J65cNr7d7jhnXVfvHOsXhXzcyQb963m4VCPRbjYSb6qM0rjBwxfI1cDFxecQnR8jJvxUyWBc5E1zEekM3KiqQRdKxXv9xBqmGj4H/hj7wpwnquqPUdYVD6+I29skPMx7mKqeFVB+KDBFXFZhcE7rt/2IOuhUbS+gv7j9rWPJqHobLjx8sZfNwIU7H5RUNgPRscgw9GtxKXiDEnIStorSSRgiT1U3ikiKiKSoy6//bBTy8SYbXCUuhv8M3G5o1Yku1DneVBlx3+BaZHMeEWkGRPM3jIdngbNw1wCqOiNsRBOEeK+fUJhqNIEJe+fARWQybu78Q9zD7Q0ReVnLbqFWg6Jh3n66NRCq+rCfpguNYP+g+7Z8DeqLiyujqqp+Lm7tTTtf9JNGl5G3QlHZDMQ0EemuqpMBRKQb0W0nOheXAygXN8XxMW6xUlA2+3nTb4ChIrKe/VNQRyLeZIPxbjYSV6qMUrrBi7ISODpG2ahR1RVFomqjiQKL6fopxTDV64Hu6jOhegf197hpw7KgUNwWrct9+y2IIl08gL9eYt4CWF1G1c64UTi4fWEiRjLKgfd0ae2nOAOH2lYkKpuByMTNQYacws2B+eKTuAUYZoamqEI7SEU7RTUD93C4DfdArEd06X7jTTaYS1jEkaquIbre6HW4h8kz7EuV0T8K+bhvcBEZxL6HSgoudLZMnOzACu8kVnELLG8hwH4SYcR6/TyJ6/E/jgsuCBEqC4qwv0ErYF9EWVlwDzBRRCb4dk/EpVH//+3db4xcVR3G8e+jEYuQitqYqCklQqxKg01tBYEEEGKI4Y2mxgBCS4glEYnYRF8oMX2BxhiiUQgSFP8E/IOCBkQSIWKJJUBaSlNsATWKafwTaKICopDSxxfnTnZ2nHbvzp2duzPzfN5sd+7cOWe3s3v2nPM7v9/IqKSn/xgzPwe3SLqxxiyqaU2XsTRtUUwrDnd9rg00SXt7IyX6PXaY+4cSRaLZyQbfaLtWssGmJH0PuNKzD/pd45qpQobUhw1dnx4Anuo9fLWAbS+jpDY/hzI4/ZKySV9rFtX2+6cKMd1AmcVAGWy+a3tUS3SdCL5NwKOUJJlPjyLAoKv93ZTQ4s4s6ihKTem638NXulmqj7EyVTOIhhEUMOAS1RxRJLV/uen/kw1eDDxcv/uNndQZHKCk2JY0n1QhjdmeV/bOIbe9n8GXwqD5+6fRSVzbX1EpWtRJF3PJKDepVepgfJISzbaLErDxICMIMOjuBs1mUX+S1EkWeN8AAQNjZapmEE1JepxySGnWEhXlL9lDLlGppOZ4HQ1PUkpaS7Nkg42onDo/s2cGcf98z4EM2HZ3LYdZl5hfFEqTPjQK8237/dO26v9wHeXsyupqJvxF18yGPKQ+NJpFqSSLPI+SA20N5fDnj1zVuJg0GSDmoekS1RDa783Gej9wg0eUslvSxcBnKQWLoKydf8H2zSNo++0cJjHiQn/vqz7cSwkZ7Xy9HwUutF0rzLft90/bJG23vU4lA/LJtl+UtMc10qUPuR9rmJlF/WbQWVQVpvs1yntgPifCx0YGiDEi6VuUZIPd9Shetl032eAw+vBOZpYE7vP8UoU0aXen7TWSbrZ90Sja7NOHXbZXz/VY9CfpZ5TULldS3kP/AF5l+wMjaHupS7nX1/e7Ps+Z/BmUgkXnUpYIb7V9+3B6urhM1R7EBGiajbWxakAYyaDQ4whJFwCn9gk1HFWY4TAq4k2trgOdWyT9mhLFV6uexhD8gLI09Aizlyo7CSPrVCRE0lOUDfYfA5/ubHZPqswgxoikncCHPTvZ4G29kS2TSKUOx4WUsxx39lz2KCKp1L8i3hW29y1027E4dGYibfdjVDJAjBE1TDY4CSRd6prZTxeg7dbDfKMZSb+yffZcj/W57zO2vyzp6/2ue8RlW0clS0zjpWmywbFn+yY1yGjaUOthvjEYSUuA1wDLqs3lTmjrUuAtNV6icyDykQXo3qKVAWK8NE02OPY0YEbTIWlaETDacxllc/zNlF/ynQHiWeC6uW62/fPqY2vncNqQJaYx0vQk7iSozhIMktF0GG23FuYbwyHpihppNfrd16Si3NjKXz/jpWmywUkwUEbTYXCpCLiDmTDf+VYEjJbZvlbSKkrq/O6iXXPNQAeuKDfOMoMYI4OexJ0kVXjkamDQjKYxxVSKVJ1JGSDupuQ022a7Vtp1paJcLGLntt2BRWBL2x2Isbaeks/sUduXqNQJv2WOe7qlolwsTpOeiqEOl/KVEYP6j+2Dkg6olN59Glg+j/tTUS5isZG0zfbpkp6jz0lY20tb6lqMlx2SjgG+SYlmep55hIp7yirKZQ8iIqaSSkW7pbZ3z/HU3vvaOoczchkgImLiVRlcD8l2raqEhzqHM6knqTNARMTEq6LfDsW2axUtavMcThuyBxERE8/2WUN6qdbO4bQhA0RETI2qItxm4Fjbm6oN55W276r5EsuAvZKm4hxOBoiImCbfoUQvnVp9/hdK6pS6A8SWBejTopUBIiKmyfG2PyLpfADbL0jSXDd1TNs5nAwQETFNXpJ0JNVZGknH07VUdCjTeg4nUUwRMRWqmcJFwKWUXEz3AKcBG21vbbFri1YGiIiYGpIeoyTrO4Xy1/9Dtve32qlFLEtMETFNdgJvtf2LtjsyDjKDiIipIekJ4ATgz8C/mdlDmPhU+YPIABERU0PSin6PJ1NyfxkgIiKir1e03YGIiFicMkBERERfGSAiKpI+J2mPpN2Sdkk6eQHb2ippIusYx+RImGsEIOm9wHnAGtsvSloGHNFytyJalRlERPEmYH+nfKTt/bb/KunzkrZL+q2kGzt5e6oZwFcl7ZD0uKR1kn4q6feSrq6ec5ykJyR9v3rObVU20VkkvV/Sg5J2SvqJpKOrx78kaW81o7lmhN+LCCADRETHPcBySb+TdL2kM6rHr7O9zvYq4EjKLKPjJdtrgRuAO4DLgVXARklvqJ6zErje9juAZ4GPdzdazVSuAs6xvQbYAWyu7v8gcGIVo3/1AnzNEYeVASICsP088G5gE/AMcKukjcBZkh6uUjS8Dzix67Y7q4+PAXts/62agfwRWF5d22f7gerftwCn9zR9CiUv0AOSdgEbgBXAv4D/AjdJ+hDwwtC+2IiasgcRUbH9MrAV2FoNCJcBJwFrbe+TtAVY0nVLJwvoQWZnBD3IzM9W70Gj3s8F3Gv7/N7+SHoPcDawHvgEZYCKGJnMICIASSur6mIdq4Enq3/vr/YF1g/w0sdWG+AAFwDbeq4/BJwm6YSqH0dJelvV3mtt3w18CnjXAG1HNJIZRERxNHCtpGOAA8AfKMtN/6TUIf47sH2A130SuFzSt4G9wDe6L9p+plrK+qGkV1cPXwU8B9whaQlllrF5gLYjGkmqjYgFIuk44K5qgzti7GSJKSIi+soMIiIi+soMIiIi+soAERERfWWAiIiIvjJAREREXxkgIiKirwwQERHR1/8As+gzf6h9pW8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SC.plot(20), SC.plot(20, cumulative = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   power   people  tactics powerful   social  control    group \n",
      "     245       40       33       31       27       23       23 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SC.tabulate(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = SC.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245</td>\n",
       "      <td>power</td>\n",
       "      <td>0.125770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40</td>\n",
       "      <td>people</td>\n",
       "      <td>0.020534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>33</td>\n",
       "      <td>tactics</td>\n",
       "      <td>0.016940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>31</td>\n",
       "      <td>powerful</td>\n",
       "      <td>0.015914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>social</td>\n",
       "      <td>0.013860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TF      Term       wTF\n",
       "0    245     power  0.125770\n",
       "21    40    people  0.020534\n",
       "89    33   tactics  0.016940\n",
       "183   31  powerful  0.015914\n",
       "1     27    social  0.013860"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245</td>\n",
       "      <td>power</td>\n",
       "      <td>0.125770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40</td>\n",
       "      <td>people</td>\n",
       "      <td>0.020534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>33</td>\n",
       "      <td>tactics</td>\n",
       "      <td>0.016940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>31</td>\n",
       "      <td>powerful</td>\n",
       "      <td>0.015914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>social</td>\n",
       "      <td>0.013860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>control</td>\n",
       "      <td>0.011807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>23</td>\n",
       "      <td>group</td>\n",
       "      <td>0.011807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>influence</td>\n",
       "      <td>0.011294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20</td>\n",
       "      <td>use</td>\n",
       "      <td>0.010267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>20</td>\n",
       "      <td>coercive</td>\n",
       "      <td>0.010267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TF       Term       wTF\n",
       "0    245      power  0.125770\n",
       "21    40     people  0.020534\n",
       "89    33    tactics  0.016940\n",
       "183   31   powerful  0.015914\n",
       "1     27     social  0.013860\n",
       "24    23    control  0.011807\n",
       "151   23      group  0.011807\n",
       "23    22  influence  0.011294\n",
       "36    20        use  0.010267\n",
       "64    20   coercive  0.010267"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='wTF', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3</td>\n",
       "      <td>satisfaction</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3</td>\n",
       "      <td>creates</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>3</td>\n",
       "      <td>holder</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3</td>\n",
       "      <td>reduction</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3</td>\n",
       "      <td>including</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3</td>\n",
       "      <td>outcome</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3</td>\n",
       "      <td>appropriate</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3</td>\n",
       "      <td>draw</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>3</td>\n",
       "      <td>quality</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>3</td>\n",
       "      <td>stage</td>\n",
       "      <td>0.00154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TF          Term      wTF\n",
       "142   3  satisfaction  0.00154\n",
       "141   3       creates  0.00154\n",
       "131   3        holder  0.00154\n",
       "125   3     reduction  0.00154\n",
       "124   3     including  0.00154\n",
       "123   3       outcome  0.00154\n",
       "121   3   appropriate  0.00154\n",
       "120   3          draw  0.00154\n",
       "119   3       quality  0.00154\n",
       "305   3         stage  0.00154"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='wTF', ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full list of terms ::>>\n"
     ]
    }
   ],
   "source": [
    "print(\"The full list of terms ::>>\")\n",
    "#SC.list_terms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SC.set_stemmer(STEMMER_FUNC)\n",
    "SC.compute_stems()\n",
    "#SC.stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245</td>\n",
       "      <td>power</td>\n",
       "      <td>power</td>\n",
       "      <td>0.125770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40</td>\n",
       "      <td>people</td>\n",
       "      <td>peopl</td>\n",
       "      <td>0.020534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>33</td>\n",
       "      <td>tactics</td>\n",
       "      <td>tactic</td>\n",
       "      <td>0.016940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>31</td>\n",
       "      <td>powerful</td>\n",
       "      <td>power</td>\n",
       "      <td>0.015914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>social</td>\n",
       "      <td>social</td>\n",
       "      <td>0.013860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TF      Term    Stem       wTF\n",
       "0    245     power   power  0.125770\n",
       "21    40    people   peopl  0.020534\n",
       "89    33   tactics  tactic  0.016940\n",
       "183   31  powerful   power  0.015914\n",
       "1     27    social  social  0.013860"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = SC.to_pandas()\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Computing specificity of terms in a corpus with respect to a reference background corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Scoring in module omterms.measures:\n",
      "\n",
      "class Scoring(builtins.object)\n",
      " |  The object given term frequency distribution of a foreground specific corpus and a background\n",
      " |  reference corpus, provides tools that help to compute specificity of each term in the foreground corpus.\n",
      " |  \n",
      " |  This kind of scoring is mainly to be used for the cases where an input text around a specific\n",
      " |  theme or topic is given. The process expects a tokenized, cleaned text with term counts.\n",
      " |  \n",
      " |  Note:\n",
      " |      It consumes a Corpus object and uses its methods and attributed and mutates it unless desired otherwise.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      sCorpus (:obj:`Corpus`): A Corpus class instance of the specific corpus to be scored.\n",
      " |      rCorpus (:obj:`Corpus`): A Corpus class instance of the reference corpus.\n",
      " |      common (:obj:`list` of `str`): The common terms between the foreground and backgrouns corpus\n",
      " |      distinct (:obj:`list` of `str`): The terms observed in the foreground but not in the backgrouns corpus\n",
      " |      model: a prediction model created during instantiation process using the data of the class instance.\n",
      " |          For details see`form_prediction_model` method description.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, sCorpus, rCorpus, nsteps=3, mutate=False, model_threshold=1.0)\n",
      " |      The class constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          sCorpus (:obj:`Corpus`): A Corpus class instance of the specific corpus to be scored.\n",
      " |          rCorpus (:obj:`Corpus`): A Corpus class instance of the reference corpus.\n",
      " |          nsteps (:obj:`int`):  Number of phases to process at init.\n",
      " |              1-> raw, 2 -> raw,stem, 3 ->raw,stem,noref (default 3)\n",
      " |          mutate (:obj:`bool`, optional): A flag when true mutates the input Corpus object \n",
      " |              for specific text corpus (default False).\n",
      " |          model_threshold (:obj:`float` or None) :  The minimum score value used for prediction model.\n",
      " |  \n",
      " |  compute_commons(self)\n",
      " |      Computes the specifity score of the terms in the corpus.\n",
      " |      \n",
      " |      Note:\n",
      " |          It is a simple log likelihood measure. It compares frequency count of a term in\n",
      " |          a specific corpus versus its frequency count in the reference reference corpus.\n",
      " |          Here assumption is that the reference corpus is a large enough sample of the language\n",
      " |          at observing the occurance of a term. Then having a higher/lower observation frequency of\n",
      " |          a term in the specific corpus is a proxy indicator for the term choice while having a debate\n",
      " |          on the topic.\n",
      " |      \n",
      " |          The likelihood ratio for a term $P_t$ is calculated as:\n",
      " |          .. math::\n",
      " |              $P_t = log ( (ntS/NS) / (ntR/NR) )$\n",
      " |          \n",
      " |          where\n",
      " |              - *ntS* is the raw frequency count of the term in the entire specific corpus\n",
      " |              - *ntR* is the raw frequenccy count of the term in the reference corpus\n",
      " |              - *NS* is the total number of terms in the specific corpus\n",
      " |              - *NR* is the total number of terms in the reference corpus\n",
      " |          \n",
      " |          It should be noted that frequency counts are calculated after having applied the same tokenization\n",
      " |          and post processing such as excluding stop-words, pancuations, rare terms, etc both on the reference\n",
      " |          corpus and the specific corpus.\n",
      " |          \n",
      " |      Args:\n",
      " |          None\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  compute_distincts(self)\n",
      " |      Computes the specifity score of the terms in the corpus when neither the term nor its stems\n",
      " |          matched by the background corpus.\n",
      " |          \n",
      " |      Note:\n",
      " |          It uses a log linear regression model to predict likelihood of the dictinct terms.\n",
      " |          The model is trained using the scores and frequencies within the matching set.\n",
      " |          \n",
      " |          See `form_prediction_model` method description for details.\n",
      " |          \n",
      " |      Args:\n",
      " |          None\n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  compute_stem_commons(self)\n",
      " |      Computes the specifity score of the terms in the corpus when the term as it is not \n",
      " |          matched by a term in the reference corpus. It matches the stems. The loglikelihood\n",
      " |          ration is applied over the mean frequency counts of the matching stems.\n",
      " |          \n",
      " |          See `compute_commons` method description for details.\n",
      " |          \n",
      " |      Args:\n",
      " |          None\n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  form_prediction_model(self, threshold=1.0)\n",
      " |      The method creats the prediction model to be used for distinct terms.\n",
      " |          \n",
      " |      Note:\n",
      " |          It is based on a log-linear regression. The model is created using the observed\n",
      " |          scores and frequencies within the matching set. The model aims to fit a best line\n",
      " |          to logarithm of the observed term frequencies vs associated scores.\n",
      " |          \n",
      " |          Considering the fact that frequent distinct terms are likely among the ones with a \n",
      " |          higher specificity, the terms with relatively high scores are used for the regression.\n",
      " |          The R-squared of the regression tests have been used for validation of the approach.\n",
      " |          In the same reasoning among the all distinct terms the ones with relatively higher frequencies\n",
      " |          are considered for scoring.\n",
      " |          \n",
      " |      ToDo:\n",
      " |          As a second approach, the model training to be improved considering terms with relatively high term\n",
      " |          frequencies and high specificity scores. Observe the scatter plots for the insight.\n",
      " |          \n",
      " |          An alternative, a third approach, would be forming the logarithmic bins on frequencies and using\n",
      " |          distributional charcteristics of each bin at making predictions. For instance, by simply predicting\n",
      " |          the median value as the guess. \n",
      " |          \n",
      " |      Args:\n",
      " |          threshold (:obj:`float`, optional):  The default value is driven from regression tests on \n",
      " |              test cases (default 1.0).\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  get_scores_by(self, stype='raw')\n",
      " |      The method returns computed/available scores by the label of the terms.\n",
      " |      \n",
      " |      Note:\n",
      " |          The labels in this implementation correspond:\n",
      " |          - raw: the term as it is was identified in the background corpus, so\n",
      " |              a loglikelihood scoring was applied\n",
      " |          - stem: not the term as it is but its stem was identified, so mean of the observed\n",
      " |              stem occurances in the background was used as the reference\n",
      " |          - noref: neither the term nor its stem was identified, so the prediction model was used\n",
      " |              for the frequent ones.\n",
      " |          \n",
      " |      Args:\n",
      " |          stype (:obj:`str`, optional): The term scoring type (default 'raw').\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`dict`): The term scores.\n",
      " |  \n",
      " |  plot(self, threshold=1.0, islog=True)\n",
      " |      Scatter plot of frequency vs scores.\n",
      " |                      \n",
      " |      Args:\n",
      " |          threshold (:obj:`float`, optional):  The default value is driven from regression tests on \n",
      " |              test cases (default 1.0).\n",
      " |          \n",
      " |          islog (:obj:`bool`): Whether natural log of the frequency counts to be returned (default True).\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  predict(self, w, count, minp=0.001, minf=3)\n",
      " |      The method assigns a predicted score to a given term with a a frequency\n",
      " |          over the designated threshold. An internally formed prediction model is used.\n",
      " |          The natural logorithm of raw frequency counts is passed to the model. See \n",
      " |          `form_prediction_model` method description for details.\n",
      " |          \n",
      " |      Args:\n",
      " |          count (:obj:`int`): The raw frequency count.\n",
      " |          minp (:obj:`float`, optional): The relative frequency threshold (default 0.001).\n",
      " |          minf (:obj:`int`, optional): The raw frequency threshold (default 3).\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`float`): The predicted score.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Loading and preparing a reference corpus\n",
    "For the demonstration purpose a NLTK's Brown corpus is used. \n",
    "\n",
    "However for a more sound comparison foreground corpus needs to a sample or a driven niche of the background corpus. In that respect full Wikipedia Corpus needs to be inetgrated into this work:\n",
    "\n",
    "https://github.com/pavlobaron/wpcorpus\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the first timers: uncomment the command below for an interaction download process\n",
    "#nltk.download()\n",
    "from nltk.corpus import brown\n",
    "TOKENSREF = list(nltk.corpus.brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning process: Initial size of tokens = 1161192\n",
      "Initial state:\n",
      "Total term counts: 1161192\n",
      "[('the', 69971),\n",
      " (',', 58334),\n",
      " ('.', 49346),\n",
      " ('of', 36412),\n",
      " ('and', 28853),\n",
      " ('to', 26158),\n",
      " ('a', 23195),\n",
      " ('in', 21337),\n",
      " ('that', 10594),\n",
      " ('is', 10109)]\n",
      "Removing panctuation only terms...\n",
      "Total term counts: 1016830\n",
      "[('the', 69971),\n",
      " ('of', 36412),\n",
      " ('and', 28853),\n",
      " ('to', 26158),\n",
      " ('a', 23195),\n",
      " ('in', 21337),\n",
      " ('that', 10594),\n",
      " ('is', 10109),\n",
      " ('was', 9815),\n",
      " ('he', 9548)]\n",
      "Removing stopwords...\n",
      "Total term counts: 526248\n",
      "[('--', 3432),\n",
      " ('will', 2245),\n",
      " ('said', 1961),\n",
      " ('new', 1635),\n",
      " ('time', 1598),\n",
      " ('two', 1412),\n",
      " ('now', 1314),\n",
      " ('man', 1207),\n",
      " ('even', 1170),\n",
      " ('made', 1125)]\n",
      "Reduction due to punctuations and stopwords = 1111606.\n",
      "Reduction due to all numeral terms = 1747\n",
      "Reduction due to short terms = 178\n",
      "Reduction due to rare terms = 27810\n",
      "Reduction due to partially numeral terms = 49\n",
      "Reduction due to terms with not allowed symbols = 645\n",
      "The total term count reduction during this cleaning process = 1142035\n",
      "Percentage = 98%\n"
     ]
    }
   ],
   "source": [
    "TOKENSREF_TF = run_cleaning_process(Cleaner, TOKENSREF,\n",
    "                                    minL = MIN_LENGTH,\n",
    "                                    minF = MIN_FREQ,\n",
    "                                    notallowed = NOTALLOWED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words = 19157\n",
      "Number of words = 467021\n",
      "\n",
      "Most frequents ::>>\n",
      "[('will', 2245),\n",
      " ('said', 1961),\n",
      " ('new', 1635),\n",
      " ('time', 1598),\n",
      " ('two', 1412),\n",
      " ('now', 1314),\n",
      " ('man', 1207),\n",
      " ('even', 1170),\n",
      " ('made', 1125),\n",
      " ('must', 1013),\n",
      " ('back', 966),\n",
      " ('years', 950),\n",
      " ('much', 937),\n",
      " ('way', 908),\n",
      " ('people', 847),\n",
      " ('little', 831),\n",
      " ('state', 807),\n",
      " ('good', 806),\n",
      " ('make', 794),\n",
      " ('world', 787)]\n",
      "\n",
      "Least frequents ::>>\n",
      "[('quintus', 3),\n",
      " ('longue', 3),\n",
      " ('steels', 3),\n",
      " ('lovejoy', 3),\n",
      " ('fairview', 3),\n",
      " ('carraway', 3),\n",
      " ('peony', 3),\n",
      " ('ballplayers', 3),\n",
      " ('fudomae', 3),\n",
      " ('anthea', 3),\n",
      " ('herberet', 3),\n",
      " ('jennie', 3),\n",
      " ('pioneers', 3),\n",
      " ('poitrine', 3),\n",
      " ('bookies', 3),\n",
      " ('feeley', 3),\n",
      " ('crumb', 3),\n",
      " ('saleslady', 3),\n",
      " ('non-fiction', 3),\n",
      " ('quasimodo', 3)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will said  new time  two  now  man \n",
      "2245 1961 1635 1598 1412 1314 1207 \n"
     ]
    }
   ],
   "source": [
    "CRef = Corpus(TOKENSREF_TF)\n",
    "DF_Brown = summary_corpus(CRef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2245</td>\n",
       "      <td>will</td>\n",
       "      <td>0.004807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1961</td>\n",
       "      <td>said</td>\n",
       "      <td>0.004199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1635</td>\n",
       "      <td>new</td>\n",
       "      <td>0.003501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1598</td>\n",
       "      <td>time</td>\n",
       "      <td>0.003422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1412</td>\n",
       "      <td>two</td>\n",
       "      <td>0.003023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>1314</td>\n",
       "      <td>now</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>1207</td>\n",
       "      <td>man</td>\n",
       "      <td>0.002584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>1170</td>\n",
       "      <td>even</td>\n",
       "      <td>0.002505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1125</td>\n",
       "      <td>made</td>\n",
       "      <td>0.002409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1013</td>\n",
       "      <td>must</td>\n",
       "      <td>0.002169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TF  Term       wTF\n",
       "147   2245  will  0.004807\n",
       "4     1961  said  0.004199\n",
       "182   1635   new  0.003501\n",
       "370   1598  time  0.003422\n",
       "76    1412   two  0.003023\n",
       "667   1314   now  0.002814\n",
       "262   1207   man  0.002584\n",
       "1181  1170  even  0.002505\n",
       "398   1125  made  0.002409\n",
       "344   1013  must  0.002169"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_Brown.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming the terms in the corpus ..\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2245</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>0.004807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1961</td>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "      <td>0.004199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1635</td>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>0.003501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1598</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>0.003422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1412</td>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>0.003023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TF  Term  Stem       wTF\n",
       "147  2245  will  will  0.004807\n",
       "4    1961  said  said  0.004199\n",
       "182  1635   new   new  0.003501\n",
       "370  1598  time  time  0.003422\n",
       "76   1412   two   two  0.003023"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRef = run_stemming_process(CRef, STEMMER_FUNC)\n",
    "CRef.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Scoring in module omterms.measures:\n",
      "\n",
      "class Scoring(builtins.object)\n",
      " |  The object given term frequency distribution of a foreground specific corpus and a background\n",
      " |  reference corpus, provides tools that help to compute specificity of each term in the foreground corpus.\n",
      " |  \n",
      " |  This kind of scoring is mainly to be used for the cases where an input text around a specific\n",
      " |  theme or topic is given. The process expects a tokenized, cleaned text with term counts.\n",
      " |  \n",
      " |  Note:\n",
      " |      It consumes a Corpus object and uses its methods and attributed and mutates it unless desired otherwise.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      sCorpus (:obj:`Corpus`): A Corpus class instance of the specific corpus to be scored.\n",
      " |      rCorpus (:obj:`Corpus`): A Corpus class instance of the reference corpus.\n",
      " |      common (:obj:`list` of `str`): The common terms between the foreground and backgrouns corpus\n",
      " |      distinct (:obj:`list` of `str`): The terms observed in the foreground but not in the backgrouns corpus\n",
      " |      model: a prediction model created during instantiation process using the data of the class instance.\n",
      " |          For details see`form_prediction_model` method description.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, sCorpus, rCorpus, nsteps=3, mutate=False, model_threshold=1.0)\n",
      " |      The class constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          sCorpus (:obj:`Corpus`): A Corpus class instance of the specific corpus to be scored.\n",
      " |          rCorpus (:obj:`Corpus`): A Corpus class instance of the reference corpus.\n",
      " |          nsteps (:obj:`int`):  Number of phases to process at init.\n",
      " |              1-> raw, 2 -> raw,stem, 3 ->raw,stem,noref (default 3)\n",
      " |          mutate (:obj:`bool`, optional): A flag when true mutates the input Corpus object \n",
      " |              for specific text corpus (default False).\n",
      " |          model_threshold (:obj:`float` or None) :  The minimum score value used for prediction model.\n",
      " |  \n",
      " |  compute_commons(self)\n",
      " |      Computes the specifity score of the terms in the corpus.\n",
      " |      \n",
      " |      Note:\n",
      " |          It is a simple log likelihood measure. It compares frequency count of a term in\n",
      " |          a specific corpus versus its frequency count in the reference reference corpus.\n",
      " |          Here assumption is that the reference corpus is a large enough sample of the language\n",
      " |          at observing the occurance of a term. Then having a higher/lower observation frequency of\n",
      " |          a term in the specific corpus is a proxy indicator for the term choice while having a debate\n",
      " |          on the topic.\n",
      " |      \n",
      " |          The likelihood ratio for a term $P_t$ is calculated as:\n",
      " |          .. math::\n",
      " |              $P_t = log ( (ntS/NS) / (ntR/NR) )$\n",
      " |          \n",
      " |          where\n",
      " |              - *ntS* is the raw frequency count of the term in the entire specific corpus\n",
      " |              - *ntR* is the raw frequenccy count of the term in the reference corpus\n",
      " |              - *NS* is the total number of terms in the specific corpus\n",
      " |              - *NR* is the total number of terms in the reference corpus\n",
      " |          \n",
      " |          It should be noted that frequency counts are calculated after having applied the same tokenization\n",
      " |          and post processing such as excluding stop-words, pancuations, rare terms, etc both on the reference\n",
      " |          corpus and the specific corpus.\n",
      " |          \n",
      " |      Args:\n",
      " |          None\n",
      " |          \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  compute_distincts(self)\n",
      " |      Computes the specifity score of the terms in the corpus when neither the term nor its stems\n",
      " |          matched by the background corpus.\n",
      " |          \n",
      " |      Note:\n",
      " |          It uses a log linear regression model to predict likelihood of the dictinct terms.\n",
      " |          The model is trained using the scores and frequencies within the matching set.\n",
      " |          \n",
      " |          See `form_prediction_model` method description for details.\n",
      " |          \n",
      " |      Args:\n",
      " |          None\n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  compute_stem_commons(self)\n",
      " |      Computes the specifity score of the terms in the corpus when the term as it is not \n",
      " |          matched by a term in the reference corpus. It matches the stems. The loglikelihood\n",
      " |          ration is applied over the mean frequency counts of the matching stems.\n",
      " |          \n",
      " |          See `compute_commons` method description for details.\n",
      " |          \n",
      " |      Args:\n",
      " |          None\n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  form_prediction_model(self, threshold=1.0)\n",
      " |      The method creats the prediction model to be used for distinct terms.\n",
      " |          \n",
      " |      Note:\n",
      " |          It is based on a log-linear regression. The model is created using the observed\n",
      " |          scores and frequencies within the matching set. The model aims to fit a best line\n",
      " |          to logarithm of the observed term frequencies vs associated scores.\n",
      " |          \n",
      " |          Considering the fact that frequent distinct terms are likely among the ones with a \n",
      " |          higher specificity, the terms with relatively high scores are used for the regression.\n",
      " |          The R-squared of the regression tests have been used for validation of the approach.\n",
      " |          In the same reasoning among the all distinct terms the ones with relatively higher frequencies\n",
      " |          are considered for scoring.\n",
      " |          \n",
      " |      ToDo:\n",
      " |          As a second approach, the model training to be improved considering terms with relatively high term\n",
      " |          frequencies and high specificity scores. Observe the scatter plots for the insight.\n",
      " |          \n",
      " |          An alternative, a third approach, would be forming the logarithmic bins on frequencies and using\n",
      " |          distributional charcteristics of each bin at making predictions. For instance, by simply predicting\n",
      " |          the median value as the guess. \n",
      " |          \n",
      " |      Args:\n",
      " |          threshold (:obj:`float`, optional):  The default value is driven from regression tests on \n",
      " |              test cases (default 1.0).\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): Notifying completion of scoring.\n",
      " |  \n",
      " |  get_scores_by(self, stype='raw')\n",
      " |      The method returns computed/available scores by the label of the terms.\n",
      " |      \n",
      " |      Note:\n",
      " |          The labels in this implementation correspond:\n",
      " |          - raw: the term as it is was identified in the background corpus, so\n",
      " |              a loglikelihood scoring was applied\n",
      " |          - stem: not the term as it is but its stem was identified, so mean of the observed\n",
      " |              stem occurances in the background was used as the reference\n",
      " |          - noref: neither the term nor its stem was identified, so the prediction model was used\n",
      " |              for the frequent ones.\n",
      " |          \n",
      " |      Args:\n",
      " |          stype (:obj:`str`, optional): The term scoring type (default 'raw').\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`dict`): The term scores.\n",
      " |  \n",
      " |  plot(self, threshold=1.0, islog=True)\n",
      " |      Scatter plot of frequency vs scores.\n",
      " |                      \n",
      " |      Args:\n",
      " |          threshold (:obj:`float`, optional):  The default value is driven from regression tests on \n",
      " |              test cases (default 1.0).\n",
      " |          \n",
      " |          islog (:obj:`bool`): Whether natural log of the frequency counts to be returned (default True).\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`bool`): True.\n",
      " |  \n",
      " |  predict(self, w, count, minp=0.001, minf=3)\n",
      " |      The method assigns a predicted score to a given term with a a frequency\n",
      " |          over the designated threshold. An internally formed prediction model is used.\n",
      " |          The natural logorithm of raw frequency counts is passed to the model. See \n",
      " |          `form_prediction_model` method description for details.\n",
      " |          \n",
      " |      Args:\n",
      " |          count (:obj:`int`): The raw frequency count.\n",
      " |          minp (:obj:`float`, optional): The relative frequency threshold (default 0.001).\n",
      " |          minf (:obj:`int`, optional): The raw frequency threshold (default 3).\n",
      " |              \n",
      " |      Returns:\n",
      " |          (:obj:`float`): The predicted score.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275 / 306  raw term matches found.\n",
      "Identifying specificity score for each matched terms...\n",
      "31 / 306 non-raw match found.\n",
      "Identifying specifificity score for stem matches...\n",
      "9 stems matched.\n",
      "Forming prediction model for non-matching terms...\n",
      "The minimum score used for the modelling = 1.0\n",
      "Computing specificity score for frequent distinct terms...\n",
      "All phases are done!\n"
     ]
    }
   ],
   "source": [
    "myScoring = Scoring(SC,CRef)\n",
    "SCored = copy.deepcopy(myScoring.sCorpus)\n",
    "DF = SCored.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myScoring.plot(threshold = 1.0, islog = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'referent': 4.21628163783526,\n",
       " 'abusive': 5.122896075378883,\n",
       " 'internalization': 3.232674832184158,\n",
       " 'relational': 3.1703413836049004,\n",
       " 'episodic': 4.668640803101286,\n",
       " 'abusers': 4.275598214991679,\n",
       " 'abuser': 4.275598214991679,\n",
       " 'reinforcement': 5.116665525628246,\n",
       " 'authoritys': 3.407972655098805}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myScoring.get_scores_by('stem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kraus': 2.7982323816182513,\n",
       " 'gender': 2.7982323816182513,\n",
       " 'raven': 2.909720393267773,\n",
       " 'counterpower': 3.2239874472484447,\n",
       " 'galbraith': 2.7982323816182513,\n",
       " 'constraint': 2.7982323816182513,\n",
       " 'reprimanded': 2.7982323816182513,\n",
       " 'unmarked': 3.1783419319076303,\n",
       " 'coercive': 3.5334402907275293,\n",
       " 'macro': 2.7982323816182513,\n",
       " 'gramsci': 2.7982323816182513,\n",
       " 'kelman': 2.7982323816182513,\n",
       " 'prerogative': 2.7982323816182513,\n",
       " 'nonrational': 2.7982323816182513,\n",
       " 'protagonist': 2.909720393267773,\n",
       " 'tarnow': 2.7982323816182513,\n",
       " 'clegg': 2.7982323816182513,\n",
       " 'empathy': 2.996197213447814,\n",
       " 'literacy': 3.066853920258109,\n",
       " 'bjrn': 2.7982323816182513,\n",
       " 'foucault': 3.126593314659349,\n",
       " 'hegemony': 2.996197213447814}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myScoring.get_scores_by('noref')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exporting topic specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvfile_name = OUTPUT_FOLDER + OUTPUT_FNAME_PREFIX + \".csv\"\n",
    "with open(csvfile_name, 'w') as csvfile:\n",
    "    DF.to_csv(csvfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/Power.csv\n"
     ]
    }
   ],
   "source": [
    "print(csvfile_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exporting part of data\n",
    "\n",
    "#### Selecting a specific range of scores\n",
    "\n",
    "Note that with the function below a specific slice between a mix and max value can be determined. Besides, the filterin can be applied to any column as long as its data type is a number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Term</th>\n",
       "      <th>Stem</th>\n",
       "      <th>wTF</th>\n",
       "      <th>SType</th>\n",
       "      <th>Score</th>\n",
       "      <th>wTFref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>12</td>\n",
       "      <td>rewards</td>\n",
       "      <td>reward</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>raw</td>\n",
       "      <td>6.578183</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>7</td>\n",
       "      <td>interpersonal</td>\n",
       "      <td>interperson</td>\n",
       "      <td>0.003593</td>\n",
       "      <td>raw</td>\n",
       "      <td>6.326869</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>33</td>\n",
       "      <td>tactics</td>\n",
       "      <td>tactic</td>\n",
       "      <td>0.016940</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.980346</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>behaviour</td>\n",
       "      <td>behaviour</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.767253</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>4</td>\n",
       "      <td>ultimatum</td>\n",
       "      <td>ultimatum</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>raw</td>\n",
       "      <td>5.767253</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TF           Term         Stem       wTF SType     Score    wTFref\n",
       "161  12        rewards       reward  0.006160   raw  6.578183  0.000009\n",
       "65    7  interpersonal  interperson  0.003593   raw  6.326869  0.000006\n",
       "89   33        tactics       tactic  0.016940   raw  5.980346  0.000043\n",
       "25    4      behaviour    behaviour  0.002053   raw  5.767253  0.000006\n",
       "282   4      ultimatum    ultimatum  0.002053   raw  5.767253  0.000006"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/Power_min4.csv\n"
     ]
    }
   ],
   "source": [
    "min_t = 4\n",
    "aslice = pandas_filter_rows(DF, col = 'Score', min_t = min_t)\n",
    "reduced = '_min{}'.format(min_t)\n",
    "filtered_csvfile_name = OUTPUT_FOLDER + OUTPUT_FNAME_PREFIX + reduced + \".csv\"\n",
    "aslice.to_csv(filtered_csvfile_name)\n",
    "print(filtered_csvfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%connect_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omterms",
   "language": "python",
   "name": "omterms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
